import pandas as pd
import numpy as np

def prepare_compas(file_path, binarize_features_dict=None, replace_dict=None, dummified=True, drop_first=False,
                   drop_duplicates=True, binary_risk_score = False,
                   # _list=None
                   ):
    orig_data = pd.read_csv(file_path)[
        ["c_charge_degree", "race", "age_cat", "sex", "priors_count",
                    "days_b_screening_arrest",
         "is_recid",
         "two_year_recid","score_text", "c_jail_in", "c_jail_out"]]

    # ProBublica Cleaning
    orig_data = orig_data.query(
        'days_b_screening_arrest <= 30 & days_b_screening_arrest >= -30 & is_recid != -1 & c_charge_degree != "O" & score_text != "N/A"').copy()

    # ProPublica New Feature
    orig_data["length_of_stay"] = (pd.to_datetime(orig_data["c_jail_out"]) - pd.to_datetime(orig_data["c_jail_in"])).apply(
        lambda x: x.round('d').days)

    # Drop COMPAS labels
    orig_data = orig_data.drop(["c_jail_out", "c_jail_in", "score_text", "is_recid"], axis=1)

    # Rename Attributes
    orig_data = orig_data.rename(dict(age_cat="Age Category", race="Race", sex="Gender", priors_count="Priors Count",
                            c_charge_degree="Felony or Misdemeanor", two_year_recid="Ground Truth",
                            decile_score="Risk Score", days_b_screening_arrest="Days Before Arrest",
                            # is_recid="Recidivist",
                            length_of_stay="Stay Length"), axis=1)

    # attribute renaming/casting
    orig_data["Felony or Misdemeanor"] = orig_data["Felony or Misdemeanor"].apply(
        lambda val: "Felony" if val == "F" else "Misdemeanor" if val == "M" else None)
    orig_data["Ground Truth"] = orig_data["Ground Truth"].apply(
        lambda a: "Will reoffend" if a == 1 else "Will not reoffend")
    # orig_data["Recidivist"] = orig_data["Recidivist"].astype(bool)
    orig_data["Days Before Arrest"] = orig_data["Days Before Arrest"].astype(int)


    # make any replacements

    if replace_dict is not None:
        data = orig_data.replace(replace_dict)
    else:
        data = orig_data

    # binarize data
    if binarize_features_dict is not None:
        for feat, acceptable_feats in binarize_features_dict.items():
            data[feat] = data[feat].where(data[feat].isin(acceptable_feats), "Other_{}".format(feat))

    # # pick a subset of data
    # if _list is None:
    #     data = data[['Age Category', 'Race', 'Gender', 'Felony or Misdemeanor',
    #                  'Priors Count', 'Ground Truth']]
    # else:
    #     data = data[_list]

    if binary_risk_score:
        data['Risk Score'] = data['Risk Score'].apply(
            lambda s: "High risk to reoffend" if s > 5 else "Low risk to reoffend")

    # drop duplicates
    if drop_duplicates:
        len_before = len(data)
        data = data.drop_duplicates().reset_index(drop=True)
        len_after = len(data)
        print("Removed {} duplicates: {} -> {}".format(len_before - len_after, len_before, len_after))

    if dummified:
        data = pd.get_dummies(data,
                              drop_first=drop_first)
        #         print(data.head)
        # cast as all integers
        data = data.astype(int)

    print("There are no duplicates." if not np.any(data.duplicated()) else "Duplicates exist.")

    return data