import pandas as pd
import numpy as np

def prepare_compas(file_path, binarize_features_dict=None, replace_dict=None, dummified=True, drop_first=False,
                   drop_duplicates=True, binary_risk_score = False,
                   _list=None):
    orig_data = pd.read_csv(file_path)[
        ["age_cat", "race", "sex", "priors_count", "c_charge_degree", "two_year_recid", "decile_score",
         "score_text"]].rename(dict(age_cat="Age Category", race="Race", sex="Gender", priors_count="Priors Count",
                                    c_charge_degree="Felony or Misdemeanor", two_year_recid="Ground Truth",
                                    decile_score="Risk Score", score_text="Algorithm Risk Evaluation"), axis=1)

    # column re-ordering
    orig_data = orig_data[['Age Category', 'Race', 'Gender',
                           'Felony or Misdemeanor', 'Priors Count',
                           'Algorithm Risk Evaluation', 'Risk Score',
                           'Ground Truth']]

    # attribute renaming
    orig_data["Felony or Misdemeanor"] = orig_data["Felony or Misdemeanor"].apply(
        lambda val: "Felony" if val == "F" else "Misdemeanor" if val == "M" else None)
    orig_data["Ground Truth"] = orig_data["Ground Truth"].apply(
        lambda a: "Will reoffend" if a == 1 else "Will not reoffend")

    # make any replacements
    data = orig_data.replace(replace_dict)

    # binarize data
    if binarize_features_dict is not None:
        for feat, acceptable_feats in binarize_features_dict.items():
            data[feat] = data[feat].where(data[feat].isin(acceptable_feats), "Other_{}".format(feat))

    # pick a subset of data
    if _list is None:
        data = data[['Age Category', 'Race', 'Gender', 'Felony or Misdemeanor',
                     'Priors Count', 'Ground Truth']]
    else:
        data = data[_list]

    if binary_risk_score:
        data['Risk Score'] = data['Risk Score'].apply(
            lambda s: "High risk to reoffend" if s > 5 else "Low risk to reoffend")

    # drop duplicates
    if drop_duplicates:
        len_before = len(data)
        data = data.drop_duplicates().reset_index(drop=True)
        len_after = len(data)
        print("Removed {} duplicates: {} -> {}".format(len_before - len_after, len_before, len_after))

    if dummified:
        data = pd.get_dummies(data,
                              drop_first=drop_first)
        #         print(data.head)
        # cast as all integers
        data = data.astype(int)

    print("There are no duplicates." if not np.any(data.duplicated()) else "Duplicates exist.")

    return data