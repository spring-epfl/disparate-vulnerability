from functools import reduce

import pandas as pd
import numpy as np
import seaborn as sns

from scipy.stats import combine_pvalues
from statsmodels.stats.multitest import multipletests

def plot_vuln_dists(
    metrics_by_model,
    models,
    axes,
    vuln_method="python",
    renaming_dict=None,
    ignore_subgroups=None,
    legend=True,
    percentages=False,
    order=None,
):
    """
    Plot distribution plots of vulnerability values for all subgroups.
    """
    if renaming_dict is None:
        renaming_dict = {model: model for model in models}

    if ignore_subgroups is None:
        ignore_subgroups = []

    for ax_id, model_name in enumerate(models):
        metrics = metrics_by_model[model_name]
        plot_df = metrics.query(f"vuln_method=='{vuln_method}'")
        for ignore_subgroup in ignore_subgroups:
            plot_df = plot_df.query(f"subgroup != '{ignore_subgroup}'").copy()

        plot_df.loc[:, "vuln"] = plot_df.vuln.astype(np.float32)
        plot_df = (
            plot_df.groupby(["batch_no", "attacker", "vuln_method", "subgroup"])
            .agg({"vuln": "mean"})
            .reset_index()
        )
        plot_df = plot_df.replace(renaming_dict)

        if percentages:
            plot_df["vuln"] = plot_df["vuln"] * 100

        g = sns.violinplot(
            data=plot_df.query("subgroup != 'Overall'"),
            x="vuln",
            hue="attacker",
            y="subgroup",
            ax=axes[0, ax_id],
            inner="quartile",
            split=True,
            order=order,
        )
        h = sns.violinplot(
            data=plot_df.query("subgroup == 'Overall'"),
            x="vuln",
            hue="attacker",
            y="subgroup",
            ax=axes[1, ax_id],
            inner="quartile",
            split=True,
        )

        axes[0, ax_id].set_xlabel("")
        axes[1, ax_id].set_xlabel("Vulnerability")
        if ax_id > 0:
            g.set_yticks([], [])
            h.set_yticks([], [])

        g.set_ylabel("Subgroups" if ax_id == 0 else "")
        h.set_ylabel("")
        h.get_legend().remove()
        g.set_title(renaming_dict[model_name])
        if legend and (ax_id == len(models) - 1):
            g.legend(title="Attacker", framealpha=0.4)
        else:
            g.get_legend().remove()

    return axes

def plot_vuln_dists_legends_combined(
        metrics_by_model,
        models,
        axes,
        vuln_method="python",
        renaming_dict=None,
        ignore_subgroups=None,
        #         legend=True,
        percentages=False,
        barplot_metrics=None,
        xlim_dists=None,
        xlim_barplots=None,
        additional_barplot_metrics_series=None
):
    """
    Plot distribution plots of vulnerability values for all subgroups.
    """

    def get_subgroup_renaming_dict_and_order(plot_df):
        overall = plot_df.query("subgroup == 'Overall'")["support"].drop_duplicates().iloc[0]
        support_df = plot_df[["subgroup", "support"]].drop_duplicates(subset=["subgroup"]).sort_values("support",
                                                                                                       ascending=False)
        subgroup_renaming_dict = reduce(lambda x1, x2: {**x1, **x2}, support_df.apply(
            lambda x: {
                x.subgroup: f'{x.subgroup}: {x.support}\n({x.support / overall:.2%})'},
            axis=1))

        subgroup_renaming_dict = {k: v.replace("-", "-\n", 1) if "-" in v else v for k, v in
                                  subgroup_renaming_dict.items()}
        return subgroup_renaming_dict, np.roll(support_df.subgroup, -1).tolist()

    def add_additional_series(_df):
        if additional_barplot_metrics_series is not None:
            for ser_name, ser in additional_barplot_metrics_series.items():
                _df = _df.merge(ser.rename(ser_name), left_on="subgroup", right_index=True)
        return _df

    def add_additional_metrics(g, overall, remove_ticks=False):
        g_2 = g.twiny()
        _query = "subgroup != 'Overall'" if not overall else "subgroup == 'Overall'"
        _df = plot_df.query(_query).groupby(["batch_no", "subgroup"]).agg("mean").groupby("subgroup").agg(
            "mean").reset_index()
        _df = add_additional_series(_df)
        _value_vars = barplot_metrics if additional_barplot_metrics_series is None else barplot_metrics + list(
            additional_barplot_metrics_series.keys())
        plot_df_2 = pd.melt(_df, id_vars="subgroup", value_vars=_value_vars)
        sns.barplot(data=plot_df_2, x="value", y="subgroup", hue="variable", ax=g_2, palette="YlOrRd", alpha=0.3,
                    saturation=1)
        g_2.set_xlabel("")
        g_2.legend_.remove()
        g_2.spines['top'].set_color('red')
        g_2.xaxis.label.set_color('red')
        g_2.tick_params(axis='x', colors='red')

        if remove_ticks:
            g_2.set_xticklabels([])

        return g_2

    if barplot_metrics is None:
        barplot_metrics = []

    if renaming_dict is None:
        renaming_dict = {model: model for model in models}

    if ignore_subgroups is None:
        ignore_subgroups = []

    legend_returns = dict(handles=[], labels=[])

    for ax_id, model_name in enumerate(models):
        metrics = metrics_by_model[model_name]
        plot_df = metrics.query(f"vuln_method=='{vuln_method}'")
        subgroup_renaming_dict, model_order = get_subgroup_renaming_dict_and_order(plot_df)

        for ignore_subgroup in ignore_subgroups:
            plot_df = plot_df.query(f"subgroup != '{ignore_subgroup}'").copy()

        plot_df.loc[:, "vuln"] = plot_df.vuln.astype(np.float32)
        plot_df = (
            plot_df.groupby(["batch_no", "attacker", "vuln_method", "subgroup"])
                .agg("mean")
                .reset_index()
        )

        # additional metrics
        fpr = lambda plot_df, dataset: plot_df[f"fp_{dataset}"] / (plot_df[f"fp_{dataset}"] + plot_df[f"tp_{dataset}"])
        tpr = lambda plot_df, dataset: plot_df[f"tp_{dataset}"] / (plot_df[f"fp_{dataset}"] + plot_df[f"tp_{dataset}"])
        fnr = lambda plot_df, dataset: plot_df[f"fn_{dataset}"] / (plot_df[f"fn_{dataset}"] + plot_df[f"tn_{dataset}"])
        tnr = lambda plot_df, dataset: plot_df[f"tn_{dataset}"] / (plot_df[f"fn_{dataset}"] + plot_df[f"tn_{dataset}"])

        pr = lambda plot_df, dataset: (plot_df[f"fp_{dataset}"] + plot_df[f"tp_{dataset}"]) / (
                plot_df[f"fp_{dataset}"] + plot_df[f"tp_{dataset}"] + plot_df[f"fn_{dataset}"] + plot_df[
            f"tn_{dataset}"])

        def total_variability(plot_df):
            # todo: change to p-classes not just 2.
            denum = lambda dataset: plot_df[f"fp_{dataset}"] + plot_df[f"tp_{dataset}"] + plot_df[f"fn_{dataset}"] + \
                                    plot_df[f"tn_{dataset}"]
            tv = 0
            for measure in ["fp", "tp", "fn", "tn"]:
                tv += abs(plot_df[f"{measure}_train"] / denum("train") - plot_df[f"{measure}_test"] / denum("test"))
            return tv

        plot_df["Overfitting (Accuracy)"] = plot_df.target_train_acc - plot_df.target_test_acc
        plot_df["Overfitting (FPR)"] = fpr(plot_df, "train") - fpr(plot_df, "test")
        plot_df["Overfitting (TPR)"] = tpr(plot_df, "train") - tpr(plot_df, "test")
        plot_df["Overfitting (PR)"] = pr(plot_df, "train") - pr(plot_df, "test")
        # import pdb; pdb.set_trace()
        plot_df["Total Variation"] = total_variability(plot_df)

        plot_df = plot_df.replace(renaming_dict)

        if percentages:
            plot_df["vuln"] = plot_df["vuln"] * 100
            for met in barplot_metrics:
                #                 import pdb; pdb.set_trace();
                plot_df[met] = plot_df[met] * 100

        g = sns.violinplot(
            data=plot_df.query("subgroup != 'Overall'"),
            x="vuln",
            order=filter(lambda x: x not in ignore_subgroups, model_order[:-1]),
            hue="attacker",
            y="subgroup",
            ax=axes[0, ax_id],
            inner="quartile",
            split=True,
        )
        g.set_yticklabels([subgroup_renaming_dict[item.get_text()] for item in g.get_yticklabels()])

        h = sns.violinplot(
            data=plot_df.query("subgroup == 'Overall'"),
            x="vuln",
            hue="attacker",
            y="subgroup",
            ax=axes[1, ax_id],
            inner="quartile",
            split=True,
        )

        # import pdb; pdb.set_trace();
        h.set_yticklabels([subgroup_renaming_dict[item.get_text()] for item in h.get_yticklabels()])

        if barplot_metrics or additional_barplot_metrics_series:
            g_2 = add_additional_metrics(g, overall=False, remove_ticks=False)
            h_2 = add_additional_metrics(h, overall=True, remove_ticks=True)

        axes[0, ax_id].set_xlabel("")
        axes[1, ax_id].set_xlabel("Vulnerability")
        if ax_id > 0:
            g.set_yticks([], [])
            h.set_yticks([], [])

        g.set_ylabel("Subgroups" if ax_id == 0 else "")
        h.set_ylabel("")
        h.get_legend().remove()
        g.set_title(renaming_dict[model_name])
        #         if legend and (ax_id == len(models) - 1):
        #             g.legend(title="Attacker", framealpha=0.4)
        #         else:
        g.get_legend().remove()

        if xlim_dists is not None:
            for _ax in [g, h]:
                _ax.set_xlim(xlim_dists)
                _ax.set_facecolor('none')
                _ax.set_alpha(0)
        if xlim_barplots is not None:
            for _ax in [g_2, h_2]:
                _ax.set_xlim(xlim_barplots)

        if ax_id == len(models) - 1:
            for _id, ax in enumerate([g, g_2] if barplot_metrics or additional_barplot_metrics_series else [g]):
                # get handles and labels to export
                handles, labels = ax.get_legend_handles_labels()

                legend_returns["handles"] += handles
                legend_returns["labels"] += labels

    return legend_returns


def plot_stat_heatmaps(
        metrics, p_matrices, subgroups, ax, alpha=0.005, mode="meta", method=None,
        xticklabels=True, yticklabels=True, cmap=None
):
    """
    Plot heatmaps of pairwise t-tests for disparity between all subgroup pairs.
    """
    res_matrix = pd.DataFrame(
        np.zeros((len(subgroups), len(subgroups))), columns=subgroups, index=subgroups
    )

    for i, z1 in enumerate(subgroups):
        for j, z2 in enumerate(subgroups):
            p_values = []
            for p_matrix in p_matrices:
                p_values.append(p_matrix.loc[z1][z2])

            if mode == "multitests":
                rejects, _, _, _ = multipletests(p_values, alpha=alpha, method=method or "holm")
                res_matrix.loc[z1][z2] = rejects.mean()
            elif mode == "meta":
                _, fisher_p = combine_pvalues(p_values)
                res_matrix.loc[z1][z2] = float(fisher_p < alpha)

    mask = np.ones_like(res_matrix)
    mask[np.triu_indices_from(mask, k=1)] = False

    sns.heatmap(
        res_matrix,
        annot=True,
        mask=mask,
        square=True,
        vmin=0.0,
        vmax=1.0,
        ax=ax,
        xticklabels=xticklabels,
        yticklabels=yticklabels,
        cbar=False,
        cmap=cmap,
    )
    ax.set_ylim(len(subgroups), 0)
    return ax
