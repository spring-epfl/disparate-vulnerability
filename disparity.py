import itertools

import pandas as pd
import numpy as np
from scipy import stats
from statsmodels.stats.multitest import multipletests
from joblib import Parallel, delayed

from rpy2.robjects.packages import importr
from rpy2.robjects import r, globalenv, pandas2ri

from tqdm.notebook import tqdm

from utils import metrics_dict_to_dataframe, insert_example_ids


# R libraries
utils = importr("utils")
base = importr("base")
lmerTest = importr("lmerTest")
emmeans = importr("emmeans")
pandas2ri.activate()


def _compute_batch_p_matrix(batch, subgroups, metrics, attacker, vuln_method, test):
    p_matrix = pd.DataFrame(
        np.zeros((len(subgroups), len(subgroups))), columns=subgroups, index=subgroups
    )
    for (i, z1), (j, z2) in itertools.combinations(enumerate(subgroups), 2):
        if z1 != z2:
            vuln_df = metrics.query(
                f"vuln_method == '{vuln_method}' and attacker == '{attacker}' and batch_no == {batch}"
            )
            a = vuln_df.query(f"subgroup == {repr(z1)}").vuln.values.astype(np.float32)
            b = vuln_df.query(f"subgroup == {repr(z2)}").vuln.values.astype(np.float32)
            if test == "t-test":
                _, p_value = stats.ttest_ind(a, b, equal_var=False)
            elif test == "mannwhitneyu":
                _, p_value = stats.mannwhitneyu(a, b)
            elif test == "brunnermunzel":
                _, p_value = stats.brunnermunzel(a, b)
            p_matrix.loc[z1][z2] = p_value
    return p_matrix


def compute_anovas(metrics_by_model, attacker, vuln_method="counts", anova_kwargs=None):
    """
    Fit linear mixed-effects models and compute corresponding ANOVA p-values.
    """
    if anova_kwargs is None:
        anova_kwargs = {"ddf": "Satterthwaite"}

    anovas_by_model = {}
    for model, metrics in tqdm(metrics_by_model.items()):
        vuln_df = metrics.query(
            f"vuln_method == '{vuln_method}' and attacker == '{attacker}' "
            f"and subgroup != 'Overall'"
        )
        vuln_df = insert_example_ids(vuln_df)
        vuln_df.vuln = vuln_df.vuln.astype(np.float32)
        lmer_model = lmerTest.lmer(
            r.formula("vuln ~ subgroup + (1 | example_id/batch_no) + (1 | batch_no)"),
            data=vuln_df,
        )
        p_value = r.anova(lmer_model, **anova_kwargs)["Pr(>F)"][0]
        anovas_by_model[model] = (p_value, lmer_model)
    return anovas_by_model


def compute_p_matrices(
    metrics_by_model, attacker, subgroups, vuln_method="counts", test="t-test", n_jobs=4
):
    """
    Compute pairwise tests.
    """
    p_matrices_by_model = {}
    for model, metrics in tqdm(metrics_by_model.items()):
        it = (
            delayed(_compute_batch_p_matrix)(
                batch, subgroups, metrics, attacker, vuln_method, test
            )
            for batch in metrics.batch_no.unique()
        )
        p_matrices_by_model[model] = Parallel(n_jobs=n_jobs)(it)

    return p_matrices_by_model


def compute_emm(anovas_by_model, subgroups, emmeans_kwargs=None):
    "Compute pairwise difference through expected marginal means."
    if emmeans_kwargs is None:
        emmeans_kwargs = {"lmer.df": "Satterthwaite", "lmerTest.limit": 10_000_000}

    p_matrices_by_model = {}
    for model, anova in tqdm(anovas_by_model.items()):
        p_value, lmer_model = anova

        # Compute EMM.
        emm_obj = emmeans.emmeans(lmer_model, "subgroup", **emmeans_kwargs)
        emm_mat = r.summary(r.pairs(emm_obj))

        # Translate results into n x n dataframe
        p_matrix = pd.DataFrame(
            np.zeros((len(subgroups), len(subgroups))),
            columns=subgroups,
            index=subgroups,
        )
        for _, row in emm_mat.iterrows():
            a, b = row["contrast"].split(" - ")
            p_value = row["p.value"]
            p_matrix[a][b] = p_value
            p_matrix[b][a] = p_value
        p_matrices_by_model[model] = [p_matrix]

    return p_matrices_by_model


def max_disparity(
    metrics,
    renaming_dict,
    plot_order=None,
    ax=None,
    x_label="Max Vuln. Disparity",
    y_label="Model",
    single_dataframe=False,
    additional_columns_to_keep=None,
):
    def calc_max_disparity(gr):
        _max = np.max(np.subtract.outer(*[gr.values] * 2))
        return _max

    if additional_columns_to_keep is None:
        additional_columns_to_keep = []

    if not single_dataframe:
        # aggreagte all dataframes into one
        metrics_all = metrics_dict_to_dataframe(metrics)
    else:
        metrics_all = metrics

    metrics_all["vuln"] = metrics_all["vuln"].astype(int)

    aggregated = metrics_all.groupby(["subgroup", "batch_no", "attacker", "model"]).agg(
        "mean"
    )
    aggregated["overfitting_gap"] = aggregated.apply(
        lambda x: x["target_train_acc"] - x["target_test_acc"], axis=1
    )

    average_vuln = (
        aggregated.groupby(["subgroup", "attacker", "model"])
        .agg("mean")
        .groupby(["attacker", "model"])
        .agg(["mean", "std"])
        .drop("support", axis=1)
    )

    max_vuln_disparity = (
        aggregated[["vuln"]]
        .groupby(["batch_no", "attacker", "model"])
        .apply(lambda gr: calc_max_disparity(gr))
        .to_frame(name="max_vuln_disparity")
        .groupby(["attacker", "model"])
        .agg(["mean", "std"])
    )

    table = average_vuln.join(max_vuln_disparity)
    table = table[
        ["target_test_acc", "overfitting_gap", "vuln", "max_vuln_disparity"]
        + additional_columns_to_keep
    ]

    if ax is not None:
        _plot_df = (
            table.reset_index()
            .rename(
                columns=dict(
                    attacker="Attacker",
                    model=y_label,
                    max_vuln_disparity=x_label,
                    overfitting_gap="Overfitting Gap",
                    target_train_acc="Target Train Acc.",
                    vuln="Vulnerability",
                )
            )
            .rename(renaming_dict)
            .replace(renaming_dict)
        )

        g = sns.barplot(
            data=_plot_df, order=plot_order, x=x_label, y=y_label, hue="Attacker", ax=ax
        )
        g.legend(loc="center left", bbox_to_anchor=(1, 0.5))

    return table


def max_disparity_per_batch(df, additional_indices=None):
    def calc_max_disparity(gr):
        _max = np.max(np.subtract.outer(*[gr.values] * 2))
        return _max

    assert "vuln" in df.columns
    assert "subgroup" in df.columns

    if additional_indices is not None:
        _indices = ["vuln"] + additional_indices
    else:
        _indices = ["vuln"]

    _metrics_all = df
    _metrics_all["vuln"] = _metrics_all["vuln"].astype(int)

    # get vulnerability score for the batch per subgroup
    _average_vuln = _metrics_all.groupby(["subgroup"]).agg("mean")

    # calculate max disparity (which is one number per batch)
    _max_vuln_disparity = calc_max_disparity(_average_vuln["vuln"])

    return _max_vuln_disparity
