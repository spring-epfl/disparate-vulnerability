import itertools

import pandas as pd
import numpy as np
from scipy.stats import ttest_ind

from tqdm.notebook import tqdm

from utils import metrics_dict_to_dataframe


def compute_p_matrices(
    metrics_by_model, attacker, subgroups, vuln_method="counts", test="t-test"
):
    """
    Compute pairwise tests.
    """
    p_matrices_by_model = {}
    for model, metrics in tqdm(metrics_by_model.items()):
        p_matrices = []
        for batch in metrics.batch_no.unique():
            p_matrix = pd.DataFrame(
                np.zeros((len(subgroups), len(subgroups))),
                columns=subgroups,
                index=subgroups,
            )
            for ((i, z1), (j, z2)) in itertools.combinations(enumerate(subgroups), 2):
                if z1 != z2:
                    vuln_df = metrics.query(
                        f"vuln_method == '{vuln_method}' and attacker == '{attacker}' and batch_no == {batch}"
                    )
                    a = vuln_df.query(f"subgroup == {repr(z1)}").vuln.values.astype(
                        np.float32
                    )
                    b = vuln_df.query(f"subgroup == {repr(z2)}").vuln.values.astype(
                        np.float32
                    )
                    if test == "t-test":
                        _, p_value = ttest_ind(a, b, equal_var=False)
                    p_matrix.loc[z1][z2] = p_value
            p_matrices.append(p_matrix)
        p_matrices_by_model[model] = p_matrices

    return p_matrices_by_model


def max_disparity(
    metrics,
    renaming_dict,
    plot_order=None,
    ax=None,
    x_label="Max Vuln. Disparity",
    y_label="Model",
    single_dataframe=False,
    additional_columns_to_keep=None,
):
    def calc_max_disparity(gr):
        _max = np.max(np.subtract.outer(*[gr.values] * 2))
        return _max

    if additional_columns_to_keep is None:
        additional_columns_to_keep = []

    if not single_dataframe:
        # aggreagte all dataframes into one
        metrics_all = metrics_dict_to_dataframe(metrics)
    else:
        metrics_all = metrics

    metrics_all["vuln"] = metrics_all["vuln"].astype(int)

    aggregated = metrics_all.groupby(["subgroup", "batch_no", "attacker", "model"]).agg(
        "mean"
    )
    aggregated["overfitting_gap"] = aggregated.apply(
        lambda x: x["target_train_acc"] - x["target_test_acc"], axis=1
    )

    average_vuln = (
        aggregated.groupby(["subgroup", "attacker", "model"])
        .agg("mean")
        .groupby(["attacker", "model"])
        .agg(["mean", "std"])
        .drop("support", axis=1)
    )

    max_vuln_disparity = (
        aggregated[["vuln"]]
        .groupby(["batch_no", "attacker", "model"])
        .apply(lambda gr: calc_max_disparity(gr))
        .to_frame(name="max_vuln_disparity")
        .groupby(["attacker", "model"])
        .agg(["mean", "std"])
    )

    table = average_vuln.join(max_vuln_disparity)
    table = table[
        ["target_test_acc", "overfitting_gap", "vuln", "max_vuln_disparity"]
        + additional_columns_to_keep
    ]

    if ax is not None:
        _plot_df = (
            table.reset_index()
            .rename(
                columns=dict(
                    attacker="Attacker",
                    model=y_label,
                    max_vuln_disparity=x_label,
                    overfitting_gap="Overfitting Gap",
                    target_train_acc="Target Train Acc.",
                    vuln="Vulnerability",
                )
            )
            .rename(renaming_dict)
            .replace(renaming_dict)
        )

        g = sns.barplot(
            data=_plot_df, order=plot_order, x=x_label, y=y_label, hue="Attacker", ax=ax
        )
        g.legend(loc="center left", bbox_to_anchor=(1, 0.5))

    return table


def max_disparity_per_batch(df, additional_indices=None):
    def calc_max_disparity(gr):
        _max = np.max(np.subtract.outer(*[gr.values] * 2))
        return _max

    assert "vuln" in df.columns
    assert "subgroup" in df.columns

    if additional_indices is not None:
        _indices = ["vuln"] + additional_indices
    else:
        _indices = ["vuln"]

    _metrics_all = df
    _metrics_all["vuln"] = _metrics_all["vuln"].astype(int)

    # get vulnerability score for the batch per subgroup
    _average_vuln = _metrics_all.groupby(["subgroup"]).agg("mean")

    # calculate max disparity (which is one number per batch)
    _max_vuln_disparity = calc_max_disparity(_average_vuln["vuln"])

    return _max_vuln_disparity
