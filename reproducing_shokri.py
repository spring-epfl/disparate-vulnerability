# ---
# jupyter:
#   jupytext:
#     formats: ipynb,py:percent
#     text_representation:
#       extension: .py
#       format_name: percent
#       format_version: '1.3'
#       jupytext_version: 1.11.1
#   kernelspec:
#     display_name: Python 3
#     language: python
#     name: python3
# ---

# %%
# %load_ext autoreload
# %autoreload 2

import itertools

import pandas as pd
import numpy as np
import seaborn as sns
import diffprivlib.models as dp

from tqdm import notebook as tqdm
from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import MinMaxScaler
from sklearn.pipeline import Pipeline
from scipy import stats

from mia.vuln import run_threshold_estimator

import plot_params

# %%
from model_zoo import model_zoo, lr_setup, renaming_dict


# %%
class ThreshClassifier:
    def __init__(self, threshold=0.):
        self.threshold = threshold
        
    def fit(self, *args, **kwargs):
        pass
    
    def predict_proba(self, xs, *args, **kwargs):
        if isinstance(xs, pd.DataFrame):
            xs = xs.values
        p = xs[:, 0] > self.threshold
        p = np.expand_dims(p, 1)
        return np.hstack([1-p, p])
    
ThreshClassifier().predict_proba(np.array([[0, 1], [1, 0]]))
model_zoo["threshold"] = lambda: ThreshClassifier()

# %% [markdown]
# ## Reproduce some Shokri experiments

# %%
total_size = 2500
size0 = 0.2
size1 = 0.8
gen = np.random.RandomState(seed=1)
minus0 = gen.multivariate_normal([0, -1], [[7, 1], [1, 7]],
                                 size=int(0.1 * size0 * total_size))
plus0 = gen.multivariate_normal([1, 2], [[5, 2], [2, 5]],
                                 size=int(0.9 * size0 * total_size))
minus1 = gen.multivariate_normal([-5, 0], [[5, 1], [1, 5]],
                                 size=int(0.5 * size1 * total_size))
plus1 = gen.multivariate_normal([2, 3], [[10, 1], [1, 4]],
                                 size=int(0.5 * size1 * total_size))
print(len(minus0), len(plus0), len(minus1), len(plus1))

data = pd.concat([
    pd.DataFrame(minus0).assign(z=0, y=0),
    pd.DataFrame(plus0).assign(z=0, y=1),
    pd.DataFrame(minus1).assign(z=1, y=0),
    pd.DataFrame(plus1).assign(z=1, y=1),
], axis=0, ignore_index=True)

data.head()

# %%
sns.displot(data, x=0, hue="z", col="y")


# %%
def get_subgroup_vulns(clf, data_train, data_test,
                       sensitive_features=False, ys=None, zs=None,
                       ignore_y=False, visualize=False,
                       method="average_loss_threshold"):
    if ys is None: ys = [0, 1]
    if zs is None: zs = [0, 1]
    
    result = pd.DataFrame()
    for y, z in itertools.product(ys, zs):
        group_train = data_train.query(f"y == {y} and z == {z}")
        group_test = data_test.query(f"y == {y} and z == {z}")
        
        
        preds_train = clf.predict_proba(group_train[[0, 1]])[:, 1]
        preds_test = clf.predict_proba(group_test[[0, 1]])[:, 1]
        
        vuln = run_threshold_estimator(
            group_train.y, preds_train, group_test.y, preds_test,
            microdata=True,
            method=method,
        )
            
        result = result.append(
            pd.DataFrame(dict(vuln=vuln)).assign(y=y, z=z, i=vuln.index), ignore_index=True
        )
        
    return result

methods = ["best_loss_threshold", "average_loss_threshold"]
num_reps = 30
shokri_results = pd.DataFrame()
for rep in tqdm.trange(num_reps):
    data_train, data_test = train_test_split(
        data, test_size=0.5, random_state=rep)
    X_train = data_train[[0, 1]].values
    y_train = data_train.y.values
    
    control_model = ThreshClassifier()
    control_model.fit(X_train, y_train)
    normal_model = MLPClassifier(hidden_layer_sizes=[8, 8, 8]).fit(X_train, y_train)
#     fair_model = model_zoo["lr_eo"]()
#     fair_model.fit(X_train, y_train, sensitive_features=data_train.z)
    
    for method in methods:
        vulns_data = pd.concat([
            get_subgroup_vulns(control_model, data_train, data_test,
                               method=method) \
                .assign(model="control", method=method),
            get_subgroup_vulns(normal_model, data_train, data_test,
                               method=method) \
                .assign(model="nn", method=method),
#             get_subgroup_vulns(fair_model, data_train, data_test,
#                                sensitive_features=True,
#                                method=method) \
#                 .assign(model="fair", method=method),
        ], axis=0, ignore_index=True).assign(rep=rep)
        shokri_results = shokri_results.append(vulns_data, ignore_index=True)

shokri_results.head()

# %%
shokri_results.groupby(["model", "method", "z", "y"]).vuln.mean()

# %%
shokri_results["subgroup"] = list(f"{z}-{y}" for z, y in zip(shokri_results["z"], shokri_results["y"]))

# %%
from statsmodels.stats.anova import AnovaRM
from statsmodels.stats.multicomp import pairwise_tukeyhsd

for model, method in itertools.product(["control", "nn"], methods):
    df = shokri_results.query(f"model == '{model}' and method == '{method}'")
    anova = AnovaRM(
        data=df,
        depvar="vuln",
        subject="rep",
        within=["subgroup"],
        aggregate_func=np.mean
    )
    res = anova.fit()
    f, p = (
        res.anova_table.loc["subgroup", "F Value"],
        res.anova_table.loc["subgroup", "Pr > F"]
    )
    
    print(f"{model=} {method=}")
    print(f"{p=} {f=}\n")
    shokri_results.loc[df.index, "p"] = p
    shokri_results.loc[df.index, "F"] = f

# %%
plot_df = shokri_results.copy()
plot_df = plot_df.replace({
    "average_loss_threshold": "Avg. loss threshold",
    "best_loss_threshold": "Opt. loss threshold",
}).rename(columns={
    "subgroup": "Subgroup",
    "vuln": "Vuln. estimation bias",
    "method": "Method",
})

fig, ax = plt.subplots(figsize=(12, 8))
sns.barplot(
    data=plot_df.query("model == 'control'"),
    estimator=lambda vulns: (2 * vulns.mean() - 1) * 100,
    x="Subgroup", y="Vuln. estimation bias", hue="Method",
    ax=ax
)

# %%
shokri_results \
    .groupby(["model", "method",]) \
    .p.mean()

# %%
shokri_results \
    .groupby(["i", "model", "method"]) \
    .agg(dict(vuln="mean", z="mean", y="mean")) \
    .groupby(["method", "model", "z", "y"]) \
    .vuln.mean()
