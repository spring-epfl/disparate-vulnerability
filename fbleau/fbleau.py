import subprocess
import numpy as np
from tempfile import NamedTemporaryFile
import pandas as pd
from sklearn.model_selection import train_test_split
from helpers import encode_dataframe

FBLEAU_CMD = 'fbleau'
ESTIMATES = ['log', 'log10', 'frequentist', '--knn=1']
DISTANCES = ['euclidean', 'levenshtein']


def fbleau(O_learn, O_eval, S_learn, S_eval, estimate):
    """Runs F-BLEAU and returns its estimate.
    """
    # Remove NaNs
    # S = S[~np.isnan(O).any(axis=1)]
    # O = O[~np.isnan(O).any(axis=1)]

    # Split into training/test data
    # O_learn, O_eval, S_learn, S_eval = train_test_split(O, S, test_size=test_size, stratify=S)

    # print(O_learn[0], O_learn.shape)
    # print(O_eval[0], O_eval.shape)
    # print(S_learn[0], S_learn.shape)
    # print(S_eval[0], S_eval.shape)

    trainfile = NamedTemporaryFile(delete=True)
    testfile = NamedTemporaryFile(delete=True)
    fmt = ['%d'] + ['%.3f'] * O_learn.shape[1]
    np.savetxt(trainfile.name, np.hstack((S_learn.reshape(-1, 1), O_learn)),
               delimiter=',', fmt=fmt)
    np.savetxt(testfile.name, np.hstack((S_eval.reshape(-1, 1), O_eval)),
               delimiter=',', fmt=fmt)

    logfile = NamedTemporaryFile(delete=True)
    cmd = '{} {} --verbose={} {} {}'.format(FBLEAU_CMD, estimate, logfile.name,
                                            trainfile.name, testfile.name)
    proc = subprocess.call(cmd.split(' '))

    if proc != 0:
        print(proc)
        print(logfile.name)
        print(trainfile.name)
        print(testfile.name)
        raise Exception("fbleau failed")

    trainfile.close()
    testfile.close()
    data = np.loadtxt(logfile.name, delimiter=',', skiprows=1)
    logfile.close()

    return data


# def estimate_beta(O, S, guess_risk=None, repeat=5, test_size=0.2, estimates=ESTIMATES):
#     """Estimates beta using F-BLEAU.
#     For now it assumes uniform priors.
#     """
#     bayes_risk = 1.
#     for estimate in estimates:
#         est = 0.
#         for _ in range(repeat):
#             fbleau_logs = fbleau(O, S, estimate, test_size)
#             est += min(fbleau_logs[:, 2])
#         est /= repeat
#         if est < bayes_risk:
#             bayes_risk = est
#
#     if guess_risk is None:
#         raise Exception("Not implemented")
#
#     return bayes_risk / guess_risk

def calc_vulnerability(train_learn_df, train_eval_df, test_learn_df, test_eval_df,
                       attacker, z_label, y_label, p_label, z_values, z_value=None, estimate_method='frequentist',
                       repeat=1):
    def encode_and_prepare(df):
        df_ = df[[p_label, y_label, z_label]].copy()
        df_.loc[:, z_label] = df_[z_label].apply(lambda x: enc_dict[x]).copy()
        return df_

    enc_dict = {item: i for i, item in enumerate(z_values)}

    train_learn_df_ = encode_and_prepare(train_learn_df)
    train_eval_df_ = encode_and_prepare(train_eval_df)
    test_learn_df_ = encode_and_prepare(test_learn_df)
    test_eval_df_ = encode_and_prepare(test_eval_df)

    learn_df = train_learn_df_.assign(m=1).append(test_learn_df_.assign(m=0))
    eval_df = train_eval_df_.assign(m=1).append(test_eval_df_.assign(m=0))

    if z_value is not None:
        # we are calculating subgroup vulnerability
        eval_df = eval_df.loc[eval_df[z_label] == enc_dict[z_value]].copy()

    if attacker == "regular":
        O_learn, O_eval = learn_df[[p_label, y_label]].values, eval_df[[p_label, y_label]].values
        S_learn, S_eval = learn_df["m"].values, eval_df["m"].values
    elif attacker == "discriminating":
        O_learn, O_eval = learn_df[[p_label, y_label, z_label]].values, eval_df[[p_label, y_label, z_label]].values
        S_learn, S_eval = learn_df["m"].values, eval_df["m"].values
    else:
        raise NotImplementedError

    est_list = []
    for _ in range(repeat):
        fbleau_logs = fbleau(O_learn, O_eval, S_learn, S_eval, estimate_method)
        est_list.append(min(fbleau_logs[:, 2]))

    est = np.mean(est_list)
    return 1 - est
