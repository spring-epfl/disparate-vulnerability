import itertools
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from functools import reduce
from operator import xor

from scipy.stats import ttest_ind

from sklearn.linear_model import LogisticRegression
from sklearn.metrics.ranking import _binary_clf_curve
from sklearn.model_selection import StratifiedKFold
from sklearn.utils import resample
from keras import backend as K

from tqdm import tqdm_notebook


def encode_dataframe(df, output_columns=None, ignore_cols=None, initially_drop_columns=None, finally_drop_columns=None,
                     drop_first=True,
                     add_non_dummified_columns=None, return_output_columns=False):
    if ignore_cols is None:
        ignore_cols = []
    if initially_drop_columns is not None:
        df = df.drop(initially_drop_columns, axis=1)

    df_ = pd.get_dummies(df, columns=[col for col in df.columns if col != "strat"
                                      and not pd.api.types.is_numeric_dtype(df.dtypes[col]) and col not in ignore_cols],
                         drop_first=drop_first)

    if add_non_dummified_columns is not None:
        keep_cols = df[add_non_dummified_columns]
        df_ = pd.concat([df_, keep_cols], axis=1)

    if output_columns is not None:
        df_ = df_.reindex(columns=output_columns, fill_value=0)

    if finally_drop_columns is not None:
        df_ = df_.drop(finally_drop_columns, axis=1)

    if return_output_columns:
        return df_, df_.columns.tolist()
    else:
        return df_


def assign_y(p_ser, thr):
    return (p_ser > thr).astype(int)


def calculate_measures(trn_df, tst_df, evl_df):
    thr2dfs = {thr: {} for thr in np.arange(0.01, 0.99, 0.01)}
    for thr in thr2dfs.keys():
        train_df = trn_df.copy()
        test_df = tst_df.copy()
        eval_df = evl_df.copy()
        train_df.loc[:, "yhat"] = assign_y(train_df["p"], thr)
        test_df.loc[:, "yhat"] = assign_y(test_df["p"], thr)
        eval_df.loc[:, "yhat"] = assign_y(eval_df["p"], thr)
        thr2dfs[thr]["train_df"] = train_df
        thr2dfs[thr]["test_df"] = test_df
        thr2dfs[thr]["eval_df"] = eval_df

    return thr2dfs


def metrics_dict_to_dataframe(metrics):
    return reduce(lambda df1, df2: pd.DataFrame.append(df1, df2),
                  [df.assign(model=model_name) for model_name, df in metrics.items()])


def balance_dataset(data_undummified, z_label, y_label, random_state=None):
    subgroups = data_undummified[z_label].value_counts().index.to_list()
    regroup_list = []

    for sg in subgroups:
        df_ = data_undummified.loc[data_undummified[z_label] == sg]
        counts = df_[y_label].value_counts().sort_values(ascending=True)
        min_count, min_group_label, maj_group_label = counts.iloc[0], counts.index[0], counts.index[1]
        # min_group = resample(df_.loc[df_[y_label] == min_group_label], n_samples=min_count, replace=False)
        min_group = df_.loc[df_[y_label] == min_group_label]
        maj_group = resample(df_.loc[df_[y_label] == maj_group_label], n_samples=min_count, replace=False,
                             **({"random_state": random_state} if random_state is not None else {}))
        _balanced_df = min_group.append(maj_group)
        regroup_list.append(_balanced_df)

    balanced_df = reduce(lambda df1, df2: pd.DataFrame.append(df1, df2), regroup_list)
    return balanced_df


def compute_p_matrices(metrics_by_model, attacker, subgroups, num_reps, vuln_method="counts"):
    """
    Compute pairwise t-tests.
    """
    p_matrices_by_model = {}
    for model, metrics in tqdm_notebook(metrics_by_model.items()):
        p_matrices = []
        for batch in range(num_reps):
            p_matrix = pd.DataFrame(np.zeros((len(subgroups), len(subgroups))),
                                    columns=subgroups, index=subgroups)
            for ((i, z1), (j, z2)) in itertools.combinations(enumerate(subgroups), 2):
                if z1 != z2:
                    vuln_df = metrics.query(
                        f"vuln_method == '{vuln_method}' and attacker == '{attacker}' and batch_no == {batch}"
                    )
                    a = vuln_df.query(f"subgroup == {repr(z1)}").vuln.values.astype(np.float32)
                    b = vuln_df.query(f"subgroup == {repr(z2)}").vuln.values.astype(np.float32)
                    _, p_value = ttest_ind(a, b, equal_var=False)
                    p_matrix.loc[z1][z2] = p_value
            p_matrices.append(p_matrix)
        p_matrices_by_model[model] = p_matrices

    return p_matrices_by_model


def max_disparity(_metrics, renaming_dict, plot_order=None, ax=None, x_label="Max Vuln. Disparity", y_label="Model",
                  single_dataframe=False, additional_columns_to_keep=None):
    def calc_max_disparity(gr):
        _max = np.max(np.subtract.outer(*[gr.values] * 2))
        return _max

    if additional_columns_to_keep is None:
        additional_columns_to_keep = []

    if not single_dataframe:
        # aggreagte all dataframes into one
        _metrics_all = metrics_dict_to_dataframe(_metrics)
    else:
        _metrics_all = _metrics

    _metrics_all["vuln"] = _metrics_all["vuln"].astype(int)

    _aggregated = (_metrics_all
                   .groupby(["subgroup", "batch_no", "attacker", "model"]).agg("mean"))

    _average_vuln = _aggregated.groupby(["subgroup", "attacker", "model"]).agg("mean").groupby(
        ["attacker", "model"]).agg("mean").drop("support", axis=1)

    _max_vuln_disparity = _aggregated[["vuln"]].groupby(["batch_no", "attacker", "model"]).apply(
        lambda gr: calc_max_disparity(gr)).to_frame(name="max_vuln_disparity").groupby(["attacker", "model"]).agg(
        "mean")

    _poster_table = _average_vuln.join(_max_vuln_disparity)
    _poster_table["overfitting_gap"] = _average_vuln.apply(lambda x: x["target_train_acc"] - x["target_test_acc"],
                                                           axis=1)
    _poster_table = _poster_table[["target_train_acc", "overfitting_gap", "vuln", "max_vuln_disparity"] + additional_columns_to_keep]

    if ax is not None:
        _plot_df = (_poster_table
                    .reset_index()
                    .rename(columns=dict(attacker="Attacker",
                                         model=y_label,
                                         max_vuln_disparity=x_label,
                                         overfitting_gap="Overfitting Gap",
                                         target_train_acc="Target Train Acc.",
                                         vuln="Vulnerability"))
                    .rename(renaming_dict)
                    .replace(renaming_dict))

        g = sns.barplot(data=_plot_df, order=plot_order, x=x_label, y=y_label, hue="Attacker", ax=ax)
        g.legend(loc='center left', bbox_to_anchor=(1, 0.5))

    return _poster_table


def reset_weights(model):
    session = K.get_session()
    for layer in model.layers:
        if hasattr(layer, 'kernel_initializer'):
            layer.kernel.initializer.run(session=session)
