import itertools
import pandas as pd
import numpy as np
import seaborn as sns
from functools import reduce
from scipy.stats import ttest_ind
from sklearn.utils import resample
from keras import backend as K
from tqdm import tqdm_notebook
import pdb


def encode_dataframe(
    df,
    output_columns=None,
    ignore_cols=None,
    initially_drop_columns=None,
    finally_drop_columns=None,
    drop_first=True,
    add_non_dummified_columns=None,
    return_output_columns=False,
):
    if ignore_cols is None:
        ignore_cols = []
    if initially_drop_columns is not None:
        df = df.drop(initially_drop_columns, axis=1)

    df_ = pd.get_dummies(
        df,
        columns=[
            col
            for col in df.columns
            if col != "strat"
            and not pd.api.types.is_numeric_dtype(df.dtypes[col])
            and col not in ignore_cols
        ],
        drop_first=drop_first,
    )

    if add_non_dummified_columns is not None:
        keep_cols = df[add_non_dummified_columns]
        df_ = pd.concat([df_, keep_cols], axis=1)

    if output_columns is not None:
        df_ = df_.reindex(columns=output_columns, fill_value=0)

    if finally_drop_columns is not None:
        df_ = df_.drop(finally_drop_columns, axis=1)

    if return_output_columns:
        return df_, df_.columns.tolist()
    else:
        return df_


def assign_y(p_ser, thr):
    return (p_ser > thr).astype(int)


def calculate_measures(trn_df, tst_df, evl_df):
    thr2dfs = {thr: {} for thr in np.arange(0.01, 0.99, 0.01)}
    for thr in thr2dfs.keys():
        train_df = trn_df.copy()
        test_df = tst_df.copy()
        eval_df = evl_df.copy()
        train_df.loc[:, "yhat"] = assign_y(train_df["p"], thr)
        test_df.loc[:, "yhat"] = assign_y(test_df["p"], thr)
        eval_df.loc[:, "yhat"] = assign_y(eval_df["p"], thr)
        thr2dfs[thr]["train_df"] = train_df
        thr2dfs[thr]["test_df"] = test_df
        thr2dfs[thr]["eval_df"] = eval_df

    return thr2dfs


def metrics_dict_to_dataframe(metrics):
    return reduce(
        lambda df1, df2: pd.DataFrame.append(df1, df2),
        [df.assign(model=model_name) for model_name, df in metrics.items()],
    )


def balance_dataset(data_undummified, z_label, y_label, random_state=None):
    subgroups = data_undummified[z_label].value_counts().index.to_list()
    regroup_list = []

    for sg in subgroups:
        df_ = data_undummified.loc[data_undummified[z_label] == sg]
        counts = df_[y_label].value_counts().sort_values(ascending=True)
        min_count, min_group_label, maj_group_label = (
            counts.iloc[0],
            counts.index[0],
            counts.index[1],
        )
        # min_group = resample(df_.loc[df_[y_label] == min_group_label], n_samples=min_count, replace=False)
        min_group = df_.loc[df_[y_label] == min_group_label]
        maj_group = resample(
            df_.loc[df_[y_label] == maj_group_label],
            n_samples=min_count,
            replace=False,
            **({"random_state": random_state} if random_state is not None else {}),
        )
        _balanced_df = min_group.append(maj_group)
        regroup_list.append(_balanced_df)

    balanced_df = reduce(lambda df1, df2: pd.DataFrame.append(df1, df2), regroup_list)
    return balanced_df


def compute_p_matrices(
    metrics_by_model, attacker, subgroups, num_reps, vuln_method="counts"
):
    """
    Compute pairwise t-tests.
    """
    p_matrices_by_model = {}
    for model, metrics in tqdm_notebook(metrics_by_model.items()):
        p_matrices = []
        for batch in range(num_reps):
            p_matrix = pd.DataFrame(
                np.zeros((len(subgroups), len(subgroups))),
                columns=subgroups,
                index=subgroups,
            )
            for ((i, z1), (j, z2)) in itertools.combinations(enumerate(subgroups), 2):
                if z1 != z2:
                    vuln_df = metrics.query(
                        f"vuln_method == '{vuln_method}' and attacker == '{attacker}' and batch_no == {batch}"
                    )
                    a = vuln_df.query(f"subgroup == {repr(z1)}").vuln.values.astype(
                        np.float32
                    )
                    b = vuln_df.query(f"subgroup == {repr(z2)}").vuln.values.astype(
                        np.float32
                    )
                    _, p_value = ttest_ind(a, b, equal_var=False)
                    p_matrix.loc[z1][z2] = p_value
            p_matrices.append(p_matrix)
        p_matrices_by_model[model] = p_matrices

    return p_matrices_by_model


def max_disparity(
    metrics,
    renaming_dict,
    plot_order=None,
    ax=None,
    x_label="Max Vuln. Disparity",
    y_label="Model",
    single_dataframe=False,
    additional_columns_to_keep=None,
):
    def calc_max_disparity(gr):
        _max = np.max(np.subtract.outer(*[gr.values] * 2))
        return _max

    if additional_columns_to_keep is None:
        additional_columns_to_keep = []

    if not single_dataframe:
        # aggreagte all dataframes into one
        metrics_all = metrics_dict_to_dataframe(metrics)
    else:
        metrics_all = metrics

    metrics_all["vuln"] = metrics_all["vuln"].astype(int)

    aggregated = metrics_all.groupby(["subgroup", "batch_no", "attacker", "model"]).agg(
        "mean"
    )
    aggregated["overfitting_gap"] = aggregated.apply(
        lambda x: x["target_train_acc"] - x["target_test_acc"], axis=1
    )

    average_vuln = (
        aggregated.groupby(["subgroup", "attacker", "model"])
        .agg("mean")
        .groupby(["attacker", "model"])
        .agg(["mean", "std"])
        .drop("support", axis=1)
    )

    max_vuln_disparity = (
        aggregated[["vuln"]]
        .groupby(["batch_no", "attacker", "model"])
        .apply(lambda gr: calc_max_disparity(gr))
        .to_frame(name="max_vuln_disparity")
        .groupby(["attacker", "model"])
        .agg(["mean", "std"])
    )

    table = average_vuln.join(max_vuln_disparity)
    table = table[
        ["target_test_acc", "overfitting_gap", "vuln", "max_vuln_disparity"]
        + additional_columns_to_keep
    ]

    if ax is not None:
        _plot_df = (
            table.reset_index()
            .rename(
                columns=dict(
                    attacker="Attacker",
                    model=y_label,
                    max_vuln_disparity=x_label,
                    overfitting_gap="Overfitting Gap",
                    target_train_acc="Target Train Acc.",
                    vuln="Vulnerability",
                )
            )
            .rename(renaming_dict)
            .replace(renaming_dict)
        )

        g = sns.barplot(
            data=_plot_df, order=plot_order, x=x_label, y=y_label, hue="Attacker", ax=ax
        )
        g.legend(loc="center left", bbox_to_anchor=(1, 0.5))

    return table


def max_disparity_per_batch(df, additional_indices=None):
    def calc_max_disparity(gr):
        _max = np.max(np.subtract.outer(*[gr.values] * 2))
        return _max

    assert "vuln" in df.columns
    assert "subgroup" in df.columns

    if additional_indices is not None:
        _indices = ["vuln"] + additional_indices
    else:
        _indices = ["vuln"]

    _metrics_all = df
    _metrics_all["vuln"] = _metrics_all["vuln"].astype(int)

    # get vulnerability score for the batch per subgroup
    _average_vuln = _metrics_all.groupby(["subgroup"]).agg("mean")

    # calculate max disparity (which is one number per batch)
    _max_vuln_disparity = calc_max_disparity(_average_vuln["vuln"])

    return _max_vuln_disparity


def convert_max_disparity_to_wide(df):
    # pivot table to append discriminating and regular attacker tables horizontally
    _df = df.pivot_table(index=["model"], columns=["attacker"])

    # ordering and prettification
    _df.columns.names = [None, None, None]
    _df = _df.reorder_levels([2, 0, 1], axis=1)
    #     new_col_order = _df.columns.sort_values()
    new_col_order = pd.MultiIndex.from_tuples(
        [
            ("regular", "target_test_acc", "mean"),
            ("regular", "target_test_acc", "std"),
            ("regular", "overfitting_gap", "mean"),
            ("regular", "overfitting_gap", "std"),
            ("regular", "max_vuln_disparity", "mean"),
            ("regular", "max_vuln_disparity", "std"),
            ("regular", "vuln", "mean"),
            ("regular", "vuln", "std"),
            ("discriminating", "max_vuln_disparity", "mean"),
            ("discriminating", "max_vuln_disparity", "std"),
            ("discriminating", "vuln", "mean"),
            ("discriminating", "vuln", "std"),
        ]
    )
    _df = _df[new_col_order]

    # prettification
    _df.columns = pd.MultiIndex.from_tuples(
        [
            ("", "target_test_acc", "mean"),
            ("", "target_test_acc", "std"),
            ("", "overfitting_gap", "mean"),
            ("", "overfitting_gap", "std"),
            ("regular", "max_vuln_disparity", "mean"),
            ("regular", "max_vuln_disparity", "std"),
            ("regular", "vuln", "mean"),
            ("regular", "vuln", "std"),
            ("discriminating", "max_vuln_disparity", "mean"),
            ("discriminating", "max_vuln_disparity", "std"),
            ("discriminating", "vuln", "mean"),
            ("discriminating", "vuln", "std"),
        ]
    )

    return _df


def get_latex_table(df):
    df.index.name = None
    orig = "{} & \multicolumn{4}{l}{Regular} & \multicolumn{4}{l}{Discriminating}"
    replacement = "\multicolumn{5}{l}{} & \multicolumn{4}{l}{Regular} & \multicolumn{4}{l}{Discriminating}"
    return df.to_latex(index=True, escape=False).replace(orig, replacement)


def reset_weights(model):
    session = K.get_session()
    for layer in model.layers:
        if hasattr(layer, "kernel_initializer"):
            layer.kernel.initializer.run(session=session)
