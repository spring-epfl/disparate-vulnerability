import pandas as pd
import numpy as np
from functools import reduce

from sklearn.utils import resample
from keras import backend as K


def encode_dataframe(
    df,
    output_columns=None,
    ignore_cols=None,
    initially_drop_columns=None,
    finally_drop_columns=None,
    drop_first=True,
    add_non_dummified_columns=None,
    return_output_columns=False,
):
    if ignore_cols is None:
        ignore_cols = []
    if initially_drop_columns is not None:
        df = df.drop(initially_drop_columns, axis=1)

    df_ = pd.get_dummies(
        df,
        columns=[
            col
            for col in df.columns
            if col != "strat"
            and not pd.api.types.is_numeric_dtype(df.dtypes[col])
            and col not in ignore_cols
        ],
        drop_first=drop_first,
    )

    if add_non_dummified_columns is not None:
        keep_cols = df[add_non_dummified_columns]
        df_ = pd.concat([df_, keep_cols], axis=1)

    if output_columns is not None:
        df_ = df_.reindex(columns=output_columns, fill_value=0)

    if finally_drop_columns is not None:
        df_ = df_.drop(finally_drop_columns, axis=1)

    if return_output_columns:
        return df_, df_.columns.tolist()
    else:
        return df_


def assign_y(p_ser, thr):
    return (p_ser > thr).astype(int)


def calculate_measures(trn_df, tst_df, evl_df):
    thr2dfs = {thr: {} for thr in np.arange(0.01, 0.99, 0.01)}
    for thr in thr2dfs.keys():
        train_df = trn_df.copy()
        test_df = tst_df.copy()
        eval_df = evl_df.copy()
        train_df.loc[:, "yhat"] = assign_y(train_df["p"], thr)
        test_df.loc[:, "yhat"] = assign_y(test_df["p"], thr)
        eval_df.loc[:, "yhat"] = assign_y(eval_df["p"], thr)
        thr2dfs[thr]["train_df"] = train_df
        thr2dfs[thr]["test_df"] = test_df
        thr2dfs[thr]["eval_df"] = eval_df

    return thr2dfs


def metrics_dict_to_dataframe(metrics):
    return reduce(
        lambda df1, df2: pd.DataFrame.append(df1, df2),
        [df.assign(model=model_name) for model_name, df in metrics.items()],
    )


def balance_dataset(data_undummified, z_label, y_label, random_state=None):
    subgroups = data_undummified[z_label].value_counts().index.to_list()
    regroup_list = []

    for sg in subgroups:
        df_ = data_undummified.loc[data_undummified[z_label] == sg]
        counts = df_[y_label].value_counts().sort_values(ascending=True)
        min_count, min_group_label, maj_group_label = (
            counts.iloc[0],
            counts.index[0],
            counts.index[1],
        )
        # min_group = resample(df_.loc[df_[y_label] == min_group_label], n_samples=min_count, replace=False)
        min_group = df_.loc[df_[y_label] == min_group_label]
        maj_group = resample(
            df_.loc[df_[y_label] == maj_group_label],
            n_samples=min_count,
            replace=False,
            **({"random_state": random_state} if random_state is not None else {}),
        )
        _balanced_df = min_group.append(maj_group)
        regroup_list.append(_balanced_df)

    balanced_df = reduce(lambda df1, df2: pd.DataFrame.append(df1, df2), regroup_list)
    return balanced_df


def convert_max_disparity_to_wide(df):
    # pivot table to append discriminating and regular attacker tables horizontally
    _df = df.pivot_table(index=["model"], columns=["attacker"])

    # ordering and prettification
    _df.columns.names = [None, None, None]
    _df = _df.reorder_levels([2, 0, 1], axis=1)
    #     new_col_order = _df.columns.sort_values()
    new_col_order = pd.MultiIndex.from_tuples(
        [
            ("regular", "target_test_acc", "mean"),
            ("regular", "target_test_acc", "std"),
            ("regular", "overfitting_gap", "mean"),
            ("regular", "overfitting_gap", "std"),
            # ("regular", "max_vuln_disparity", "mean"),
            # ("regular", "max_vuln_disparity", "std"),
            ("regular", "vuln", "mean"),
            ("regular", "vuln", "std"),
            # ("discriminating", "max_vuln_disparity", "mean"),
            # ("discriminating", "max_vuln_disparity", "std"),
            ("discriminating", "vuln", "mean"),
            ("discriminating", "vuln", "std"),
        ]
    )
    _df = _df[new_col_order]

    # prettification
    _df.columns = pd.MultiIndex.from_tuples(
        [
            ("", "target_test_acc", "mean"),
            ("", "target_test_acc", "std"),
            ("", "overfitting_gap", "mean"),
            ("", "overfitting_gap", "std"),
            # ("regular", "max_vuln_disparity", "mean"),
            # ("regular", "max_vuln_disparity", "std"),
            ("regular", "vuln", "mean"),
            ("regular", "vuln", "std"),
            # ("discriminating", "max_vuln_disparity", "mean"),
            # ("discriminating", "max_vuln_disparity", "std"),
            ("discriminating", "vuln", "mean"),
            ("discriminating", "vuln", "std"),
        ]
    )

    return _df


def get_latex_table(df):
    df.index.name = None
    orig = "{} & \multicolumn{4}{l}{Regular} & \multicolumn{4}{l}{Discriminating}"
    replacement = "\multicolumn{5}{l}{} & \multicolumn{4}{l}{Regular} & \multicolumn{4}{l}{Discriminating}"
    return df.to_latex(index=True, escape=False).replace(orig, replacement)


def reset_weights(model):
    session = K.get_session()
    for layer in model.layers:
        if hasattr(layer, "kernel_initializer"):
            layer.kernel.initializer.run(session=session)


def insert_example_ids(metrics):
    if metrics.get("example_id") is not None:
        return metrics

    metrics = metrics.copy()
    metrics["example_id"] = range(len(metrics)) % (metrics.batch_no == 0).sum()
    metrics["example_id"] = metrics.example_id.astype(int)
    return metrics
