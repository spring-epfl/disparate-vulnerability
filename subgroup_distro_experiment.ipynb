{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subgroup Distibutions Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "from plot_utils import plot_stat_heatmaps, plot_vuln_dists\n",
    "from experiment import *\n",
    "from fixes import model_zoo, renaming_dict\n",
    "\n",
    "import plot_params\n",
    "\n",
    "from paper_commons import diagnostics\n",
    "from helpers import metrics_dict_to_dataframe, compute_p_matrices, max_disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from matplotlib import rc\n",
    "rc('text', usetex=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import math\n",
    "# import cv2\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "# import umap\n",
    "from PIL import Image\n",
    "from scipy import misc\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "from random import shuffle\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utkface import prepare_utkface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UTKFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, meta_data = prepare_utkface(\"data/UTKFace/\", \"data/UTKFace.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgroups = meta_data.race.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Indian', 'Black', 'Other', 'White', 'Asian'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample(meta_data, z_label, subgroups, random_state=None):\n",
    "    _data = meta_data.loc[meta_data[z_label].isin(subgroups)]\n",
    "    counts = _data.race.value_counts()\n",
    "    smallest_subgroup_size = counts.min()\n",
    "    state = np.random.RandomState(random_state) if random_state is not None else np.random.RandomState() \n",
    "    \n",
    "    train_idx_dict = {}\n",
    "    test_idx_dict = {}\n",
    "    for group in subgroups:\n",
    "        group_idx = state.choice(\n",
    "                _data.query(f\"{z_label} == '{group}'\").index, size=int(smallest_subgroup_size)).tolist()\n",
    "        \n",
    "        train_idx_dict[group] = group_idx[:int(smallest_subgroup_size/2)]\n",
    "        test_idx_dict[group] = group_idx[int(smallest_subgroup_size/2):]\n",
    "        \n",
    "    return train_idx_dict, test_idx_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx_dict, test_idx_dict = subsample(meta_data, \"race\", list(filter(lambda x: x != \"Other\", subgroups)), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1717, 1717), (1717, 1717), (1717, 1717), (1717, 1717)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(len(train_set), len(test_idx_dict[group])) for group, train_set in train_idx_dict.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 32)        8224      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 535,142\n",
      "Trainable params: 535,142\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clf = tf.keras.Sequential()\n",
    "\n",
    "clf.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(32,32,3))) \n",
    "clf.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "clf.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "clf.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "clf.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "clf.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "clf.add(tf.keras.layers.Flatten())\n",
    "clf.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "clf.add(tf.keras.layers.Dropout(0.5))\n",
    "clf.add(tf.keras.layers.Dense(6, activation='softmax'))\n",
    "\n",
    "# clf.compile(loss='sparse_categorical_crossentropy',\n",
    "#              optimizer='adam',\n",
    "#              metrics=['accuracy'])\n",
    "clf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"models/subgroup_disto_model_{}.h5\"\n",
    "fit_args = dict(batch_size=64, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes = [200, 500, 700, 1000, 1300, 1717]\n",
    "# train_sizes = [200]\n",
    "validation_ratio = 0.2\n",
    "reps = \n",
    "num_batches = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b36842c29d84ecebebdbb700a097764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 640 samples, validate on 160 samples\n",
      "Epoch 1/30\n",
      "640/640 [==============================] - 1s 1ms/sample - loss: 1.6815 - accuracy: 0.4062 - val_loss: 1.5922 - val_accuracy: 0.4313\n",
      "Epoch 2/30\n",
      "640/640 [==============================] - 0s 111us/sample - loss: 1.5926 - accuracy: 0.4313 - val_loss: 1.6159 - val_accuracy: 0.4313\n",
      "Epoch 3/30\n",
      "640/640 [==============================] - 0s 110us/sample - loss: 1.5774 - accuracy: 0.4313 - val_loss: 1.5983 - val_accuracy: 0.4313\n",
      "Epoch 4/30\n",
      "640/640 [==============================] - 0s 104us/sample - loss: 1.5740 - accuracy: 0.4313 - val_loss: 1.5957 - val_accuracy: 0.4313\n",
      "Epoch 5/30\n",
      "640/640 [==============================] - 0s 96us/sample - loss: 1.5669 - accuracy: 0.4313 - val_loss: 1.5986 - val_accuracy: 0.4313\n",
      "Epoch 6/30\n",
      "640/640 [==============================] - 0s 98us/sample - loss: 1.5724 - accuracy: 0.4313 - val_loss: 1.5991 - val_accuracy: 0.4313\n",
      "Epoch 7/30\n",
      "640/640 [==============================] - 0s 98us/sample - loss: 1.5700 - accuracy: 0.4313 - val_loss: 1.5969 - val_accuracy: 0.4313\n",
      "Epoch 8/30\n",
      "640/640 [==============================] - 0s 87us/sample - loss: 1.5724 - accuracy: 0.4313 - val_loss: 1.5941 - val_accuracy: 0.4313\n",
      "Epoch 9/30\n",
      "640/640 [==============================] - 0s 89us/sample - loss: 1.5685 - accuracy: 0.4313 - val_loss: 1.6016 - val_accuracy: 0.4313\n",
      "Epoch 10/30\n",
      "640/640 [==============================] - 0s 87us/sample - loss: 1.5619 - accuracy: 0.4313 - val_loss: 1.5941 - val_accuracy: 0.4313\n",
      "Epoch 11/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5634 - accuracy: 0.4313 - val_loss: 1.6078 - val_accuracy: 0.4313\n",
      "Epoch 12/30\n",
      "640/640 [==============================] - 0s 82us/sample - loss: 1.5916 - accuracy: 0.4313 - val_loss: 1.5990 - val_accuracy: 0.4313\n",
      "Epoch 13/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5699 - accuracy: 0.4313 - val_loss: 1.5977 - val_accuracy: 0.4313\n",
      "Epoch 14/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5838 - accuracy: 0.4313 - val_loss: 1.5946 - val_accuracy: 0.4313\n",
      "Epoch 15/30\n",
      "640/640 [==============================] - 0s 83us/sample - loss: 1.5691 - accuracy: 0.4313 - val_loss: 1.5978 - val_accuracy: 0.4313\n",
      "Epoch 16/30\n",
      "640/640 [==============================] - 0s 84us/sample - loss: 1.5792 - accuracy: 0.4313 - val_loss: 1.5942 - val_accuracy: 0.4313\n",
      "Epoch 17/30\n",
      "640/640 [==============================] - 0s 84us/sample - loss: 1.5650 - accuracy: 0.4313 - val_loss: 1.5950 - val_accuracy: 0.4313\n",
      "Epoch 18/30\n",
      "640/640 [==============================] - 0s 84us/sample - loss: 1.5688 - accuracy: 0.4313 - val_loss: 1.5955 - val_accuracy: 0.4313\n",
      "Epoch 19/30\n",
      "640/640 [==============================] - 0s 361us/sample - loss: 1.5635 - accuracy: 0.4313 - val_loss: 1.5921 - val_accuracy: 0.4313\n",
      "Epoch 20/30\n",
      "640/640 [==============================] - 0s 92us/sample - loss: 1.5687 - accuracy: 0.4313 - val_loss: 1.5932 - val_accuracy: 0.4313\n",
      "Epoch 21/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5815 - accuracy: 0.4313 - val_loss: 1.5926 - val_accuracy: 0.4313\n",
      "Epoch 22/30\n",
      "640/640 [==============================] - 0s 85us/sample - loss: 1.5640 - accuracy: 0.4313 - val_loss: 1.5934 - val_accuracy: 0.4313\n",
      "Epoch 23/30\n",
      "640/640 [==============================] - 0s 146us/sample - loss: 1.5668 - accuracy: 0.4313 - val_loss: 1.5917 - val_accuracy: 0.4313\n",
      "Epoch 24/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5675 - accuracy: 0.4313 - val_loss: 1.5933 - val_accuracy: 0.4313\n",
      "Epoch 25/30\n",
      "640/640 [==============================] - 0s 152us/sample - loss: 1.5689 - accuracy: 0.4313 - val_loss: 1.5905 - val_accuracy: 0.4313\n",
      "Epoch 26/30\n",
      "640/640 [==============================] - 0s 87us/sample - loss: 1.5681 - accuracy: 0.4313 - val_loss: 1.5925 - val_accuracy: 0.4313\n",
      "Epoch 27/30\n",
      "640/640 [==============================] - 0s 83us/sample - loss: 1.5602 - accuracy: 0.4313 - val_loss: 1.5910 - val_accuracy: 0.4313\n",
      "Epoch 28/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5582 - accuracy: 0.4313 - val_loss: 1.5913 - val_accuracy: 0.4313\n",
      "Epoch 29/30\n",
      "640/640 [==============================] - 0s 145us/sample - loss: 1.5640 - accuracy: 0.4313 - val_loss: 1.5896 - val_accuracy: 0.4313\n",
      "Epoch 30/30\n",
      "640/640 [==============================] - 0s 85us/sample - loss: 1.5590 - accuracy: 0.4313 - val_loss: 1.5916 - val_accuracy: 0.4313\n",
      "Train on 640 samples, validate on 160 samples\n",
      "Epoch 1/30\n",
      "640/640 [==============================] - 1s 1ms/sample - loss: 1.6965 - accuracy: 0.3969 - val_loss: 1.5889 - val_accuracy: 0.4313\n",
      "Epoch 2/30\n",
      "640/640 [==============================] - 0s 109us/sample - loss: 1.5854 - accuracy: 0.4313 - val_loss: 1.6297 - val_accuracy: 0.4313\n",
      "Epoch 3/30\n",
      "640/640 [==============================] - 0s 107us/sample - loss: 1.5802 - accuracy: 0.4313 - val_loss: 1.5947 - val_accuracy: 0.4313\n",
      "Epoch 4/30\n",
      "640/640 [==============================] - 0s 106us/sample - loss: 1.5630 - accuracy: 0.4313 - val_loss: 1.5992 - val_accuracy: 0.4313\n",
      "Epoch 5/30\n",
      "640/640 [==============================] - 0s 93us/sample - loss: 1.5853 - accuracy: 0.4313 - val_loss: 1.5924 - val_accuracy: 0.4313\n",
      "Epoch 6/30\n",
      "640/640 [==============================] - 0s 95us/sample - loss: 1.5695 - accuracy: 0.4313 - val_loss: 1.5985 - val_accuracy: 0.4313\n",
      "Epoch 7/30\n",
      "640/640 [==============================] - 0s 94us/sample - loss: 1.5664 - accuracy: 0.4313 - val_loss: 1.5959 - val_accuracy: 0.4313\n",
      "Epoch 8/30\n",
      "640/640 [==============================] - 0s 91us/sample - loss: 1.5674 - accuracy: 0.4313 - val_loss: 1.5982 - val_accuracy: 0.4313\n",
      "Epoch 9/30\n",
      "640/640 [==============================] - 0s 88us/sample - loss: 1.5721 - accuracy: 0.4313 - val_loss: 1.6021 - val_accuracy: 0.4313\n",
      "Epoch 10/30\n",
      "640/640 [==============================] - 0s 87us/sample - loss: 1.5630 - accuracy: 0.4313 - val_loss: 1.5946 - val_accuracy: 0.4313\n",
      "Epoch 11/30\n",
      "640/640 [==============================] - 0s 90us/sample - loss: 1.5763 - accuracy: 0.4313 - val_loss: 1.6060 - val_accuracy: 0.4313\n",
      "Epoch 12/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5755 - accuracy: 0.4313 - val_loss: 1.5896 - val_accuracy: 0.4313\n",
      "Epoch 13/30\n",
      "640/640 [==============================] - 0s 85us/sample - loss: 1.5809 - accuracy: 0.4313 - val_loss: 1.5934 - val_accuracy: 0.4313\n",
      "Epoch 14/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5681 - accuracy: 0.4313 - val_loss: 1.5950 - val_accuracy: 0.4313\n",
      "Epoch 15/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5728 - accuracy: 0.4313 - val_loss: 1.5981 - val_accuracy: 0.4313\n",
      "Epoch 16/30\n",
      "640/640 [==============================] - 0s 88us/sample - loss: 1.5662 - accuracy: 0.4313 - val_loss: 1.5959 - val_accuracy: 0.4313\n",
      "Epoch 17/30\n",
      "640/640 [==============================] - 0s 88us/sample - loss: 1.5654 - accuracy: 0.4313 - val_loss: 1.5923 - val_accuracy: 0.4313\n",
      "Epoch 18/30\n",
      "640/640 [==============================] - 0s 88us/sample - loss: 1.5742 - accuracy: 0.4313 - val_loss: 1.5928 - val_accuracy: 0.4313\n",
      "Epoch 19/30\n",
      "640/640 [==============================] - 0s 88us/sample - loss: 1.5593 - accuracy: 0.4313 - val_loss: 1.5906 - val_accuracy: 0.4313\n",
      "Epoch 20/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5601 - accuracy: 0.4313 - val_loss: 1.6006 - val_accuracy: 0.4313\n",
      "Epoch 21/30\n",
      "640/640 [==============================] - 0s 83us/sample - loss: 1.5696 - accuracy: 0.4313 - val_loss: 1.5933 - val_accuracy: 0.4313\n",
      "Epoch 22/30\n",
      "640/640 [==============================] - 0s 84us/sample - loss: 1.5721 - accuracy: 0.4313 - val_loss: 1.5936 - val_accuracy: 0.4313\n",
      "Epoch 23/30\n",
      "640/640 [==============================] - 0s 83us/sample - loss: 1.5668 - accuracy: 0.4313 - val_loss: 1.5956 - val_accuracy: 0.4313\n",
      "Epoch 24/30\n",
      "640/640 [==============================] - 0s 82us/sample - loss: 1.5702 - accuracy: 0.4313 - val_loss: 1.5915 - val_accuracy: 0.4313\n",
      "Epoch 25/30\n",
      "640/640 [==============================] - 0s 84us/sample - loss: 1.5656 - accuracy: 0.4313 - val_loss: 1.5930 - val_accuracy: 0.4313\n",
      "Epoch 26/30\n",
      "640/640 [==============================] - 0s 226us/sample - loss: 1.5667 - accuracy: 0.4313 - val_loss: 1.5885 - val_accuracy: 0.4313\n",
      "Epoch 27/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5622 - accuracy: 0.4313 - val_loss: 1.5902 - val_accuracy: 0.4313\n",
      "Epoch 28/30\n",
      "640/640 [==============================] - 0s 83us/sample - loss: 1.5609 - accuracy: 0.4313 - val_loss: 1.5889 - val_accuracy: 0.4313\n",
      "Epoch 29/30\n",
      "640/640 [==============================] - 0s 84us/sample - loss: 1.5724 - accuracy: 0.4313 - val_loss: 1.5915 - val_accuracy: 0.4313\n",
      "Epoch 30/30\n",
      "640/640 [==============================] - 0s 202us/sample - loss: 1.5592 - accuracy: 0.4313 - val_loss: 1.5881 - val_accuracy: 0.4313\n",
      "Train on 640 samples, validate on 160 samples\n",
      "Epoch 1/30\n",
      "640/640 [==============================] - 1s 970us/sample - loss: 1.6947 - accuracy: 0.4078 - val_loss: 1.5960 - val_accuracy: 0.4313\n",
      "Epoch 2/30\n",
      "640/640 [==============================] - 0s 115us/sample - loss: 1.5650 - accuracy: 0.4313 - val_loss: 1.6225 - val_accuracy: 0.4313\n",
      "Epoch 3/30\n",
      "640/640 [==============================] - 0s 167us/sample - loss: 1.5823 - accuracy: 0.4313 - val_loss: 1.5939 - val_accuracy: 0.4313\n",
      "Epoch 4/30\n",
      "640/640 [==============================] - 0s 109us/sample - loss: 1.5718 - accuracy: 0.4313 - val_loss: 1.5962 - val_accuracy: 0.4313\n",
      "Epoch 5/30\n",
      "640/640 [==============================] - 0s 106us/sample - loss: 1.5767 - accuracy: 0.4313 - val_loss: 1.6018 - val_accuracy: 0.4313\n",
      "Epoch 6/30\n",
      "640/640 [==============================] - 0s 102us/sample - loss: 1.5678 - accuracy: 0.4313 - val_loss: 1.5939 - val_accuracy: 0.4313\n",
      "Epoch 7/30\n",
      "640/640 [==============================] - 0s 101us/sample - loss: 1.5677 - accuracy: 0.4313 - val_loss: 1.6028 - val_accuracy: 0.4313\n",
      "Epoch 8/30\n",
      "640/640 [==============================] - 0s 164us/sample - loss: 1.5692 - accuracy: 0.4313 - val_loss: 1.5906 - val_accuracy: 0.4313\n",
      "Epoch 9/30\n",
      "640/640 [==============================] - 0s 94us/sample - loss: 1.5793 - accuracy: 0.4313 - val_loss: 1.6058 - val_accuracy: 0.4313\n",
      "Epoch 10/30\n",
      "640/640 [==============================] - 0s 92us/sample - loss: 1.5644 - accuracy: 0.4313 - val_loss: 1.5944 - val_accuracy: 0.4313\n",
      "Epoch 11/30\n",
      "640/640 [==============================] - 0s 93us/sample - loss: 1.5810 - accuracy: 0.4313 - val_loss: 1.5951 - val_accuracy: 0.4313\n",
      "Epoch 12/30\n",
      "640/640 [==============================] - 0s 94us/sample - loss: 1.5656 - accuracy: 0.4313 - val_loss: 1.5970 - val_accuracy: 0.4313\n",
      "Epoch 13/30\n",
      "640/640 [==============================] - 0s 89us/sample - loss: 1.5745 - accuracy: 0.4313 - val_loss: 1.5962 - val_accuracy: 0.4313\n",
      "Epoch 14/30\n",
      "640/640 [==============================] - 0s 90us/sample - loss: 1.5636 - accuracy: 0.4313 - val_loss: 1.5948 - val_accuracy: 0.4313\n",
      "Epoch 15/30\n",
      "640/640 [==============================] - 0s 148us/sample - loss: 1.5671 - accuracy: 0.4313 - val_loss: 1.5902 - val_accuracy: 0.4313\n",
      "Epoch 16/30\n",
      "640/640 [==============================] - 0s 87us/sample - loss: 1.5731 - accuracy: 0.4313 - val_loss: 1.5993 - val_accuracy: 0.4313\n",
      "Epoch 17/30\n",
      "640/640 [==============================] - 0s 85us/sample - loss: 1.5651 - accuracy: 0.4313 - val_loss: 1.5907 - val_accuracy: 0.4313\n",
      "Epoch 18/30\n",
      "640/640 [==============================] - 0s 144us/sample - loss: 1.5694 - accuracy: 0.4313 - val_loss: 1.5889 - val_accuracy: 0.4313\n",
      "Epoch 19/30\n",
      "640/640 [==============================] - 0s 87us/sample - loss: 1.5593 - accuracy: 0.4313 - val_loss: 1.5903 - val_accuracy: 0.4313\n",
      "Epoch 20/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5678 - accuracy: 0.4313 - val_loss: 1.5905 - val_accuracy: 0.4313\n",
      "Epoch 21/30\n",
      "640/640 [==============================] - 0s 85us/sample - loss: 1.5658 - accuracy: 0.4313 - val_loss: 1.5897 - val_accuracy: 0.4313\n",
      "Epoch 22/30\n",
      "640/640 [==============================] - 0s 89us/sample - loss: 1.5707 - accuracy: 0.4313 - val_loss: 1.5992 - val_accuracy: 0.4313\n",
      "Epoch 23/30\n",
      "640/640 [==============================] - 0s 87us/sample - loss: 1.5767 - accuracy: 0.4313 - val_loss: 1.5909 - val_accuracy: 0.4313\n",
      "Epoch 24/30\n",
      "640/640 [==============================] - 0s 85us/sample - loss: 1.5588 - accuracy: 0.4313 - val_loss: 1.5910 - val_accuracy: 0.4313\n",
      "Epoch 25/30\n",
      "640/640 [==============================] - 0s 148us/sample - loss: 1.5700 - accuracy: 0.4313 - val_loss: 1.5889 - val_accuracy: 0.4313\n",
      "Epoch 26/30\n",
      "640/640 [==============================] - 0s 87us/sample - loss: 1.5539 - accuracy: 0.4313 - val_loss: 1.5898 - val_accuracy: 0.4313\n",
      "Epoch 27/30\n",
      "640/640 [==============================] - 0s 257us/sample - loss: 1.5679 - accuracy: 0.4313 - val_loss: 1.5845 - val_accuracy: 0.4313\n",
      "Epoch 28/30\n",
      "640/640 [==============================] - 0s 88us/sample - loss: 1.5522 - accuracy: 0.4313 - val_loss: 1.5871 - val_accuracy: 0.4313\n",
      "Epoch 29/30\n",
      "640/640 [==============================] - 0s 270us/sample - loss: 1.5647 - accuracy: 0.4313 - val_loss: 1.5843 - val_accuracy: 0.4313\n",
      "Epoch 30/30\n",
      "640/640 [==============================] - 0s 314us/sample - loss: 1.5523 - accuracy: 0.4313 - val_loss: 1.5824 - val_accuracy: 0.4313\n",
      "Train on 640 samples, validate on 160 samples\n",
      "Epoch 1/30\n",
      "640/640 [==============================] - 1s 1ms/sample - loss: 1.6892 - accuracy: 0.4094 - val_loss: 1.6036 - val_accuracy: 0.4313\n",
      "Epoch 2/30\n",
      "640/640 [==============================] - 0s 114us/sample - loss: 1.5896 - accuracy: 0.4313 - val_loss: 1.6184 - val_accuracy: 0.4313\n",
      "Epoch 3/30\n",
      "640/640 [==============================] - 0s 169us/sample - loss: 1.5751 - accuracy: 0.4313 - val_loss: 1.5945 - val_accuracy: 0.4313\n",
      "Epoch 4/30\n",
      "640/640 [==============================] - 0s 112us/sample - loss: 1.5680 - accuracy: 0.4313 - val_loss: 1.6012 - val_accuracy: 0.4313\n",
      "Epoch 5/30\n",
      "640/640 [==============================] - 0s 103us/sample - loss: 1.5673 - accuracy: 0.4313 - val_loss: 1.5961 - val_accuracy: 0.4313\n",
      "Epoch 6/30\n",
      "640/640 [==============================] - 0s 105us/sample - loss: 1.5654 - accuracy: 0.4313 - val_loss: 1.5971 - val_accuracy: 0.4313\n",
      "Epoch 7/30\n",
      "640/640 [==============================] - 0s 162us/sample - loss: 1.5601 - accuracy: 0.4313 - val_loss: 1.5921 - val_accuracy: 0.4313\n",
      "Epoch 8/30\n",
      "640/640 [==============================] - 0s 97us/sample - loss: 1.5767 - accuracy: 0.4313 - val_loss: 1.5965 - val_accuracy: 0.4313\n",
      "Epoch 9/30\n",
      "640/640 [==============================] - 0s 95us/sample - loss: 1.5689 - accuracy: 0.4313 - val_loss: 1.5994 - val_accuracy: 0.4313\n",
      "Epoch 10/30\n",
      "640/640 [==============================] - 0s 93us/sample - loss: 1.5753 - accuracy: 0.4313 - val_loss: 1.6006 - val_accuracy: 0.4313\n",
      "Epoch 11/30\n",
      "640/640 [==============================] - 0s 155us/sample - loss: 1.5680 - accuracy: 0.4313 - val_loss: 1.5908 - val_accuracy: 0.4313\n",
      "Epoch 12/30\n",
      "640/640 [==============================] - 0s 91us/sample - loss: 1.5728 - accuracy: 0.4313 - val_loss: 1.6007 - val_accuracy: 0.4313\n",
      "Epoch 13/30\n",
      "640/640 [==============================] - 0s 91us/sample - loss: 1.5711 - accuracy: 0.4313 - val_loss: 1.5952 - val_accuracy: 0.4313\n",
      "Epoch 14/30\n",
      "640/640 [==============================] - 0s 89us/sample - loss: 1.5679 - accuracy: 0.4313 - val_loss: 1.5962 - val_accuracy: 0.4313\n",
      "Epoch 15/30\n",
      "640/640 [==============================] - 0s 88us/sample - loss: 1.5697 - accuracy: 0.4313 - val_loss: 1.5942 - val_accuracy: 0.4313\n",
      "Epoch 16/30\n",
      "640/640 [==============================] - 0s 87us/sample - loss: 1.5778 - accuracy: 0.4313 - val_loss: 1.5937 - val_accuracy: 0.4313\n",
      "Epoch 17/30\n",
      "640/640 [==============================] - 0s 88us/sample - loss: 1.5796 - accuracy: 0.4313 - val_loss: 1.5981 - val_accuracy: 0.4313\n",
      "Epoch 18/30\n",
      "640/640 [==============================] - 0s 84us/sample - loss: 1.5640 - accuracy: 0.4313 - val_loss: 1.5929 - val_accuracy: 0.4313\n",
      "Epoch 19/30\n",
      "640/640 [==============================] - 0s 87us/sample - loss: 1.5655 - accuracy: 0.4313 - val_loss: 1.5915 - val_accuracy: 0.4313\n",
      "Epoch 20/30\n",
      "640/640 [==============================] - 0s 87us/sample - loss: 1.5674 - accuracy: 0.4313 - val_loss: 1.5938 - val_accuracy: 0.4313\n",
      "Epoch 21/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5667 - accuracy: 0.4313 - val_loss: 1.5948 - val_accuracy: 0.4313\n",
      "Epoch 22/30\n",
      "640/640 [==============================] - 0s 161us/sample - loss: 1.5620 - accuracy: 0.4313 - val_loss: 1.5887 - val_accuracy: 0.4313\n",
      "Epoch 23/30\n",
      "640/640 [==============================] - 0s 85us/sample - loss: 1.5656 - accuracy: 0.4313 - val_loss: 1.5898 - val_accuracy: 0.4313\n",
      "Epoch 24/30\n",
      "640/640 [==============================] - 0s 87us/sample - loss: 1.5595 - accuracy: 0.4313 - val_loss: 1.5926 - val_accuracy: 0.4313\n",
      "Epoch 25/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5643 - accuracy: 0.4313 - val_loss: 1.5896 - val_accuracy: 0.4313\n",
      "Epoch 26/30\n",
      "640/640 [==============================] - 0s 85us/sample - loss: 1.5683 - accuracy: 0.4313 - val_loss: 1.6095 - val_accuracy: 0.4313\n",
      "Epoch 27/30\n",
      "640/640 [==============================] - 0s 157us/sample - loss: 1.5602 - accuracy: 0.4313 - val_loss: 1.5862 - val_accuracy: 0.4313\n",
      "Epoch 28/30\n",
      "640/640 [==============================] - 0s 87us/sample - loss: 1.5600 - accuracy: 0.4313 - val_loss: 1.5955 - val_accuracy: 0.4313\n",
      "Epoch 29/30\n",
      "640/640 [==============================] - 0s 366us/sample - loss: 1.5656 - accuracy: 0.4313 - val_loss: 1.5800 - val_accuracy: 0.4313\n",
      "Epoch 30/30\n",
      "640/640 [==============================] - 0s 88us/sample - loss: 1.5544 - accuracy: 0.4313 - val_loss: 1.5806 - val_accuracy: 0.4313\n",
      "Train on 640 samples, validate on 160 samples\n",
      "Epoch 1/30\n",
      "640/640 [==============================] - 1s 1ms/sample - loss: 1.6907 - accuracy: 0.4000 - val_loss: 1.6039 - val_accuracy: 0.4313\n",
      "Epoch 2/30\n",
      "640/640 [==============================] - 0s 112us/sample - loss: 1.5850 - accuracy: 0.4313 - val_loss: 1.6274 - val_accuracy: 0.4313\n",
      "Epoch 3/30\n",
      "640/640 [==============================] - 0s 167us/sample - loss: 1.5834 - accuracy: 0.4313 - val_loss: 1.6022 - val_accuracy: 0.4313\n",
      "Epoch 4/30\n",
      "640/640 [==============================] - 0s 166us/sample - loss: 1.5733 - accuracy: 0.4313 - val_loss: 1.5996 - val_accuracy: 0.4313\n",
      "Epoch 5/30\n",
      "640/640 [==============================] - 0s 164us/sample - loss: 1.5721 - accuracy: 0.4313 - val_loss: 1.5924 - val_accuracy: 0.4313\n",
      "Epoch 6/30\n",
      "640/640 [==============================] - 0s 164us/sample - loss: 1.5695 - accuracy: 0.4313 - val_loss: 1.5920 - val_accuracy: 0.4313\n",
      "Epoch 7/30\n",
      "640/640 [==============================] - 0s 108us/sample - loss: 1.5712 - accuracy: 0.4313 - val_loss: 1.6001 - val_accuracy: 0.4313\n",
      "Epoch 8/30\n",
      "640/640 [==============================] - 0s 192us/sample - loss: 1.5789 - accuracy: 0.4313 - val_loss: 1.5918 - val_accuracy: 0.4313\n",
      "Epoch 9/30\n",
      "640/640 [==============================] - 0s 99us/sample - loss: 1.5764 - accuracy: 0.4313 - val_loss: 1.6016 - val_accuracy: 0.4313\n",
      "Epoch 10/30\n",
      "640/640 [==============================] - 0s 101us/sample - loss: 1.5786 - accuracy: 0.4313 - val_loss: 1.5956 - val_accuracy: 0.4313\n",
      "Epoch 11/30\n",
      "640/640 [==============================] - 0s 99us/sample - loss: 1.5634 - accuracy: 0.4313 - val_loss: 1.5947 - val_accuracy: 0.4313\n",
      "Epoch 12/30\n",
      "640/640 [==============================] - 0s 159us/sample - loss: 1.5689 - accuracy: 0.4313 - val_loss: 1.5906 - val_accuracy: 0.4313\n",
      "Epoch 13/30\n",
      "640/640 [==============================] - 0s 97us/sample - loss: 1.5637 - accuracy: 0.4313 - val_loss: 1.5941 - val_accuracy: 0.4313\n",
      "Epoch 14/30\n",
      "640/640 [==============================] - 0s 94us/sample - loss: 1.5719 - accuracy: 0.4313 - val_loss: 1.5970 - val_accuracy: 0.4313\n",
      "Epoch 15/30\n",
      "640/640 [==============================] - 0s 97us/sample - loss: 1.5649 - accuracy: 0.4313 - val_loss: 1.5958 - val_accuracy: 0.4313\n",
      "Epoch 16/30\n",
      "640/640 [==============================] - 0s 90us/sample - loss: 1.5650 - accuracy: 0.4313 - val_loss: 1.5926 - val_accuracy: 0.4313\n",
      "Epoch 17/30\n",
      "640/640 [==============================] - 0s 91us/sample - loss: 1.5633 - accuracy: 0.4313 - val_loss: 1.5951 - val_accuracy: 0.4313\n",
      "Epoch 18/30\n",
      "640/640 [==============================] - 0s 89us/sample - loss: 1.5748 - accuracy: 0.4313 - val_loss: 1.5909 - val_accuracy: 0.4313\n",
      "Epoch 19/30\n",
      "640/640 [==============================] - 0s 89us/sample - loss: 1.5640 - accuracy: 0.4313 - val_loss: 1.5911 - val_accuracy: 0.4313\n",
      "Epoch 20/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5654 - accuracy: 0.4313 - val_loss: 1.5941 - val_accuracy: 0.4313\n",
      "Epoch 21/30\n",
      "640/640 [==============================] - 0s 85us/sample - loss: 1.5665 - accuracy: 0.4313 - val_loss: 1.5938 - val_accuracy: 0.4313\n",
      "Epoch 22/30\n",
      "640/640 [==============================] - 0s 87us/sample - loss: 1.5696 - accuracy: 0.4313 - val_loss: 1.5929 - val_accuracy: 0.4313\n",
      "Epoch 23/30\n",
      "640/640 [==============================] - 0s 87us/sample - loss: 1.5715 - accuracy: 0.4313 - val_loss: 1.5957 - val_accuracy: 0.4313\n",
      "Epoch 24/30\n",
      "640/640 [==============================] - 0s 87us/sample - loss: 1.5657 - accuracy: 0.4313 - val_loss: 1.5909 - val_accuracy: 0.4313\n",
      "Epoch 25/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5651 - accuracy: 0.4313 - val_loss: 1.5907 - val_accuracy: 0.4313\n",
      "Epoch 26/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5591 - accuracy: 0.4313 - val_loss: 1.5938 - val_accuracy: 0.4313\n",
      "Epoch 27/30\n",
      "640/640 [==============================] - 0s 83us/sample - loss: 1.5691 - accuracy: 0.4313 - val_loss: 1.5947 - val_accuracy: 0.4313\n",
      "Epoch 28/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5663 - accuracy: 0.4313 - val_loss: 1.5928 - val_accuracy: 0.4313\n",
      "Epoch 29/30\n",
      "640/640 [==============================] - 0s 83us/sample - loss: 1.5599 - accuracy: 0.4313 - val_loss: 1.5930 - val_accuracy: 0.4313\n",
      "Epoch 30/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5602 - accuracy: 0.4313 - val_loss: 1.5922 - val_accuracy: 0.4313\n",
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1183b1f8da4d45938e26a9d6bcaa52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/30\n",
      "1600/1600 [==============================] - 1s 737us/sample - loss: 1.6282 - accuracy: 0.4187 - val_loss: 1.5663 - val_accuracy: 0.4500\n",
      "Epoch 2/30\n",
      "1600/1600 [==============================] - 0s 255us/sample - loss: 1.5621 - accuracy: 0.4331 - val_loss: 1.5376 - val_accuracy: 0.4500\n",
      "Epoch 3/30\n",
      "1600/1600 [==============================] - 0s 243us/sample - loss: 1.5644 - accuracy: 0.4331 - val_loss: 1.5348 - val_accuracy: 0.4500\n",
      "Epoch 4/30\n",
      "1600/1600 [==============================] - 0s 102us/sample - loss: 1.5588 - accuracy: 0.4331 - val_loss: 1.5357 - val_accuracy: 0.4500\n",
      "Epoch 5/30\n",
      "1600/1600 [==============================] - 0s 99us/sample - loss: 1.5642 - accuracy: 0.4331 - val_loss: 1.5353 - val_accuracy: 0.4500\n",
      "Epoch 6/30\n",
      "1600/1600 [==============================] - 0s 86us/sample - loss: 1.5611 - accuracy: 0.4331 - val_loss: 1.5568 - val_accuracy: 0.4500\n",
      "Epoch 7/30\n",
      "1600/1600 [==============================] - 0s 82us/sample - loss: 1.5608 - accuracy: 0.4331 - val_loss: 1.5400 - val_accuracy: 0.4500\n",
      "Epoch 8/30\n",
      "1600/1600 [==============================] - 0s 79us/sample - loss: 1.5580 - accuracy: 0.4331 - val_loss: 1.5375 - val_accuracy: 0.4500\n",
      "Epoch 9/30\n",
      "1600/1600 [==============================] - 0s 244us/sample - loss: 1.5648 - accuracy: 0.4331 - val_loss: 1.5345 - val_accuracy: 0.4500\n",
      "Epoch 10/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5558 - accuracy: 0.4331 - val_loss: 1.5606 - val_accuracy: 0.4500\n",
      "Epoch 11/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5589 - accuracy: 0.4331 - val_loss: 1.5553 - val_accuracy: 0.4500\n",
      "Epoch 12/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5569 - accuracy: 0.4331 - val_loss: 1.5402 - val_accuracy: 0.4500\n",
      "Epoch 13/30\n",
      "1600/1600 [==============================] - 0s 75us/sample - loss: 1.5566 - accuracy: 0.4331 - val_loss: 1.5519 - val_accuracy: 0.4500\n",
      "Epoch 14/30\n",
      "1600/1600 [==============================] - 0s 226us/sample - loss: 1.5519 - accuracy: 0.4331 - val_loss: 1.5333 - val_accuracy: 0.4500\n",
      "Epoch 15/30\n",
      "1600/1600 [==============================] - 0s 254us/sample - loss: 1.5481 - accuracy: 0.4331 - val_loss: 1.5236 - val_accuracy: 0.4500\n",
      "Epoch 16/30\n",
      "1600/1600 [==============================] - 0s 79us/sample - loss: 1.5539 - accuracy: 0.4331 - val_loss: 1.5495 - val_accuracy: 0.4500\n",
      "Epoch 17/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5462 - accuracy: 0.4331 - val_loss: 1.5262 - val_accuracy: 0.4500\n",
      "Epoch 18/30\n",
      "1600/1600 [==============================] - 0s 216us/sample - loss: 1.5314 - accuracy: 0.4331 - val_loss: 1.4970 - val_accuracy: 0.4500\n",
      "Epoch 19/30\n",
      "1600/1600 [==============================] - 0s 241us/sample - loss: 1.5170 - accuracy: 0.4344 - val_loss: 1.4811 - val_accuracy: 0.4500\n",
      "Epoch 20/30\n",
      "1600/1600 [==============================] - 0s 218us/sample - loss: 1.4932 - accuracy: 0.4469 - val_loss: 1.4623 - val_accuracy: 0.4800\n",
      "Epoch 21/30\n",
      "1600/1600 [==============================] - 0s 222us/sample - loss: 1.4784 - accuracy: 0.4581 - val_loss: 1.4444 - val_accuracy: 0.4875\n",
      "Epoch 22/30\n",
      "1600/1600 [==============================] - 0s 78us/sample - loss: 1.4771 - accuracy: 0.4544 - val_loss: 1.4576 - val_accuracy: 0.4775\n",
      "Epoch 23/30\n",
      "1600/1600 [==============================] - 0s 225us/sample - loss: 1.4668 - accuracy: 0.4588 - val_loss: 1.4272 - val_accuracy: 0.4900\n",
      "Epoch 24/30\n",
      "1600/1600 [==============================] - 0s 224us/sample - loss: 1.4659 - accuracy: 0.4581 - val_loss: 1.4265 - val_accuracy: 0.4900\n",
      "Epoch 25/30\n",
      "1600/1600 [==============================] - 0s 79us/sample - loss: 1.4546 - accuracy: 0.4650 - val_loss: 1.4389 - val_accuracy: 0.4800\n",
      "Epoch 26/30\n",
      "1600/1600 [==============================] - 0s 215us/sample - loss: 1.4272 - accuracy: 0.4781 - val_loss: 1.4055 - val_accuracy: 0.4875\n",
      "Epoch 27/30\n",
      "1600/1600 [==============================] - 0s 226us/sample - loss: 1.4203 - accuracy: 0.4756 - val_loss: 1.3968 - val_accuracy: 0.4750\n",
      "Epoch 28/30\n",
      "1600/1600 [==============================] - 0s 243us/sample - loss: 1.4226 - accuracy: 0.4644 - val_loss: 1.3840 - val_accuracy: 0.4875\n",
      "Epoch 29/30\n",
      "1600/1600 [==============================] - 0s 218us/sample - loss: 1.4128 - accuracy: 0.4769 - val_loss: 1.3790 - val_accuracy: 0.4925\n",
      "Epoch 30/30\n",
      "1600/1600 [==============================] - 0s 222us/sample - loss: 1.3996 - accuracy: 0.4781 - val_loss: 1.3629 - val_accuracy: 0.4975\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/30\n",
      "1600/1600 [==============================] - 1s 514us/sample - loss: 1.6139 - accuracy: 0.4244 - val_loss: 1.5492 - val_accuracy: 0.4500\n",
      "Epoch 2/30\n",
      "1600/1600 [==============================] - 0s 126us/sample - loss: 1.5700 - accuracy: 0.4331 - val_loss: 1.5406 - val_accuracy: 0.4500\n",
      "Epoch 3/30\n",
      "1600/1600 [==============================] - 0s 116us/sample - loss: 1.5604 - accuracy: 0.4331 - val_loss: 1.5361 - val_accuracy: 0.4500\n",
      "Epoch 4/30\n",
      "1600/1600 [==============================] - 0s 87us/sample - loss: 1.5594 - accuracy: 0.4331 - val_loss: 1.5368 - val_accuracy: 0.4500\n",
      "Epoch 5/30\n",
      "1600/1600 [==============================] - 0s 107us/sample - loss: 1.5589 - accuracy: 0.4331 - val_loss: 1.5350 - val_accuracy: 0.4500\n",
      "Epoch 6/30\n",
      "1600/1600 [==============================] - 0s 79us/sample - loss: 1.5625 - accuracy: 0.4331 - val_loss: 1.5395 - val_accuracy: 0.4500\n",
      "Epoch 7/30\n",
      "1600/1600 [==============================] - 0s 102us/sample - loss: 1.5561 - accuracy: 0.4331 - val_loss: 1.5323 - val_accuracy: 0.4500\n",
      "Epoch 8/30\n",
      "1600/1600 [==============================] - 0s 76us/sample - loss: 1.5611 - accuracy: 0.4331 - val_loss: 1.5497 - val_accuracy: 0.4500\n",
      "Epoch 9/30\n",
      "1600/1600 [==============================] - 0s 76us/sample - loss: 1.5546 - accuracy: 0.4331 - val_loss: 1.5361 - val_accuracy: 0.4500\n",
      "Epoch 10/30\n",
      "1600/1600 [==============================] - 0s 104us/sample - loss: 1.5668 - accuracy: 0.4331 - val_loss: 1.5311 - val_accuracy: 0.4500\n",
      "Epoch 11/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5555 - accuracy: 0.4331 - val_loss: 1.5447 - val_accuracy: 0.4500\n",
      "Epoch 12/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5573 - accuracy: 0.4331 - val_loss: 1.5432 - val_accuracy: 0.4500\n",
      "Epoch 13/30\n",
      "1600/1600 [==============================] - 0s 76us/sample - loss: 1.5564 - accuracy: 0.4331 - val_loss: 1.5396 - val_accuracy: 0.4500\n",
      "Epoch 14/30\n",
      "1600/1600 [==============================] - 0s 76us/sample - loss: 1.5531 - accuracy: 0.4331 - val_loss: 1.5350 - val_accuracy: 0.4500\n",
      "Epoch 15/30\n",
      "1600/1600 [==============================] - 0s 76us/sample - loss: 1.5488 - accuracy: 0.4331 - val_loss: 1.5370 - val_accuracy: 0.4500\n",
      "Epoch 16/30\n",
      "1600/1600 [==============================] - 0s 103us/sample - loss: 1.5518 - accuracy: 0.4331 - val_loss: 1.5239 - val_accuracy: 0.4500\n",
      "Epoch 17/30\n",
      "1600/1600 [==============================] - 0s 101us/sample - loss: 1.5405 - accuracy: 0.4331 - val_loss: 1.5123 - val_accuracy: 0.4500\n",
      "Epoch 18/30\n",
      "1600/1600 [==============================] - 0s 103us/sample - loss: 1.5325 - accuracy: 0.4331 - val_loss: 1.5029 - val_accuracy: 0.4500\n",
      "Epoch 19/30\n",
      "1600/1600 [==============================] - 0s 106us/sample - loss: 1.5235 - accuracy: 0.4331 - val_loss: 1.4977 - val_accuracy: 0.4500\n",
      "Epoch 20/30\n",
      "1600/1600 [==============================] - 0s 102us/sample - loss: 1.5115 - accuracy: 0.4356 - val_loss: 1.4753 - val_accuracy: 0.4500\n",
      "Epoch 21/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.4947 - accuracy: 0.4494 - val_loss: 1.4797 - val_accuracy: 0.4850\n",
      "Epoch 22/30\n",
      "1600/1600 [==============================] - 0s 101us/sample - loss: 1.4942 - accuracy: 0.4531 - val_loss: 1.4532 - val_accuracy: 0.4900\n",
      "Epoch 23/30\n",
      "1600/1600 [==============================] - 0s 101us/sample - loss: 1.4726 - accuracy: 0.4588 - val_loss: 1.4403 - val_accuracy: 0.4900\n",
      "Epoch 24/30\n",
      "1600/1600 [==============================] - 0s 76us/sample - loss: 1.4600 - accuracy: 0.4656 - val_loss: 1.4476 - val_accuracy: 0.4825\n",
      "Epoch 25/30\n",
      "1600/1600 [==============================] - 0s 103us/sample - loss: 1.4407 - accuracy: 0.4625 - val_loss: 1.4391 - val_accuracy: 0.4700\n",
      "Epoch 26/30\n",
      "1600/1600 [==============================] - 0s 102us/sample - loss: 1.4434 - accuracy: 0.4712 - val_loss: 1.4273 - val_accuracy: 0.4875\n",
      "Epoch 27/30\n",
      "1600/1600 [==============================] - 0s 78us/sample - loss: 1.4379 - accuracy: 0.4700 - val_loss: 1.4512 - val_accuracy: 0.4800\n",
      "Epoch 28/30\n",
      "1600/1600 [==============================] - 0s 100us/sample - loss: 1.4258 - accuracy: 0.4712 - val_loss: 1.3941 - val_accuracy: 0.4925\n",
      "Epoch 29/30\n",
      "1600/1600 [==============================] - 0s 101us/sample - loss: 1.4317 - accuracy: 0.4638 - val_loss: 1.3822 - val_accuracy: 0.4975\n",
      "Epoch 30/30\n",
      "1600/1600 [==============================] - 0s 102us/sample - loss: 1.4158 - accuracy: 0.4638 - val_loss: 1.3691 - val_accuracy: 0.4950\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/30\n",
      "1600/1600 [==============================] - 1s 601us/sample - loss: 1.5990 - accuracy: 0.4269 - val_loss: 1.5379 - val_accuracy: 0.4500\n",
      "Epoch 2/30\n",
      "1600/1600 [==============================] - 0s 101us/sample - loss: 1.5715 - accuracy: 0.4331 - val_loss: 1.5525 - val_accuracy: 0.4500\n",
      "Epoch 3/30\n",
      "1600/1600 [==============================] - 0s 93us/sample - loss: 1.5692 - accuracy: 0.4331 - val_loss: 1.5718 - val_accuracy: 0.4500\n",
      "Epoch 4/30\n",
      "1600/1600 [==============================] - 0s 85us/sample - loss: 1.5677 - accuracy: 0.4331 - val_loss: 1.5379 - val_accuracy: 0.4500\n",
      "Epoch 5/30\n",
      "1600/1600 [==============================] - 0s 104us/sample - loss: 1.5622 - accuracy: 0.4331 - val_loss: 1.5341 - val_accuracy: 0.4500\n",
      "Epoch 6/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5541 - accuracy: 0.4331 - val_loss: 1.5344 - val_accuracy: 0.4500\n",
      "Epoch 7/30\n",
      "1600/1600 [==============================] - 0s 122us/sample - loss: 1.5576 - accuracy: 0.4331 - val_loss: 1.5339 - val_accuracy: 0.4500\n",
      "Epoch 8/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5580 - accuracy: 0.4331 - val_loss: 1.5507 - val_accuracy: 0.4500\n",
      "Epoch 9/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5559 - accuracy: 0.4331 - val_loss: 1.5435 - val_accuracy: 0.4500\n",
      "Epoch 10/30\n",
      "1600/1600 [==============================] - 0s 76us/sample - loss: 1.5597 - accuracy: 0.4331 - val_loss: 1.5383 - val_accuracy: 0.4500\n",
      "Epoch 11/30\n",
      "1600/1600 [==============================] - 0s 76us/sample - loss: 1.5533 - accuracy: 0.4331 - val_loss: 1.5397 - val_accuracy: 0.4500\n",
      "Epoch 12/30\n",
      "1600/1600 [==============================] - 0s 76us/sample - loss: 1.5601 - accuracy: 0.4331 - val_loss: 1.5546 - val_accuracy: 0.4500\n",
      "Epoch 13/30\n",
      "1600/1600 [==============================] - 0s 102us/sample - loss: 1.5588 - accuracy: 0.4331 - val_loss: 1.5324 - val_accuracy: 0.4500\n",
      "Epoch 14/30\n",
      "1600/1600 [==============================] - 0s 78us/sample - loss: 1.5486 - accuracy: 0.4331 - val_loss: 1.5517 - val_accuracy: 0.4500\n",
      "Epoch 15/30\n",
      "1600/1600 [==============================] - 0s 118us/sample - loss: 1.5454 - accuracy: 0.4331 - val_loss: 1.5223 - val_accuracy: 0.4500\n",
      "Epoch 16/30\n",
      "1600/1600 [==============================] - 0s 100us/sample - loss: 1.5440 - accuracy: 0.4331 - val_loss: 1.5181 - val_accuracy: 0.4500\n",
      "Epoch 17/30\n",
      "1600/1600 [==============================] - 0s 100us/sample - loss: 1.5384 - accuracy: 0.4331 - val_loss: 1.5117 - val_accuracy: 0.4500\n",
      "Epoch 18/30\n",
      "1600/1600 [==============================] - 0s 101us/sample - loss: 1.5269 - accuracy: 0.4331 - val_loss: 1.4999 - val_accuracy: 0.4500\n",
      "Epoch 19/30\n",
      "1600/1600 [==============================] - 0s 100us/sample - loss: 1.5242 - accuracy: 0.4331 - val_loss: 1.4841 - val_accuracy: 0.4500\n",
      "Epoch 20/30\n",
      "1600/1600 [==============================] - 0s 102us/sample - loss: 1.5130 - accuracy: 0.4338 - val_loss: 1.4748 - val_accuracy: 0.4500\n",
      "Epoch 21/30\n",
      "1600/1600 [==============================] - 0s 106us/sample - loss: 1.4880 - accuracy: 0.4481 - val_loss: 1.4689 - val_accuracy: 0.4925\n",
      "Epoch 22/30\n",
      "1600/1600 [==============================] - 0s 103us/sample - loss: 1.4813 - accuracy: 0.4669 - val_loss: 1.4469 - val_accuracy: 0.4900\n",
      "Epoch 23/30\n",
      "1600/1600 [==============================] - 0s 100us/sample - loss: 1.4609 - accuracy: 0.4638 - val_loss: 1.4367 - val_accuracy: 0.4950\n",
      "Epoch 24/30\n",
      "1600/1600 [==============================] - 0s 108us/sample - loss: 1.4487 - accuracy: 0.4675 - val_loss: 1.4186 - val_accuracy: 0.4875\n",
      "Epoch 25/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.4370 - accuracy: 0.4744 - val_loss: 1.4431 - val_accuracy: 0.4850\n",
      "Epoch 26/30\n",
      "1600/1600 [==============================] - 0s 100us/sample - loss: 1.4240 - accuracy: 0.4731 - val_loss: 1.4078 - val_accuracy: 0.4950\n",
      "Epoch 27/30\n",
      "1600/1600 [==============================] - 0s 100us/sample - loss: 1.4135 - accuracy: 0.4762 - val_loss: 1.3943 - val_accuracy: 0.4950\n",
      "Epoch 28/30\n",
      "1600/1600 [==============================] - 0s 290us/sample - loss: 1.4051 - accuracy: 0.4775 - val_loss: 1.3628 - val_accuracy: 0.5025\n",
      "Epoch 29/30\n",
      "1600/1600 [==============================] - 0s 277us/sample - loss: 1.3915 - accuracy: 0.4869 - val_loss: 1.3501 - val_accuracy: 0.5050\n",
      "Epoch 30/30\n",
      "1600/1600 [==============================] - 0s 265us/sample - loss: 1.3742 - accuracy: 0.4856 - val_loss: 1.3341 - val_accuracy: 0.5075\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/30\n",
      "1600/1600 [==============================] - 1s 420us/sample - loss: 1.6168 - accuracy: 0.4281 - val_loss: 1.5457 - val_accuracy: 0.4500\n",
      "Epoch 2/30\n",
      "1600/1600 [==============================] - 0s 94us/sample - loss: 1.5583 - accuracy: 0.4331 - val_loss: 1.5467 - val_accuracy: 0.4500\n",
      "Epoch 3/30\n",
      "1600/1600 [==============================] - 0s 92us/sample - loss: 1.5721 - accuracy: 0.4331 - val_loss: 1.5670 - val_accuracy: 0.4500\n",
      "Epoch 4/30\n",
      "1600/1600 [==============================] - 0s 106us/sample - loss: 1.5636 - accuracy: 0.4331 - val_loss: 1.5404 - val_accuracy: 0.4500\n",
      "Epoch 5/30\n",
      "1600/1600 [==============================] - 0s 80us/sample - loss: 1.5616 - accuracy: 0.4331 - val_loss: 1.5458 - val_accuracy: 0.4500\n",
      "Epoch 6/30\n",
      "1600/1600 [==============================] - 0s 103us/sample - loss: 1.5576 - accuracy: 0.4331 - val_loss: 1.5391 - val_accuracy: 0.4500\n",
      "Epoch 7/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5530 - accuracy: 0.4331 - val_loss: 1.5631 - val_accuracy: 0.4500\n",
      "Epoch 8/30\n",
      "1600/1600 [==============================] - 0s 76us/sample - loss: 1.5567 - accuracy: 0.4331 - val_loss: 1.5450 - val_accuracy: 0.4500\n",
      "Epoch 9/30\n",
      "1600/1600 [==============================] - 0s 75us/sample - loss: 1.5691 - accuracy: 0.4331 - val_loss: 1.5630 - val_accuracy: 0.4500\n",
      "Epoch 10/30\n",
      "1600/1600 [==============================] - 0s 76us/sample - loss: 1.5661 - accuracy: 0.4331 - val_loss: 1.5449 - val_accuracy: 0.4500\n",
      "Epoch 11/30\n",
      "1600/1600 [==============================] - 0s 76us/sample - loss: 1.5568 - accuracy: 0.4331 - val_loss: 1.5413 - val_accuracy: 0.4500\n",
      "Epoch 12/30\n",
      "1600/1600 [==============================] - 0s 76us/sample - loss: 1.5539 - accuracy: 0.4331 - val_loss: 1.5406 - val_accuracy: 0.4500\n",
      "Epoch 13/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5545 - accuracy: 0.4331 - val_loss: 1.5393 - val_accuracy: 0.4500\n",
      "Epoch 14/30\n",
      "1600/1600 [==============================] - 0s 104us/sample - loss: 1.5594 - accuracy: 0.4331 - val_loss: 1.5325 - val_accuracy: 0.4500\n",
      "Epoch 15/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5584 - accuracy: 0.4331 - val_loss: 1.5372 - val_accuracy: 0.4500\n",
      "Epoch 16/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5550 - accuracy: 0.4331 - val_loss: 1.5464 - val_accuracy: 0.4500\n",
      "Epoch 17/30\n",
      "1600/1600 [==============================] - 0s 100us/sample - loss: 1.5507 - accuracy: 0.4331 - val_loss: 1.5285 - val_accuracy: 0.4500\n",
      "Epoch 18/30\n",
      "1600/1600 [==============================] - 0s 76us/sample - loss: 1.5547 - accuracy: 0.4331 - val_loss: 1.5299 - val_accuracy: 0.4500\n",
      "Epoch 19/30\n",
      "1600/1600 [==============================] - 0s 101us/sample - loss: 1.5517 - accuracy: 0.4331 - val_loss: 1.5225 - val_accuracy: 0.4500\n",
      "Epoch 20/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5449 - accuracy: 0.4331 - val_loss: 1.5391 - val_accuracy: 0.4500\n",
      "Epoch 21/30\n",
      "1600/1600 [==============================] - 0s 78us/sample - loss: 1.5549 - accuracy: 0.4331 - val_loss: 1.5359 - val_accuracy: 0.4500\n",
      "Epoch 22/30\n",
      "1600/1600 [==============================] - 0s 103us/sample - loss: 1.5474 - accuracy: 0.4331 - val_loss: 1.5209 - val_accuracy: 0.4500\n",
      "Epoch 23/30\n",
      "1600/1600 [==============================] - 0s 103us/sample - loss: 1.5231 - accuracy: 0.4331 - val_loss: 1.4932 - val_accuracy: 0.4500\n",
      "Epoch 24/30\n",
      "1600/1600 [==============================] - 0s 103us/sample - loss: 1.5119 - accuracy: 0.4338 - val_loss: 1.4883 - val_accuracy: 0.4575\n",
      "Epoch 25/30\n",
      "1600/1600 [==============================] - 0s 103us/sample - loss: 1.4931 - accuracy: 0.4425 - val_loss: 1.4550 - val_accuracy: 0.4750\n",
      "Epoch 26/30\n",
      "1600/1600 [==============================] - 0s 101us/sample - loss: 1.4821 - accuracy: 0.4538 - val_loss: 1.4475 - val_accuracy: 0.4750\n",
      "Epoch 27/30\n",
      "1600/1600 [==============================] - 0s 114us/sample - loss: 1.4803 - accuracy: 0.4512 - val_loss: 1.4474 - val_accuracy: 0.4700\n",
      "Epoch 28/30\n",
      "1600/1600 [==============================] - 0s 102us/sample - loss: 1.4707 - accuracy: 0.4706 - val_loss: 1.4337 - val_accuracy: 0.4725\n",
      "Epoch 29/30\n",
      "1600/1600 [==============================] - 0s 104us/sample - loss: 1.4570 - accuracy: 0.4737 - val_loss: 1.4182 - val_accuracy: 0.4850\n",
      "Epoch 30/30\n",
      "1600/1600 [==============================] - 0s 78us/sample - loss: 1.4533 - accuracy: 0.4644 - val_loss: 1.4358 - val_accuracy: 0.4800\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/30\n",
      "1600/1600 [==============================] - 1s 445us/sample - loss: 1.6176 - accuracy: 0.4175 - val_loss: 1.5444 - val_accuracy: 0.4500\n",
      "Epoch 2/30\n",
      "1600/1600 [==============================] - 0s 99us/sample - loss: 1.5646 - accuracy: 0.4331 - val_loss: 1.5539 - val_accuracy: 0.4500\n",
      "Epoch 3/30\n",
      "1600/1600 [==============================] - 0s 114us/sample - loss: 1.5656 - accuracy: 0.4331 - val_loss: 1.5402 - val_accuracy: 0.4500\n",
      "Epoch 4/30\n",
      "1600/1600 [==============================] - 0s 84us/sample - loss: 1.5581 - accuracy: 0.4331 - val_loss: 1.5403 - val_accuracy: 0.4500\n",
      "Epoch 5/30\n",
      "1600/1600 [==============================] - 0s 106us/sample - loss: 1.5543 - accuracy: 0.4331 - val_loss: 1.5341 - val_accuracy: 0.4500\n",
      "Epoch 6/30\n",
      "1600/1600 [==============================] - 0s 101us/sample - loss: 1.5578 - accuracy: 0.4331 - val_loss: 1.5326 - val_accuracy: 0.4500\n",
      "Epoch 7/30\n",
      "1600/1600 [==============================] - 0s 78us/sample - loss: 1.5636 - accuracy: 0.4331 - val_loss: 1.5458 - val_accuracy: 0.4500\n",
      "Epoch 8/30\n",
      "1600/1600 [==============================] - 0s 76us/sample - loss: 1.5554 - accuracy: 0.4331 - val_loss: 1.5594 - val_accuracy: 0.4500\n",
      "Epoch 9/30\n",
      "1600/1600 [==============================] - 0s 76us/sample - loss: 1.5577 - accuracy: 0.4331 - val_loss: 1.5344 - val_accuracy: 0.4500\n",
      "Epoch 10/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5608 - accuracy: 0.4331 - val_loss: 1.5371 - val_accuracy: 0.4500\n",
      "Epoch 11/30\n",
      "1600/1600 [==============================] - 0s 78us/sample - loss: 1.5549 - accuracy: 0.4331 - val_loss: 1.5374 - val_accuracy: 0.4500\n",
      "Epoch 12/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5593 - accuracy: 0.4331 - val_loss: 1.5394 - val_accuracy: 0.4500\n",
      "Epoch 13/30\n",
      "1600/1600 [==============================] - 0s 78us/sample - loss: 1.5557 - accuracy: 0.4331 - val_loss: 1.5380 - val_accuracy: 0.4500\n",
      "Epoch 14/30\n",
      "1600/1600 [==============================] - 0s 101us/sample - loss: 1.5582 - accuracy: 0.4331 - val_loss: 1.5326 - val_accuracy: 0.4500\n",
      "Epoch 15/30\n",
      "1600/1600 [==============================] - 0s 78us/sample - loss: 1.5595 - accuracy: 0.4331 - val_loss: 1.5331 - val_accuracy: 0.4500\n",
      "Epoch 16/30\n",
      "1600/1600 [==============================] - 0s 101us/sample - loss: 1.5506 - accuracy: 0.4331 - val_loss: 1.5303 - val_accuracy: 0.4500\n",
      "Epoch 17/30\n",
      "1600/1600 [==============================] - 0s 101us/sample - loss: 1.5511 - accuracy: 0.4331 - val_loss: 1.5267 - val_accuracy: 0.4500\n",
      "Epoch 18/30\n",
      "1600/1600 [==============================] - 0s 117us/sample - loss: 1.5479 - accuracy: 0.4331 - val_loss: 1.5209 - val_accuracy: 0.4500\n",
      "Epoch 19/30\n",
      "1600/1600 [==============================] - 0s 100us/sample - loss: 1.5475 - accuracy: 0.4331 - val_loss: 1.5199 - val_accuracy: 0.4500\n",
      "Epoch 20/30\n",
      "1600/1600 [==============================] - 0s 100us/sample - loss: 1.5373 - accuracy: 0.4331 - val_loss: 1.5179 - val_accuracy: 0.4500\n",
      "Epoch 21/30\n",
      "1600/1600 [==============================] - 0s 102us/sample - loss: 1.5263 - accuracy: 0.4338 - val_loss: 1.5022 - val_accuracy: 0.4500\n",
      "Epoch 22/30\n",
      "1600/1600 [==============================] - 0s 120us/sample - loss: 1.5205 - accuracy: 0.4381 - val_loss: 1.4913 - val_accuracy: 0.4500\n",
      "Epoch 23/30\n",
      "1600/1600 [==============================] - 0s 102us/sample - loss: 1.4884 - accuracy: 0.4494 - val_loss: 1.4611 - val_accuracy: 0.4775\n",
      "Epoch 24/30\n",
      "1600/1600 [==============================] - 0s 78us/sample - loss: 1.4772 - accuracy: 0.4606 - val_loss: 1.4617 - val_accuracy: 0.4875\n",
      "Epoch 25/30\n",
      "1600/1600 [==============================] - 0s 102us/sample - loss: 1.5022 - accuracy: 0.4506 - val_loss: 1.4466 - val_accuracy: 0.4800\n",
      "Epoch 26/30\n",
      "1600/1600 [==============================] - 0s 78us/sample - loss: 1.4573 - accuracy: 0.4656 - val_loss: 1.4533 - val_accuracy: 0.4750\n",
      "Epoch 27/30\n",
      "1600/1600 [==============================] - 0s 102us/sample - loss: 1.4690 - accuracy: 0.4519 - val_loss: 1.4309 - val_accuracy: 0.4750\n",
      "Epoch 28/30\n",
      "1600/1600 [==============================] - 0s 125us/sample - loss: 1.4438 - accuracy: 0.4725 - val_loss: 1.4075 - val_accuracy: 0.4900\n",
      "Epoch 29/30\n",
      "1600/1600 [==============================] - 0s 124us/sample - loss: 1.4174 - accuracy: 0.4775 - val_loss: 1.3967 - val_accuracy: 0.4850\n",
      "Epoch 30/30\n",
      "1600/1600 [==============================] - 0s 135us/sample - loss: 1.4138 - accuracy: 0.4775 - val_loss: 1.3784 - val_accuracy: 0.4950\n",
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "966ba88536894f71935bf6e1165c1ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2240 samples, validate on 560 samples\n",
      "Epoch 1/30\n",
      "2240/2240 [==============================] - 1s 323us/sample - loss: 1.6033 - accuracy: 0.4281 - val_loss: 1.5362 - val_accuracy: 0.4411\n",
      "Epoch 2/30\n",
      "2240/2240 [==============================] - 0s 91us/sample - loss: 1.5618 - accuracy: 0.4384 - val_loss: 1.5497 - val_accuracy: 0.4411\n",
      "Epoch 3/30\n",
      "2240/2240 [==============================] - 0s 77us/sample - loss: 1.5523 - accuracy: 0.4384 - val_loss: 1.5438 - val_accuracy: 0.4411\n",
      "Epoch 4/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5558 - accuracy: 0.4384 - val_loss: 1.5427 - val_accuracy: 0.4411\n",
      "Epoch 5/30\n",
      "2240/2240 [==============================] - 0s 71us/sample - loss: 1.5516 - accuracy: 0.4384 - val_loss: 1.5494 - val_accuracy: 0.4411\n",
      "Epoch 6/30\n",
      "2240/2240 [==============================] - 0s 71us/sample - loss: 1.5556 - accuracy: 0.4384 - val_loss: 1.5407 - val_accuracy: 0.4411\n",
      "Epoch 7/30\n",
      "2240/2240 [==============================] - 0s 71us/sample - loss: 1.5602 - accuracy: 0.4384 - val_loss: 1.5393 - val_accuracy: 0.4411\n",
      "Epoch 8/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5541 - accuracy: 0.4384 - val_loss: 1.5340 - val_accuracy: 0.4411\n",
      "Epoch 9/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5472 - accuracy: 0.4384 - val_loss: 1.5366 - val_accuracy: 0.4411\n",
      "Epoch 10/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5531 - accuracy: 0.4384 - val_loss: 1.5336 - val_accuracy: 0.4411\n",
      "Epoch 11/30\n",
      "2240/2240 [==============================] - 0s 88us/sample - loss: 1.5461 - accuracy: 0.4384 - val_loss: 1.5292 - val_accuracy: 0.4411\n",
      "Epoch 12/30\n",
      "2240/2240 [==============================] - 0s 88us/sample - loss: 1.5388 - accuracy: 0.4384 - val_loss: 1.5230 - val_accuracy: 0.4411\n",
      "Epoch 13/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5382 - accuracy: 0.4384 - val_loss: 1.5342 - val_accuracy: 0.4411\n",
      "Epoch 14/30\n",
      "2240/2240 [==============================] - 0s 97us/sample - loss: 1.5272 - accuracy: 0.4384 - val_loss: 1.5108 - val_accuracy: 0.4411\n",
      "Epoch 15/30\n",
      "2240/2240 [==============================] - 0s 88us/sample - loss: 1.5091 - accuracy: 0.4384 - val_loss: 1.4795 - val_accuracy: 0.4411\n",
      "Epoch 16/30\n",
      "2240/2240 [==============================] - 0s 90us/sample - loss: 1.4822 - accuracy: 0.4482 - val_loss: 1.4558 - val_accuracy: 0.4625\n",
      "Epoch 17/30\n",
      "2240/2240 [==============================] - 0s 88us/sample - loss: 1.4693 - accuracy: 0.4647 - val_loss: 1.4451 - val_accuracy: 0.4786\n",
      "Epoch 18/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.4681 - accuracy: 0.4652 - val_loss: 1.4332 - val_accuracy: 0.4786\n",
      "Epoch 19/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.4596 - accuracy: 0.4652 - val_loss: 1.4267 - val_accuracy: 0.4786\n",
      "Epoch 20/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.4277 - accuracy: 0.4795 - val_loss: 1.3954 - val_accuracy: 0.4911\n",
      "Epoch 21/30\n",
      "2240/2240 [==============================] - 0s 131us/sample - loss: 1.4084 - accuracy: 0.4790 - val_loss: 1.3717 - val_accuracy: 0.4946\n",
      "Epoch 22/30\n",
      "2240/2240 [==============================] - 0s 131us/sample - loss: 1.4115 - accuracy: 0.4732 - val_loss: 1.3668 - val_accuracy: 0.4911\n",
      "Epoch 23/30\n",
      "2240/2240 [==============================] - 0s 132us/sample - loss: 1.3841 - accuracy: 0.4875 - val_loss: 1.3643 - val_accuracy: 0.4821\n",
      "Epoch 24/30\n",
      "2240/2240 [==============================] - 0s 121us/sample - loss: 1.3711 - accuracy: 0.4844 - val_loss: 1.3390 - val_accuracy: 0.4982\n",
      "Epoch 25/30\n",
      "2240/2240 [==============================] - 1s 273us/sample - loss: 1.3691 - accuracy: 0.4830 - val_loss: 1.3046 - val_accuracy: 0.5179\n",
      "Epoch 26/30\n",
      "2240/2240 [==============================] - 1s 251us/sample - loss: 1.3489 - accuracy: 0.4920 - val_loss: 1.3001 - val_accuracy: 0.5179\n",
      "Epoch 27/30\n",
      "2240/2240 [==============================] - 1s 276us/sample - loss: 1.3348 - accuracy: 0.5027 - val_loss: 1.2807 - val_accuracy: 0.5143\n",
      "Epoch 28/30\n",
      "2240/2240 [==============================] - 1s 301us/sample - loss: 1.3243 - accuracy: 0.4960 - val_loss: 1.2712 - val_accuracy: 0.5179\n",
      "Epoch 29/30\n",
      "2240/2240 [==============================] - 1s 266us/sample - loss: 1.3141 - accuracy: 0.4942 - val_loss: 1.2510 - val_accuracy: 0.5232\n",
      "Epoch 30/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.3100 - accuracy: 0.4978 - val_loss: 1.2614 - val_accuracy: 0.5393\n",
      "Train on 2240 samples, validate on 560 samples\n",
      "Epoch 1/30\n",
      "2240/2240 [==============================] - 1s 323us/sample - loss: 1.6125 - accuracy: 0.4304 - val_loss: 1.5322 - val_accuracy: 0.4411\n",
      "Epoch 2/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5574 - accuracy: 0.4384 - val_loss: 1.5579 - val_accuracy: 0.4411\n",
      "Epoch 3/30\n",
      "2240/2240 [==============================] - 0s 81us/sample - loss: 1.5570 - accuracy: 0.4384 - val_loss: 1.5381 - val_accuracy: 0.4411\n",
      "Epoch 4/30\n",
      "2240/2240 [==============================] - 0s 73us/sample - loss: 1.5594 - accuracy: 0.4384 - val_loss: 1.5325 - val_accuracy: 0.4411\n",
      "Epoch 5/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5564 - accuracy: 0.4384 - val_loss: 1.5371 - val_accuracy: 0.4411\n",
      "Epoch 6/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5558 - accuracy: 0.4384 - val_loss: 1.5309 - val_accuracy: 0.4411\n",
      "Epoch 7/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5577 - accuracy: 0.4384 - val_loss: 1.5604 - val_accuracy: 0.4411\n",
      "Epoch 8/30\n",
      "2240/2240 [==============================] - 0s 71us/sample - loss: 1.5555 - accuracy: 0.4384 - val_loss: 1.5315 - val_accuracy: 0.4411\n",
      "Epoch 9/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5520 - accuracy: 0.4384 - val_loss: 1.5434 - val_accuracy: 0.4411\n",
      "Epoch 10/30\n",
      "2240/2240 [==============================] - 0s 71us/sample - loss: 1.5494 - accuracy: 0.4384 - val_loss: 1.5344 - val_accuracy: 0.4411\n",
      "Epoch 11/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5520 - accuracy: 0.4384 - val_loss: 1.5319 - val_accuracy: 0.4411\n",
      "Epoch 12/30\n",
      "2240/2240 [==============================] - 0s 90us/sample - loss: 1.5477 - accuracy: 0.4384 - val_loss: 1.5278 - val_accuracy: 0.4411\n",
      "Epoch 13/30\n",
      "2240/2240 [==============================] - 0s 71us/sample - loss: 1.5447 - accuracy: 0.4384 - val_loss: 1.5279 - val_accuracy: 0.4411\n",
      "Epoch 14/30\n",
      "2240/2240 [==============================] - 0s 90us/sample - loss: 1.5464 - accuracy: 0.4384 - val_loss: 1.5210 - val_accuracy: 0.4411\n",
      "Epoch 15/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5394 - accuracy: 0.4384 - val_loss: 1.5155 - val_accuracy: 0.4411\n",
      "Epoch 16/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5304 - accuracy: 0.4384 - val_loss: 1.5047 - val_accuracy: 0.4411\n",
      "Epoch 17/30\n",
      "2240/2240 [==============================] - 0s 100us/sample - loss: 1.5092 - accuracy: 0.4406 - val_loss: 1.5025 - val_accuracy: 0.4411\n",
      "Epoch 18/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.4928 - accuracy: 0.4509 - val_loss: 1.4833 - val_accuracy: 0.4714\n",
      "Epoch 19/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.4815 - accuracy: 0.4563 - val_loss: 1.4640 - val_accuracy: 0.4661\n",
      "Epoch 20/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.4576 - accuracy: 0.4652 - val_loss: 1.4408 - val_accuracy: 0.4768\n",
      "Epoch 21/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.4454 - accuracy: 0.4728 - val_loss: 1.4234 - val_accuracy: 0.4804\n",
      "Epoch 22/30\n",
      "2240/2240 [==============================] - 0s 90us/sample - loss: 1.4288 - accuracy: 0.4786 - val_loss: 1.4008 - val_accuracy: 0.4821\n",
      "Epoch 23/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.4131 - accuracy: 0.4799 - val_loss: 1.3815 - val_accuracy: 0.4821\n",
      "Epoch 24/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.4005 - accuracy: 0.4812 - val_loss: 1.3705 - val_accuracy: 0.4875\n",
      "Epoch 25/30\n",
      "2240/2240 [==============================] - 0s 90us/sample - loss: 1.3762 - accuracy: 0.4879 - val_loss: 1.3426 - val_accuracy: 0.4929\n",
      "Epoch 26/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.3660 - accuracy: 0.4920 - val_loss: 1.3183 - val_accuracy: 0.5089\n",
      "Epoch 27/30\n",
      "2240/2240 [==============================] - 0s 90us/sample - loss: 1.3494 - accuracy: 0.4853 - val_loss: 1.2992 - val_accuracy: 0.5089\n",
      "Epoch 28/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.3338 - accuracy: 0.4991 - val_loss: 1.2796 - val_accuracy: 0.5196\n",
      "Epoch 29/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.3367 - accuracy: 0.4973 - val_loss: 1.2747 - val_accuracy: 0.5339\n",
      "Epoch 30/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.3146 - accuracy: 0.4996 - val_loss: 1.2613 - val_accuracy: 0.5357\n",
      "Train on 2240 samples, validate on 560 samples\n",
      "Epoch 1/30\n",
      "2240/2240 [==============================] - 1s 324us/sample - loss: 1.5982 - accuracy: 0.4326 - val_loss: 1.5628 - val_accuracy: 0.4411\n",
      "Epoch 2/30\n",
      "2240/2240 [==============================] - 0s 98us/sample - loss: 1.5599 - accuracy: 0.4384 - val_loss: 1.5391 - val_accuracy: 0.4411\n",
      "Epoch 3/30\n",
      "2240/2240 [==============================] - 0s 94us/sample - loss: 1.5543 - accuracy: 0.4384 - val_loss: 1.5383 - val_accuracy: 0.4411\n",
      "Epoch 4/30\n",
      "2240/2240 [==============================] - 0s 90us/sample - loss: 1.5578 - accuracy: 0.4384 - val_loss: 1.5319 - val_accuracy: 0.4411\n",
      "Epoch 5/30\n",
      "2240/2240 [==============================] - 0s 73us/sample - loss: 1.5555 - accuracy: 0.4384 - val_loss: 1.5431 - val_accuracy: 0.4411\n",
      "Epoch 6/30\n",
      "2240/2240 [==============================] - 0s 71us/sample - loss: 1.5580 - accuracy: 0.4384 - val_loss: 1.5372 - val_accuracy: 0.4411\n",
      "Epoch 7/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5519 - accuracy: 0.4384 - val_loss: 1.5332 - val_accuracy: 0.4411\n",
      "Epoch 8/30\n",
      "2240/2240 [==============================] - 0s 90us/sample - loss: 1.5556 - accuracy: 0.4384 - val_loss: 1.5301 - val_accuracy: 0.4411\n",
      "Epoch 9/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5502 - accuracy: 0.4384 - val_loss: 1.5275 - val_accuracy: 0.4411\n",
      "Epoch 10/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5552 - accuracy: 0.4384 - val_loss: 1.5327 - val_accuracy: 0.4411\n",
      "Epoch 11/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5509 - accuracy: 0.4384 - val_loss: 1.5257 - val_accuracy: 0.4411\n",
      "Epoch 12/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5335 - accuracy: 0.4384 - val_loss: 1.5205 - val_accuracy: 0.4411\n",
      "Epoch 13/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5245 - accuracy: 0.4384 - val_loss: 1.5125 - val_accuracy: 0.4411\n",
      "Epoch 14/30\n",
      "2240/2240 [==============================] - 0s 73us/sample - loss: 1.5201 - accuracy: 0.4384 - val_loss: 1.5175 - val_accuracy: 0.4411\n",
      "Epoch 15/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5020 - accuracy: 0.4397 - val_loss: 1.4686 - val_accuracy: 0.4429\n",
      "Epoch 16/30\n",
      "2240/2240 [==============================] - 0s 90us/sample - loss: 1.4682 - accuracy: 0.4652 - val_loss: 1.4464 - val_accuracy: 0.4714\n",
      "Epoch 17/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.4659 - accuracy: 0.4728 - val_loss: 1.4474 - val_accuracy: 0.4732\n",
      "Epoch 18/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.4591 - accuracy: 0.4652 - val_loss: 1.4274 - val_accuracy: 0.4804\n",
      "Epoch 19/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.4335 - accuracy: 0.4750 - val_loss: 1.4051 - val_accuracy: 0.4804\n",
      "Epoch 20/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.4263 - accuracy: 0.4719 - val_loss: 1.4625 - val_accuracy: 0.4500\n",
      "Epoch 21/30\n",
      "2240/2240 [==============================] - 0s 90us/sample - loss: 1.4270 - accuracy: 0.4759 - val_loss: 1.3846 - val_accuracy: 0.4786\n",
      "Epoch 22/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.3895 - accuracy: 0.4893 - val_loss: 1.3388 - val_accuracy: 0.4982\n",
      "Epoch 23/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.3706 - accuracy: 0.4893 - val_loss: 1.3292 - val_accuracy: 0.4982\n",
      "Epoch 24/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.3602 - accuracy: 0.4933 - val_loss: 1.3079 - val_accuracy: 0.5071\n",
      "Epoch 25/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.3483 - accuracy: 0.4938 - val_loss: 1.3006 - val_accuracy: 0.5089\n",
      "Epoch 26/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.3360 - accuracy: 0.5013 - val_loss: 1.2824 - val_accuracy: 0.5125\n",
      "Epoch 27/30\n",
      "2240/2240 [==============================] - 0s 106us/sample - loss: 1.3259 - accuracy: 0.5031 - val_loss: 1.2517 - val_accuracy: 0.5393\n",
      "Epoch 28/30\n",
      "2240/2240 [==============================] - 1s 287us/sample - loss: 1.3021 - accuracy: 0.5013 - val_loss: 1.2450 - val_accuracy: 0.5304\n",
      "Epoch 29/30\n",
      "2240/2240 [==============================] - 0s 73us/sample - loss: 1.3010 - accuracy: 0.5063 - val_loss: 1.2485 - val_accuracy: 0.5464\n",
      "Epoch 30/30\n",
      "2240/2240 [==============================] - 1s 299us/sample - loss: 1.2939 - accuracy: 0.5054 - val_loss: 1.2271 - val_accuracy: 0.5393\n",
      "Train on 2240 samples, validate on 560 samples\n",
      "Epoch 1/30\n",
      "2240/2240 [==============================] - 1s 330us/sample - loss: 1.5985 - accuracy: 0.4308 - val_loss: 1.5698 - val_accuracy: 0.4411\n",
      "Epoch 2/30\n",
      "2240/2240 [==============================] - 0s 99us/sample - loss: 1.5620 - accuracy: 0.4384 - val_loss: 1.5305 - val_accuracy: 0.4411\n",
      "Epoch 3/30\n",
      "2240/2240 [==============================] - 0s 75us/sample - loss: 1.5552 - accuracy: 0.4384 - val_loss: 1.5387 - val_accuracy: 0.4411\n",
      "Epoch 4/30\n",
      "2240/2240 [==============================] - 0s 73us/sample - loss: 1.5560 - accuracy: 0.4384 - val_loss: 1.5393 - val_accuracy: 0.4411\n",
      "Epoch 5/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5571 - accuracy: 0.4384 - val_loss: 1.5428 - val_accuracy: 0.4411\n",
      "Epoch 6/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5521 - accuracy: 0.4384 - val_loss: 1.5493 - val_accuracy: 0.4411\n",
      "Epoch 7/30\n",
      "2240/2240 [==============================] - 0s 90us/sample - loss: 1.5537 - accuracy: 0.4384 - val_loss: 1.5298 - val_accuracy: 0.4411\n",
      "Epoch 8/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5485 - accuracy: 0.4384 - val_loss: 1.5463 - val_accuracy: 0.4411\n",
      "Epoch 9/30\n",
      "2240/2240 [==============================] - 0s 90us/sample - loss: 1.5532 - accuracy: 0.4384 - val_loss: 1.5284 - val_accuracy: 0.4411\n",
      "Epoch 10/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5455 - accuracy: 0.4384 - val_loss: 1.5197 - val_accuracy: 0.4411\n",
      "Epoch 11/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5339 - accuracy: 0.4384 - val_loss: 1.5176 - val_accuracy: 0.4411\n",
      "Epoch 12/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5222 - accuracy: 0.4384 - val_loss: 1.4949 - val_accuracy: 0.4411\n",
      "Epoch 13/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5005 - accuracy: 0.4420 - val_loss: 1.4758 - val_accuracy: 0.4554\n",
      "Epoch 14/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.4718 - accuracy: 0.4558 - val_loss: 1.4659 - val_accuracy: 0.4714\n",
      "Epoch 15/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.4727 - accuracy: 0.4612 - val_loss: 1.4881 - val_accuracy: 0.4536\n",
      "Epoch 16/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.4501 - accuracy: 0.4701 - val_loss: 1.4186 - val_accuracy: 0.4821\n",
      "Epoch 17/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.4370 - accuracy: 0.4728 - val_loss: 1.4099 - val_accuracy: 0.4786\n",
      "Epoch 18/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.4261 - accuracy: 0.4768 - val_loss: 1.3932 - val_accuracy: 0.4857\n",
      "Epoch 19/30\n",
      "2240/2240 [==============================] - 0s 100us/sample - loss: 1.4105 - accuracy: 0.4804 - val_loss: 1.3872 - val_accuracy: 0.4893\n",
      "Epoch 20/30\n",
      "2240/2240 [==============================] - 0s 90us/sample - loss: 1.4013 - accuracy: 0.4875 - val_loss: 1.3603 - val_accuracy: 0.4946\n",
      "Epoch 21/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.3737 - accuracy: 0.4830 - val_loss: 1.3342 - val_accuracy: 0.4964\n",
      "Epoch 22/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.3647 - accuracy: 0.4826 - val_loss: 1.3325 - val_accuracy: 0.5143\n",
      "Epoch 23/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.3431 - accuracy: 0.4951 - val_loss: 1.2905 - val_accuracy: 0.5196\n",
      "Epoch 24/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.3304 - accuracy: 0.4991 - val_loss: 1.2664 - val_accuracy: 0.5179\n",
      "Epoch 25/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.3135 - accuracy: 0.5027 - val_loss: 1.2674 - val_accuracy: 0.5161\n",
      "Epoch 26/30\n",
      "2240/2240 [==============================] - 0s 88us/sample - loss: 1.2999 - accuracy: 0.5049 - val_loss: 1.2335 - val_accuracy: 0.5339\n",
      "Epoch 27/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.2874 - accuracy: 0.5067 - val_loss: 1.2356 - val_accuracy: 0.5339\n",
      "Epoch 28/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.2725 - accuracy: 0.5067 - val_loss: 1.2308 - val_accuracy: 0.5429\n",
      "Epoch 29/30\n",
      "2240/2240 [==============================] - 1s 314us/sample - loss: 1.2765 - accuracy: 0.5138 - val_loss: 1.2183 - val_accuracy: 0.5446\n",
      "Epoch 30/30\n",
      "2240/2240 [==============================] - 0s 73us/sample - loss: 1.2678 - accuracy: 0.5174 - val_loss: 1.2186 - val_accuracy: 0.5268\n",
      "Train on 2240 samples, validate on 560 samples\n",
      "Epoch 1/30\n",
      "2240/2240 [==============================] - 1s 400us/sample - loss: 1.6051 - accuracy: 0.4290 - val_loss: 1.5418 - val_accuracy: 0.4411\n",
      "Epoch 2/30\n",
      "2240/2240 [==============================] - 0s 88us/sample - loss: 1.5561 - accuracy: 0.4384 - val_loss: 1.5644 - val_accuracy: 0.4411\n",
      "Epoch 3/30\n",
      "2240/2240 [==============================] - 0s 81us/sample - loss: 1.5527 - accuracy: 0.4384 - val_loss: 1.5575 - val_accuracy: 0.4411\n",
      "Epoch 4/30\n",
      "2240/2240 [==============================] - 0s 90us/sample - loss: 1.5576 - accuracy: 0.4384 - val_loss: 1.5403 - val_accuracy: 0.4411\n",
      "Epoch 5/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5539 - accuracy: 0.4384 - val_loss: 1.5433 - val_accuracy: 0.4411\n",
      "Epoch 6/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5557 - accuracy: 0.4384 - val_loss: 1.5370 - val_accuracy: 0.4411\n",
      "Epoch 7/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5492 - accuracy: 0.4384 - val_loss: 1.5316 - val_accuracy: 0.4411\n",
      "Epoch 8/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5527 - accuracy: 0.4384 - val_loss: 1.5308 - val_accuracy: 0.4411\n",
      "Epoch 9/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5460 - accuracy: 0.4384 - val_loss: 1.5311 - val_accuracy: 0.4411\n",
      "Epoch 10/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5514 - accuracy: 0.4384 - val_loss: 1.5323 - val_accuracy: 0.4411\n",
      "Epoch 11/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5468 - accuracy: 0.4384 - val_loss: 1.5481 - val_accuracy: 0.4411\n",
      "Epoch 12/30\n",
      "2240/2240 [==============================] - 0s 90us/sample - loss: 1.5545 - accuracy: 0.4384 - val_loss: 1.5280 - val_accuracy: 0.4411\n",
      "Epoch 13/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5487 - accuracy: 0.4384 - val_loss: 1.5251 - val_accuracy: 0.4411\n",
      "Epoch 14/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5477 - accuracy: 0.4384 - val_loss: 1.5210 - val_accuracy: 0.4411\n",
      "Epoch 15/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5336 - accuracy: 0.4384 - val_loss: 1.5105 - val_accuracy: 0.4411\n",
      "Epoch 16/30\n",
      "2240/2240 [==============================] - 0s 73us/sample - loss: 1.5350 - accuracy: 0.4384 - val_loss: 1.5113 - val_accuracy: 0.4411\n",
      "Epoch 17/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5149 - accuracy: 0.4384 - val_loss: 1.4946 - val_accuracy: 0.4411\n",
      "Epoch 18/30\n",
      "2240/2240 [==============================] - 0s 90us/sample - loss: 1.4964 - accuracy: 0.4478 - val_loss: 1.4681 - val_accuracy: 0.4679\n",
      "Epoch 19/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.4714 - accuracy: 0.4612 - val_loss: 1.4380 - val_accuracy: 0.4732\n",
      "Epoch 20/30\n",
      "2240/2240 [==============================] - 0s 88us/sample - loss: 1.4601 - accuracy: 0.4674 - val_loss: 1.4257 - val_accuracy: 0.4714\n",
      "Epoch 21/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.4374 - accuracy: 0.4674 - val_loss: 1.4225 - val_accuracy: 0.4804\n",
      "Epoch 22/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.4299 - accuracy: 0.4781 - val_loss: 1.3994 - val_accuracy: 0.4875\n",
      "Epoch 23/30\n",
      "2240/2240 [==============================] - 0s 88us/sample - loss: 1.4058 - accuracy: 0.4817 - val_loss: 1.3824 - val_accuracy: 0.4911\n",
      "Epoch 24/30\n",
      "2240/2240 [==============================] - 0s 88us/sample - loss: 1.3920 - accuracy: 0.4866 - val_loss: 1.3614 - val_accuracy: 0.4857\n",
      "Epoch 25/30\n",
      "2240/2240 [==============================] - 0s 90us/sample - loss: 1.3828 - accuracy: 0.4906 - val_loss: 1.3437 - val_accuracy: 0.5161\n",
      "Epoch 26/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.3611 - accuracy: 0.4884 - val_loss: 1.3102 - val_accuracy: 0.5089\n",
      "Epoch 27/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.3493 - accuracy: 0.4920 - val_loss: 1.3086 - val_accuracy: 0.5125\n",
      "Epoch 28/30\n",
      "2240/2240 [==============================] - 0s 90us/sample - loss: 1.3351 - accuracy: 0.4942 - val_loss: 1.2991 - val_accuracy: 0.5286\n",
      "Epoch 29/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.3239 - accuracy: 0.4969 - val_loss: 1.2676 - val_accuracy: 0.5286\n",
      "Epoch 30/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.3137 - accuracy: 0.5045 - val_loss: 1.2668 - val_accuracy: 0.5250\n",
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb1d03a26fa4ca3a721bf81e636b8e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/30\n",
      "3200/3200 [==============================] - 1s 252us/sample - loss: 1.6000 - accuracy: 0.4353 - val_loss: 1.5687 - val_accuracy: 0.4288\n",
      "Epoch 2/30\n",
      "3200/3200 [==============================] - 0s 88us/sample - loss: 1.5511 - accuracy: 0.4400 - val_loss: 1.5686 - val_accuracy: 0.4288\n",
      "Epoch 3/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.5497 - accuracy: 0.4400 - val_loss: 1.5861 - val_accuracy: 0.4288\n",
      "Epoch 4/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.5525 - accuracy: 0.4400 - val_loss: 1.5729 - val_accuracy: 0.4288\n",
      "Epoch 5/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.5468 - accuracy: 0.4400 - val_loss: 1.5778 - val_accuracy: 0.4288\n",
      "Epoch 6/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.5532 - accuracy: 0.4400 - val_loss: 1.5713 - val_accuracy: 0.4288\n",
      "Epoch 7/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5474 - accuracy: 0.4400 - val_loss: 1.5650 - val_accuracy: 0.4288\n",
      "Epoch 8/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5459 - accuracy: 0.4400 - val_loss: 1.5596 - val_accuracy: 0.4288\n",
      "Epoch 9/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5398 - accuracy: 0.4400 - val_loss: 1.5474 - val_accuracy: 0.4288\n",
      "Epoch 10/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5228 - accuracy: 0.4400 - val_loss: 1.5241 - val_accuracy: 0.4288\n",
      "Epoch 11/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5048 - accuracy: 0.4419 - val_loss: 1.5001 - val_accuracy: 0.4288\n",
      "Epoch 12/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.4758 - accuracy: 0.4600 - val_loss: 1.4887 - val_accuracy: 0.4588\n",
      "Epoch 13/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.4578 - accuracy: 0.4678 - val_loss: 1.4553 - val_accuracy: 0.4588\n",
      "Epoch 14/30\n",
      "3200/3200 [==============================] - 0s 88us/sample - loss: 1.4239 - accuracy: 0.4772 - val_loss: 1.4342 - val_accuracy: 0.4600\n",
      "Epoch 15/30\n",
      "3200/3200 [==============================] - 0s 95us/sample - loss: 1.4180 - accuracy: 0.4762 - val_loss: 1.4077 - val_accuracy: 0.4638\n",
      "Epoch 16/30\n",
      "3200/3200 [==============================] - 0s 90us/sample - loss: 1.3835 - accuracy: 0.4859 - val_loss: 1.3787 - val_accuracy: 0.4663\n",
      "Epoch 17/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.3639 - accuracy: 0.4844 - val_loss: 1.3541 - val_accuracy: 0.4762\n",
      "Epoch 18/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.3510 - accuracy: 0.4953 - val_loss: 1.3436 - val_accuracy: 0.4750\n",
      "Epoch 19/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.3316 - accuracy: 0.4997 - val_loss: 1.3399 - val_accuracy: 0.4800\n",
      "Epoch 20/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.3235 - accuracy: 0.5019 - val_loss: 1.3487 - val_accuracy: 0.4725\n",
      "Epoch 21/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.3082 - accuracy: 0.5044 - val_loss: 1.3238 - val_accuracy: 0.4800\n",
      "Epoch 22/30\n",
      "3200/3200 [==============================] - 0s 91us/sample - loss: 1.2970 - accuracy: 0.5097 - val_loss: 1.3056 - val_accuracy: 0.4850\n",
      "Epoch 23/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.2894 - accuracy: 0.5150 - val_loss: 1.2837 - val_accuracy: 0.4837\n",
      "Epoch 24/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.2797 - accuracy: 0.5169 - val_loss: 1.2833 - val_accuracy: 0.4875\n",
      "Epoch 25/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.2684 - accuracy: 0.5231 - val_loss: 1.2750 - val_accuracy: 0.4913\n",
      "Epoch 26/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.2730 - accuracy: 0.5166 - val_loss: 1.2748 - val_accuracy: 0.4938\n",
      "Epoch 27/30\n",
      "3200/3200 [==============================] - 0s 103us/sample - loss: 1.2489 - accuracy: 0.5263 - val_loss: 1.2631 - val_accuracy: 0.4950\n",
      "Epoch 28/30\n",
      "3200/3200 [==============================] - 0s 103us/sample - loss: 1.2410 - accuracy: 0.5294 - val_loss: 1.2472 - val_accuracy: 0.4925\n",
      "Epoch 29/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.2394 - accuracy: 0.5244 - val_loss: 1.2515 - val_accuracy: 0.5038\n",
      "Epoch 30/30\n",
      "3200/3200 [==============================] - 0s 95us/sample - loss: 1.2258 - accuracy: 0.5331 - val_loss: 1.2467 - val_accuracy: 0.5150\n",
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/30\n",
      "3200/3200 [==============================] - 1s 261us/sample - loss: 1.5905 - accuracy: 0.4338 - val_loss: 1.5677 - val_accuracy: 0.4288\n",
      "Epoch 2/30\n",
      "3200/3200 [==============================] - 0s 76us/sample - loss: 1.5583 - accuracy: 0.4400 - val_loss: 1.5715 - val_accuracy: 0.4288\n",
      "Epoch 3/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.5521 - accuracy: 0.4400 - val_loss: 1.5790 - val_accuracy: 0.4288\n",
      "Epoch 4/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5523 - accuracy: 0.4400 - val_loss: 1.5643 - val_accuracy: 0.4288\n",
      "Epoch 5/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.5536 - accuracy: 0.4400 - val_loss: 1.5678 - val_accuracy: 0.4288\n",
      "Epoch 6/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5532 - accuracy: 0.4400 - val_loss: 1.5639 - val_accuracy: 0.4288\n",
      "Epoch 7/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5480 - accuracy: 0.4400 - val_loss: 1.5619 - val_accuracy: 0.4288\n",
      "Epoch 8/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5487 - accuracy: 0.4400 - val_loss: 1.5598 - val_accuracy: 0.4288\n",
      "Epoch 9/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5383 - accuracy: 0.4400 - val_loss: 1.5431 - val_accuracy: 0.4288\n",
      "Epoch 10/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.5184 - accuracy: 0.4406 - val_loss: 1.5461 - val_accuracy: 0.4288\n",
      "Epoch 11/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.4898 - accuracy: 0.4534 - val_loss: 1.5179 - val_accuracy: 0.4450\n",
      "Epoch 12/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.4764 - accuracy: 0.4644 - val_loss: 1.4785 - val_accuracy: 0.4550\n",
      "Epoch 13/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.4539 - accuracy: 0.4709 - val_loss: 1.4667 - val_accuracy: 0.4625\n",
      "Epoch 14/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.4480 - accuracy: 0.4741 - val_loss: 1.4441 - val_accuracy: 0.4625\n",
      "Epoch 15/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.4147 - accuracy: 0.4800 - val_loss: 1.4156 - val_accuracy: 0.4575\n",
      "Epoch 16/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.3935 - accuracy: 0.4822 - val_loss: 1.4002 - val_accuracy: 0.4625\n",
      "Epoch 17/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.3760 - accuracy: 0.4853 - val_loss: 1.3738 - val_accuracy: 0.4700\n",
      "Epoch 18/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.3573 - accuracy: 0.4959 - val_loss: 1.3628 - val_accuracy: 0.4750\n",
      "Epoch 19/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.3407 - accuracy: 0.4959 - val_loss: 1.3450 - val_accuracy: 0.4650\n",
      "Epoch 20/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.3266 - accuracy: 0.4975 - val_loss: 1.3240 - val_accuracy: 0.4775\n",
      "Epoch 21/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.3158 - accuracy: 0.5006 - val_loss: 1.3142 - val_accuracy: 0.4850\n",
      "Epoch 22/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.2981 - accuracy: 0.5147 - val_loss: 1.3027 - val_accuracy: 0.4712\n",
      "Epoch 23/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.2799 - accuracy: 0.5150 - val_loss: 1.3011 - val_accuracy: 0.4850\n",
      "Epoch 24/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.2785 - accuracy: 0.5109 - val_loss: 1.2842 - val_accuracy: 0.4888\n",
      "Epoch 25/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.2730 - accuracy: 0.5119 - val_loss: 1.2738 - val_accuracy: 0.4888\n",
      "Epoch 26/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.2574 - accuracy: 0.5216 - val_loss: 1.2755 - val_accuracy: 0.4825\n",
      "Epoch 27/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.2621 - accuracy: 0.5178 - val_loss: 1.2801 - val_accuracy: 0.4913\n",
      "Epoch 28/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.2397 - accuracy: 0.5225 - val_loss: 1.2500 - val_accuracy: 0.4900\n",
      "Epoch 29/30\n",
      "3200/3200 [==============================] - 0s 106us/sample - loss: 1.2437 - accuracy: 0.5288 - val_loss: 1.2442 - val_accuracy: 0.4863\n",
      "Epoch 30/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.2289 - accuracy: 0.5356 - val_loss: 1.2490 - val_accuracy: 0.4925\n",
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/30\n",
      "3200/3200 [==============================] - 1s 249us/sample - loss: 1.5809 - accuracy: 0.4353 - val_loss: 1.5745 - val_accuracy: 0.4288\n",
      "Epoch 2/30\n",
      "3200/3200 [==============================] - 0s 79us/sample - loss: 1.5551 - accuracy: 0.4400 - val_loss: 1.5776 - val_accuracy: 0.4288\n",
      "Epoch 3/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.5491 - accuracy: 0.4400 - val_loss: 1.5642 - val_accuracy: 0.4288\n",
      "Epoch 4/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.5514 - accuracy: 0.4400 - val_loss: 1.5702 - val_accuracy: 0.4288\n",
      "Epoch 5/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.5500 - accuracy: 0.4400 - val_loss: 1.5645 - val_accuracy: 0.4288\n",
      "Epoch 6/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5479 - accuracy: 0.4400 - val_loss: 1.5616 - val_accuracy: 0.4288\n",
      "Epoch 7/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.5454 - accuracy: 0.4400 - val_loss: 1.5630 - val_accuracy: 0.4288\n",
      "Epoch 8/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5353 - accuracy: 0.4400 - val_loss: 1.5502 - val_accuracy: 0.4288\n",
      "Epoch 9/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5318 - accuracy: 0.4400 - val_loss: 1.5359 - val_accuracy: 0.4288\n",
      "Epoch 10/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5175 - accuracy: 0.4403 - val_loss: 1.5184 - val_accuracy: 0.4288\n",
      "Epoch 11/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.4982 - accuracy: 0.4466 - val_loss: 1.5009 - val_accuracy: 0.4387\n",
      "Epoch 12/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.4636 - accuracy: 0.4716 - val_loss: 1.4680 - val_accuracy: 0.4538\n",
      "Epoch 13/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.4419 - accuracy: 0.4728 - val_loss: 1.4574 - val_accuracy: 0.4525\n",
      "Epoch 14/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.4200 - accuracy: 0.4784 - val_loss: 1.4276 - val_accuracy: 0.4650\n",
      "Epoch 15/30\n",
      "3200/3200 [==============================] - 0s 82us/sample - loss: 1.3888 - accuracy: 0.4853 - val_loss: 1.3918 - val_accuracy: 0.4675\n",
      "Epoch 16/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.3656 - accuracy: 0.4938 - val_loss: 1.3672 - val_accuracy: 0.4663\n",
      "Epoch 17/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.3463 - accuracy: 0.4972 - val_loss: 1.3389 - val_accuracy: 0.4737\n",
      "Epoch 18/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.3207 - accuracy: 0.5003 - val_loss: 1.3154 - val_accuracy: 0.4800\n",
      "Epoch 19/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.2914 - accuracy: 0.5128 - val_loss: 1.2992 - val_accuracy: 0.4787\n",
      "Epoch 20/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.2832 - accuracy: 0.5194 - val_loss: 1.2855 - val_accuracy: 0.4863\n",
      "Epoch 21/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.2721 - accuracy: 0.5194 - val_loss: 1.2682 - val_accuracy: 0.4925\n",
      "Epoch 22/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.2439 - accuracy: 0.5231 - val_loss: 1.2674 - val_accuracy: 0.4875\n",
      "Epoch 23/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.2489 - accuracy: 0.5259 - val_loss: 1.2541 - val_accuracy: 0.4938\n",
      "Epoch 24/30\n",
      "3200/3200 [==============================] - 0s 127us/sample - loss: 1.2387 - accuracy: 0.5281 - val_loss: 1.2412 - val_accuracy: 0.5050\n",
      "Epoch 25/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.2372 - accuracy: 0.5300 - val_loss: 1.2423 - val_accuracy: 0.4975\n",
      "Epoch 26/30\n",
      "3200/3200 [==============================] - 0s 118us/sample - loss: 1.2268 - accuracy: 0.5259 - val_loss: 1.2363 - val_accuracy: 0.5113\n",
      "Epoch 27/30\n",
      "3200/3200 [==============================] - 0s 118us/sample - loss: 1.2199 - accuracy: 0.5387 - val_loss: 1.2321 - val_accuracy: 0.5050\n",
      "Epoch 28/30\n",
      "3200/3200 [==============================] - 0s 118us/sample - loss: 1.2059 - accuracy: 0.5406 - val_loss: 1.2189 - val_accuracy: 0.5100\n",
      "Epoch 29/30\n",
      "3200/3200 [==============================] - 1s 278us/sample - loss: 1.2156 - accuracy: 0.5350 - val_loss: 1.2077 - val_accuracy: 0.5050\n",
      "Epoch 30/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.2058 - accuracy: 0.5419 - val_loss: 1.2148 - val_accuracy: 0.5163\n",
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/30\n",
      "3200/3200 [==============================] - 1s 303us/sample - loss: 1.5800 - accuracy: 0.4356 - val_loss: 1.5785 - val_accuracy: 0.4288\n",
      "Epoch 2/30\n",
      "3200/3200 [==============================] - 0s 76us/sample - loss: 1.5548 - accuracy: 0.4400 - val_loss: 1.5923 - val_accuracy: 0.4288\n",
      "Epoch 3/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5501 - accuracy: 0.4400 - val_loss: 1.5736 - val_accuracy: 0.4288\n",
      "Epoch 4/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5538 - accuracy: 0.4400 - val_loss: 1.5640 - val_accuracy: 0.4288\n",
      "Epoch 5/30\n",
      "3200/3200 [==============================] - 0s 72us/sample - loss: 1.5518 - accuracy: 0.4400 - val_loss: 1.5708 - val_accuracy: 0.4288\n",
      "Epoch 6/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.5487 - accuracy: 0.4400 - val_loss: 1.5663 - val_accuracy: 0.4288\n",
      "Epoch 7/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.5526 - accuracy: 0.4400 - val_loss: 1.5627 - val_accuracy: 0.4288\n",
      "Epoch 8/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.5462 - accuracy: 0.4400 - val_loss: 1.5639 - val_accuracy: 0.4288\n",
      "Epoch 9/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5404 - accuracy: 0.4400 - val_loss: 1.5598 - val_accuracy: 0.4288\n",
      "Epoch 10/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.5293 - accuracy: 0.4400 - val_loss: 1.5410 - val_accuracy: 0.4288\n",
      "Epoch 11/30\n",
      "3200/3200 [==============================] - 0s 72us/sample - loss: 1.5173 - accuracy: 0.4406 - val_loss: 1.5411 - val_accuracy: 0.4288\n",
      "Epoch 12/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5097 - accuracy: 0.4419 - val_loss: 1.5077 - val_accuracy: 0.4288\n",
      "Epoch 13/30\n",
      "3200/3200 [==============================] - 0s 88us/sample - loss: 1.4803 - accuracy: 0.4563 - val_loss: 1.4803 - val_accuracy: 0.4563\n",
      "Epoch 14/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.4581 - accuracy: 0.4675 - val_loss: 1.4705 - val_accuracy: 0.4588\n",
      "Epoch 15/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.4437 - accuracy: 0.4731 - val_loss: 1.4524 - val_accuracy: 0.4575\n",
      "Epoch 16/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.4159 - accuracy: 0.4716 - val_loss: 1.4308 - val_accuracy: 0.4663\n",
      "Epoch 17/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.3946 - accuracy: 0.4741 - val_loss: 1.3980 - val_accuracy: 0.4650\n",
      "Epoch 18/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.3875 - accuracy: 0.4800 - val_loss: 1.3899 - val_accuracy: 0.4700\n",
      "Epoch 19/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.3581 - accuracy: 0.4906 - val_loss: 1.3678 - val_accuracy: 0.4700\n",
      "Epoch 20/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.3436 - accuracy: 0.4903 - val_loss: 1.3519 - val_accuracy: 0.4775\n",
      "Epoch 21/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.3241 - accuracy: 0.5041 - val_loss: 1.3469 - val_accuracy: 0.4762\n",
      "Epoch 22/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.3247 - accuracy: 0.4950 - val_loss: 1.3212 - val_accuracy: 0.4800\n",
      "Epoch 23/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.3065 - accuracy: 0.5003 - val_loss: 1.3096 - val_accuracy: 0.4750\n",
      "Epoch 24/30\n",
      "3200/3200 [==============================] - 0s 91us/sample - loss: 1.2948 - accuracy: 0.5106 - val_loss: 1.2951 - val_accuracy: 0.4875\n",
      "Epoch 25/30\n",
      "3200/3200 [==============================] - 0s 88us/sample - loss: 1.2856 - accuracy: 0.5081 - val_loss: 1.2896 - val_accuracy: 0.4925\n",
      "Epoch 26/30\n",
      "3200/3200 [==============================] - 0s 90us/sample - loss: 1.2720 - accuracy: 0.5128 - val_loss: 1.2832 - val_accuracy: 0.4850\n",
      "Epoch 27/30\n",
      "3200/3200 [==============================] - 0s 86us/sample - loss: 1.2716 - accuracy: 0.5169 - val_loss: 1.2760 - val_accuracy: 0.4900\n",
      "Epoch 28/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.2600 - accuracy: 0.5178 - val_loss: 1.2670 - val_accuracy: 0.4975\n",
      "Epoch 29/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.2477 - accuracy: 0.5259 - val_loss: 1.2669 - val_accuracy: 0.5025\n",
      "Epoch 30/30\n",
      "3200/3200 [==============================] - 0s 91us/sample - loss: 1.2551 - accuracy: 0.5259 - val_loss: 1.2655 - val_accuracy: 0.4988\n",
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/30\n",
      "3200/3200 [==============================] - 1s 293us/sample - loss: 1.5941 - accuracy: 0.4331 - val_loss: 1.5686 - val_accuracy: 0.4288\n",
      "Epoch 2/30\n",
      "3200/3200 [==============================] - 0s 89us/sample - loss: 1.5603 - accuracy: 0.4400 - val_loss: 1.5646 - val_accuracy: 0.4288\n",
      "Epoch 3/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.5512 - accuracy: 0.4400 - val_loss: 1.5644 - val_accuracy: 0.4288\n",
      "Epoch 4/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.5574 - accuracy: 0.4400 - val_loss: 1.5661 - val_accuracy: 0.4288\n",
      "Epoch 5/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.5515 - accuracy: 0.4400 - val_loss: 1.5659 - val_accuracy: 0.4288\n",
      "Epoch 6/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5486 - accuracy: 0.4400 - val_loss: 1.5637 - val_accuracy: 0.4288\n",
      "Epoch 7/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.5486 - accuracy: 0.4400 - val_loss: 1.5656 - val_accuracy: 0.4288\n",
      "Epoch 8/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5453 - accuracy: 0.4400 - val_loss: 1.5584 - val_accuracy: 0.4288\n",
      "Epoch 9/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.5404 - accuracy: 0.4400 - val_loss: 1.5526 - val_accuracy: 0.4288\n",
      "Epoch 10/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5327 - accuracy: 0.4400 - val_loss: 1.5387 - val_accuracy: 0.4288\n",
      "Epoch 11/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5203 - accuracy: 0.4400 - val_loss: 1.5316 - val_accuracy: 0.4288\n",
      "Epoch 12/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.5011 - accuracy: 0.4406 - val_loss: 1.5081 - val_accuracy: 0.4288\n",
      "Epoch 13/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.4759 - accuracy: 0.4578 - val_loss: 1.4916 - val_accuracy: 0.4588\n",
      "Epoch 14/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.4632 - accuracy: 0.4672 - val_loss: 1.4776 - val_accuracy: 0.4575\n",
      "Epoch 15/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.4576 - accuracy: 0.4762 - val_loss: 1.4641 - val_accuracy: 0.4600\n",
      "Epoch 16/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.4329 - accuracy: 0.4825 - val_loss: 1.4435 - val_accuracy: 0.4688\n",
      "Epoch 17/30\n",
      "3200/3200 [==============================] - 0s 96us/sample - loss: 1.4218 - accuracy: 0.4812 - val_loss: 1.4217 - val_accuracy: 0.4688\n",
      "Epoch 18/30\n",
      "3200/3200 [==============================] - 0s 91us/sample - loss: 1.3979 - accuracy: 0.4863 - val_loss: 1.3974 - val_accuracy: 0.4725\n",
      "Epoch 19/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.3690 - accuracy: 0.4888 - val_loss: 1.3724 - val_accuracy: 0.4725\n",
      "Epoch 20/30\n",
      "3200/3200 [==============================] - 0s 86us/sample - loss: 1.3602 - accuracy: 0.4944 - val_loss: 1.3525 - val_accuracy: 0.4787\n",
      "Epoch 21/30\n",
      "3200/3200 [==============================] - 0s 87us/sample - loss: 1.3443 - accuracy: 0.5025 - val_loss: 1.3366 - val_accuracy: 0.4812\n",
      "Epoch 22/30\n",
      "3200/3200 [==============================] - 0s 89us/sample - loss: 1.3385 - accuracy: 0.5000 - val_loss: 1.3282 - val_accuracy: 0.4812\n",
      "Epoch 23/30\n",
      "3200/3200 [==============================] - 0s 89us/sample - loss: 1.3086 - accuracy: 0.5109 - val_loss: 1.3052 - val_accuracy: 0.4863\n",
      "Epoch 24/30\n",
      "3200/3200 [==============================] - 0s 75us/sample - loss: 1.3077 - accuracy: 0.5041 - val_loss: 1.3068 - val_accuracy: 0.4900\n",
      "Epoch 25/30\n",
      "3200/3200 [==============================] - 0s 87us/sample - loss: 1.2999 - accuracy: 0.5056 - val_loss: 1.2959 - val_accuracy: 0.4850\n",
      "Epoch 26/30\n",
      "3200/3200 [==============================] - 0s 89us/sample - loss: 1.2956 - accuracy: 0.5113 - val_loss: 1.2860 - val_accuracy: 0.4963\n",
      "Epoch 27/30\n",
      "3200/3200 [==============================] - 0s 87us/sample - loss: 1.2779 - accuracy: 0.5125 - val_loss: 1.2839 - val_accuracy: 0.4875\n",
      "Epoch 28/30\n",
      "3200/3200 [==============================] - 0s 100us/sample - loss: 1.2743 - accuracy: 0.5213 - val_loss: 1.2649 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "3200/3200 [==============================] - 0s 75us/sample - loss: 1.2764 - accuracy: 0.5113 - val_loss: 1.2662 - val_accuracy: 0.4963\n",
      "Epoch 30/30\n",
      "3200/3200 [==============================] - 0s 97us/sample - loss: 1.2622 - accuracy: 0.5200 - val_loss: 1.2639 - val_accuracy: 0.5000\n",
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e284e779bc90496ba36e37a8272aa494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4160 samples, validate on 1040 samples\n",
      "Epoch 1/30\n",
      "4160/4160 [==============================] - 1s 215us/sample - loss: 1.5886 - accuracy: 0.4329 - val_loss: 1.5994 - val_accuracy: 0.4000\n",
      "Epoch 2/30\n",
      "4160/4160 [==============================] - 0s 86us/sample - loss: 1.5598 - accuracy: 0.4387 - val_loss: 1.5878 - val_accuracy: 0.4000\n",
      "Epoch 3/30\n",
      "4160/4160 [==============================] - 0s 73us/sample - loss: 1.5537 - accuracy: 0.4387 - val_loss: 1.5886 - val_accuracy: 0.4000\n",
      "Epoch 4/30\n",
      "4160/4160 [==============================] - 0s 73us/sample - loss: 1.5522 - accuracy: 0.4387 - val_loss: 1.5905 - val_accuracy: 0.4000\n",
      "Epoch 5/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.5517 - accuracy: 0.4387 - val_loss: 1.5850 - val_accuracy: 0.4000\n",
      "Epoch 6/30\n",
      "4160/4160 [==============================] - 0s 73us/sample - loss: 1.5539 - accuracy: 0.4387 - val_loss: 1.5901 - val_accuracy: 0.4000\n",
      "Epoch 7/30\n",
      "4160/4160 [==============================] - 0s 82us/sample - loss: 1.5475 - accuracy: 0.4387 - val_loss: 1.5750 - val_accuracy: 0.4000\n",
      "Epoch 8/30\n",
      "4160/4160 [==============================] - 0s 82us/sample - loss: 1.5237 - accuracy: 0.4387 - val_loss: 1.5594 - val_accuracy: 0.4000\n",
      "Epoch 9/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.4876 - accuracy: 0.4536 - val_loss: 1.5043 - val_accuracy: 0.4423\n",
      "Epoch 10/30\n",
      "4160/4160 [==============================] - 0s 84us/sample - loss: 1.4573 - accuracy: 0.4709 - val_loss: 1.5035 - val_accuracy: 0.4279\n",
      "Epoch 11/30\n",
      "4160/4160 [==============================] - 0s 84us/sample - loss: 1.4301 - accuracy: 0.4733 - val_loss: 1.4657 - val_accuracy: 0.4481\n",
      "Epoch 12/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.3971 - accuracy: 0.4786 - val_loss: 1.4212 - val_accuracy: 0.4712\n",
      "Epoch 13/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.3845 - accuracy: 0.4853 - val_loss: 1.3873 - val_accuracy: 0.4750\n",
      "Epoch 14/30\n",
      "4160/4160 [==============================] - 0s 82us/sample - loss: 1.3514 - accuracy: 0.4894 - val_loss: 1.3650 - val_accuracy: 0.4760\n",
      "Epoch 15/30\n",
      "4160/4160 [==============================] - 0s 84us/sample - loss: 1.3341 - accuracy: 0.4962 - val_loss: 1.3356 - val_accuracy: 0.4798\n",
      "Epoch 16/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.3064 - accuracy: 0.5060 - val_loss: 1.3183 - val_accuracy: 0.4856\n",
      "Epoch 17/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.2989 - accuracy: 0.5070 - val_loss: 1.3178 - val_accuracy: 0.4837\n",
      "Epoch 18/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.2938 - accuracy: 0.5127 - val_loss: 1.2996 - val_accuracy: 0.4875\n",
      "Epoch 19/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.2751 - accuracy: 0.5204 - val_loss: 1.2792 - val_accuracy: 0.4981\n",
      "Epoch 20/30\n",
      "4160/4160 [==============================] - 0s 73us/sample - loss: 1.2656 - accuracy: 0.5212 - val_loss: 1.2807 - val_accuracy: 0.4971\n",
      "Epoch 21/30\n",
      "4160/4160 [==============================] - 0s 103us/sample - loss: 1.2578 - accuracy: 0.5300 - val_loss: 1.2548 - val_accuracy: 0.5240\n",
      "Epoch 22/30\n",
      "4160/4160 [==============================] - 0s 73us/sample - loss: 1.2515 - accuracy: 0.5197 - val_loss: 1.2691 - val_accuracy: 0.5010\n",
      "Epoch 23/30\n",
      "4160/4160 [==============================] - 0s 101us/sample - loss: 1.2495 - accuracy: 0.5188 - val_loss: 1.2498 - val_accuracy: 0.5135\n",
      "Epoch 24/30\n",
      "4160/4160 [==============================] - 0s 101us/sample - loss: 1.2289 - accuracy: 0.5308 - val_loss: 1.2372 - val_accuracy: 0.5240\n",
      "Epoch 25/30\n",
      "4160/4160 [==============================] - 0s 73us/sample - loss: 1.2194 - accuracy: 0.5322 - val_loss: 1.2575 - val_accuracy: 0.5212\n",
      "Epoch 26/30\n",
      "4160/4160 [==============================] - 0s 102us/sample - loss: 1.2256 - accuracy: 0.5373 - val_loss: 1.2352 - val_accuracy: 0.5173\n",
      "Epoch 27/30\n",
      "4160/4160 [==============================] - 0s 102us/sample - loss: 1.2176 - accuracy: 0.5337 - val_loss: 1.2258 - val_accuracy: 0.5260\n",
      "Epoch 28/30\n",
      "4160/4160 [==============================] - 0s 103us/sample - loss: 1.2155 - accuracy: 0.5356 - val_loss: 1.2211 - val_accuracy: 0.5221\n",
      "Epoch 29/30\n",
      "4160/4160 [==============================] - 0s 73us/sample - loss: 1.2011 - accuracy: 0.5356 - val_loss: 1.2217 - val_accuracy: 0.5212\n",
      "Epoch 30/30\n",
      "4160/4160 [==============================] - 0s 102us/sample - loss: 1.2086 - accuracy: 0.5377 - val_loss: 1.2121 - val_accuracy: 0.5327\n",
      "Train on 4160 samples, validate on 1040 samples\n",
      "Epoch 1/30\n",
      "4160/4160 [==============================] - 1s 274us/sample - loss: 1.5857 - accuracy: 0.4344 - val_loss: 1.5959 - val_accuracy: 0.4000\n",
      "Epoch 2/30\n",
      "4160/4160 [==============================] - 0s 87us/sample - loss: 1.5555 - accuracy: 0.4387 - val_loss: 1.5932 - val_accuracy: 0.4000\n",
      "Epoch 3/30\n",
      "4160/4160 [==============================] - 0s 72us/sample - loss: 1.5539 - accuracy: 0.4387 - val_loss: 1.5950 - val_accuracy: 0.4000\n",
      "Epoch 4/30\n",
      "4160/4160 [==============================] - 0s 73us/sample - loss: 1.5574 - accuracy: 0.4387 - val_loss: 1.5961 - val_accuracy: 0.4000\n",
      "Epoch 5/30\n",
      "4160/4160 [==============================] - 0s 73us/sample - loss: 1.5563 - accuracy: 0.4387 - val_loss: 1.5947 - val_accuracy: 0.4000\n",
      "Epoch 6/30\n",
      "4160/4160 [==============================] - 0s 84us/sample - loss: 1.5547 - accuracy: 0.4387 - val_loss: 1.5880 - val_accuracy: 0.4000\n",
      "Epoch 7/30\n",
      "4160/4160 [==============================] - 0s 72us/sample - loss: 1.5530 - accuracy: 0.4387 - val_loss: 1.5903 - val_accuracy: 0.4000\n",
      "Epoch 8/30\n",
      "4160/4160 [==============================] - 0s 82us/sample - loss: 1.5462 - accuracy: 0.4387 - val_loss: 1.5851 - val_accuracy: 0.4000\n",
      "Epoch 9/30\n",
      "4160/4160 [==============================] - 0s 73us/sample - loss: 1.5517 - accuracy: 0.4387 - val_loss: 1.5870 - val_accuracy: 0.4000\n",
      "Epoch 10/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.5413 - accuracy: 0.4387 - val_loss: 1.5749 - val_accuracy: 0.4000\n",
      "Epoch 11/30\n",
      "4160/4160 [==============================] - 0s 82us/sample - loss: 1.5217 - accuracy: 0.4387 - val_loss: 1.5529 - val_accuracy: 0.4000\n",
      "Epoch 12/30\n",
      "4160/4160 [==============================] - 0s 82us/sample - loss: 1.4989 - accuracy: 0.4464 - val_loss: 1.5093 - val_accuracy: 0.4375\n",
      "Epoch 13/30\n",
      "4160/4160 [==============================] - 0s 82us/sample - loss: 1.4522 - accuracy: 0.4685 - val_loss: 1.4679 - val_accuracy: 0.4596\n",
      "Epoch 14/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.4251 - accuracy: 0.4784 - val_loss: 1.4325 - val_accuracy: 0.4702\n",
      "Epoch 15/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.3929 - accuracy: 0.4851 - val_loss: 1.4092 - val_accuracy: 0.4567\n",
      "Epoch 16/30\n",
      "4160/4160 [==============================] - 0s 84us/sample - loss: 1.3694 - accuracy: 0.4892 - val_loss: 1.3656 - val_accuracy: 0.4760\n",
      "Epoch 17/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.3404 - accuracy: 0.4930 - val_loss: 1.3573 - val_accuracy: 0.4837\n",
      "Epoch 18/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.3267 - accuracy: 0.4974 - val_loss: 1.3359 - val_accuracy: 0.4788\n",
      "Epoch 19/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.3214 - accuracy: 0.5012 - val_loss: 1.3080 - val_accuracy: 0.4808\n",
      "Epoch 20/30\n",
      "4160/4160 [==============================] - 0s 73us/sample - loss: 1.3020 - accuracy: 0.5123 - val_loss: 1.3231 - val_accuracy: 0.4981\n",
      "Epoch 21/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.2956 - accuracy: 0.5123 - val_loss: 1.2981 - val_accuracy: 0.4971\n",
      "Epoch 22/30\n",
      "4160/4160 [==============================] - 0s 82us/sample - loss: 1.2839 - accuracy: 0.5142 - val_loss: 1.2765 - val_accuracy: 0.5029\n",
      "Epoch 23/30\n",
      "4160/4160 [==============================] - 0s 73us/sample - loss: 1.2693 - accuracy: 0.5156 - val_loss: 1.2772 - val_accuracy: 0.5010\n",
      "Epoch 24/30\n",
      "4160/4160 [==============================] - 0s 73us/sample - loss: 1.2692 - accuracy: 0.5216 - val_loss: 1.2802 - val_accuracy: 0.5096\n",
      "Epoch 25/30\n",
      "4160/4160 [==============================] - 0s 84us/sample - loss: 1.2595 - accuracy: 0.5180 - val_loss: 1.2585 - val_accuracy: 0.5163\n",
      "Epoch 26/30\n",
      "4160/4160 [==============================] - 0s 82us/sample - loss: 1.2406 - accuracy: 0.5322 - val_loss: 1.2452 - val_accuracy: 0.5192\n",
      "Epoch 27/30\n",
      "4160/4160 [==============================] - 0s 84us/sample - loss: 1.2400 - accuracy: 0.5267 - val_loss: 1.2421 - val_accuracy: 0.5231\n",
      "Epoch 28/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.2382 - accuracy: 0.5276 - val_loss: 1.2420 - val_accuracy: 0.5346\n",
      "Epoch 29/30\n",
      "4160/4160 [==============================] - 0s 82us/sample - loss: 1.2200 - accuracy: 0.5334 - val_loss: 1.2352 - val_accuracy: 0.5327\n",
      "Epoch 30/30\n",
      "4160/4160 [==============================] - 0s 73us/sample - loss: 1.2175 - accuracy: 0.5346 - val_loss: 1.2416 - val_accuracy: 0.5087\n",
      "Train on 4160 samples, validate on 1040 samples\n",
      "Epoch 1/30\n",
      "4160/4160 [==============================] - 1s 218us/sample - loss: 1.5733 - accuracy: 0.4358 - val_loss: 1.5927 - val_accuracy: 0.4000\n",
      "Epoch 2/30\n",
      "4160/4160 [==============================] - 0s 76us/sample - loss: 1.5548 - accuracy: 0.4387 - val_loss: 1.5947 - val_accuracy: 0.4000\n",
      "Epoch 3/30\n",
      "4160/4160 [==============================] - 0s 73us/sample - loss: 1.5527 - accuracy: 0.4387 - val_loss: 1.5930 - val_accuracy: 0.4000\n",
      "Epoch 4/30\n",
      "4160/4160 [==============================] - 0s 85us/sample - loss: 1.5570 - accuracy: 0.4387 - val_loss: 1.5889 - val_accuracy: 0.4000\n",
      "Epoch 5/30\n",
      "4160/4160 [==============================] - 0s 74us/sample - loss: 1.5527 - accuracy: 0.4387 - val_loss: 1.5918 - val_accuracy: 0.4000\n",
      "Epoch 6/30\n",
      "4160/4160 [==============================] - 0s 73us/sample - loss: 1.5544 - accuracy: 0.4387 - val_loss: 1.5906 - val_accuracy: 0.4000\n",
      "Epoch 7/30\n",
      "4160/4160 [==============================] - 0s 84us/sample - loss: 1.5545 - accuracy: 0.4387 - val_loss: 1.5868 - val_accuracy: 0.4000\n",
      "Epoch 8/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.5435 - accuracy: 0.4387 - val_loss: 1.5806 - val_accuracy: 0.4000\n",
      "Epoch 9/30\n",
      "4160/4160 [==============================] - 0s 86us/sample - loss: 1.5289 - accuracy: 0.4387 - val_loss: 1.5477 - val_accuracy: 0.4000\n",
      "Epoch 10/30\n",
      "4160/4160 [==============================] - 0s 87us/sample - loss: 1.5000 - accuracy: 0.4510 - val_loss: 1.5119 - val_accuracy: 0.4385\n",
      "Epoch 11/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.4732 - accuracy: 0.4647 - val_loss: 1.4882 - val_accuracy: 0.4538\n",
      "Epoch 12/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.4510 - accuracy: 0.4702 - val_loss: 1.4727 - val_accuracy: 0.4510\n",
      "Epoch 13/30\n",
      "4160/4160 [==============================] - 0s 84us/sample - loss: 1.4237 - accuracy: 0.4774 - val_loss: 1.4359 - val_accuracy: 0.4673\n",
      "Epoch 14/30\n",
      "4160/4160 [==============================] - 0s 84us/sample - loss: 1.3973 - accuracy: 0.4800 - val_loss: 1.4011 - val_accuracy: 0.4750\n",
      "Epoch 15/30\n",
      "4160/4160 [==============================] - 0s 86us/sample - loss: 1.3624 - accuracy: 0.4909 - val_loss: 1.3786 - val_accuracy: 0.4760\n",
      "Epoch 16/30\n",
      "4160/4160 [==============================] - 0s 84us/sample - loss: 1.3387 - accuracy: 0.5005 - val_loss: 1.3481 - val_accuracy: 0.4837\n",
      "Epoch 17/30\n",
      "4160/4160 [==============================] - 0s 85us/sample - loss: 1.3105 - accuracy: 0.5043 - val_loss: 1.3380 - val_accuracy: 0.4808\n",
      "Epoch 18/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.3058 - accuracy: 0.5002 - val_loss: 1.3087 - val_accuracy: 0.4904\n",
      "Epoch 19/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.2843 - accuracy: 0.5147 - val_loss: 1.2947 - val_accuracy: 0.4952\n",
      "Epoch 20/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.2770 - accuracy: 0.5156 - val_loss: 1.2813 - val_accuracy: 0.5058\n",
      "Epoch 21/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.2673 - accuracy: 0.5228 - val_loss: 1.2700 - val_accuracy: 0.5144\n",
      "Epoch 22/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.2512 - accuracy: 0.5248 - val_loss: 1.2621 - val_accuracy: 0.5192\n",
      "Epoch 23/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.2459 - accuracy: 0.5296 - val_loss: 1.2587 - val_accuracy: 0.5115\n",
      "Epoch 24/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.2364 - accuracy: 0.5276 - val_loss: 1.2445 - val_accuracy: 0.5192\n",
      "Epoch 25/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.2377 - accuracy: 0.5255 - val_loss: 1.2362 - val_accuracy: 0.5269\n",
      "Epoch 26/30\n",
      "4160/4160 [==============================] - 0s 92us/sample - loss: 1.2257 - accuracy: 0.5257 - val_loss: 1.2334 - val_accuracy: 0.5279\n",
      "Epoch 27/30\n",
      "4160/4160 [==============================] - 0s 101us/sample - loss: 1.2283 - accuracy: 0.5305 - val_loss: 1.2298 - val_accuracy: 0.5327\n",
      "Epoch 28/30\n",
      "4160/4160 [==============================] - 0s 74us/sample - loss: 1.2121 - accuracy: 0.5310 - val_loss: 1.2416 - val_accuracy: 0.5202\n",
      "Epoch 29/30\n",
      "4160/4160 [==============================] - 0s 93us/sample - loss: 1.2076 - accuracy: 0.5406 - val_loss: 1.2293 - val_accuracy: 0.5231\n",
      "Epoch 30/30\n",
      "4160/4160 [==============================] - 0s 93us/sample - loss: 1.2071 - accuracy: 0.5317 - val_loss: 1.2158 - val_accuracy: 0.5394\n",
      "Train on 4160 samples, validate on 1040 samples\n",
      "Epoch 1/30\n",
      "4160/4160 [==============================] - 1s 255us/sample - loss: 1.5863 - accuracy: 0.4351 - val_loss: 1.5997 - val_accuracy: 0.4000\n",
      "Epoch 2/30\n",
      "4160/4160 [==============================] - 0s 77us/sample - loss: 1.5569 - accuracy: 0.4387 - val_loss: 1.6005 - val_accuracy: 0.4000\n",
      "Epoch 3/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.5556 - accuracy: 0.4387 - val_loss: 1.5900 - val_accuracy: 0.4000\n",
      "Epoch 4/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.5581 - accuracy: 0.4387 - val_loss: 1.5865 - val_accuracy: 0.4000\n",
      "Epoch 5/30\n",
      "4160/4160 [==============================] - 0s 73us/sample - loss: 1.5543 - accuracy: 0.4387 - val_loss: 1.5914 - val_accuracy: 0.4000\n",
      "Epoch 6/30\n",
      "4160/4160 [==============================] - 0s 73us/sample - loss: 1.5493 - accuracy: 0.4387 - val_loss: 1.5866 - val_accuracy: 0.4000\n",
      "Epoch 7/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.5405 - accuracy: 0.4387 - val_loss: 1.5661 - val_accuracy: 0.4000\n",
      "Epoch 8/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.5191 - accuracy: 0.4392 - val_loss: 1.5387 - val_accuracy: 0.4000\n",
      "Epoch 9/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.4937 - accuracy: 0.4462 - val_loss: 1.5036 - val_accuracy: 0.4356\n",
      "Epoch 10/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.4638 - accuracy: 0.4620 - val_loss: 1.4774 - val_accuracy: 0.4481\n",
      "Epoch 11/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.4338 - accuracy: 0.4764 - val_loss: 1.4449 - val_accuracy: 0.4606\n",
      "Epoch 12/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.3937 - accuracy: 0.4825 - val_loss: 1.4122 - val_accuracy: 0.4663\n",
      "Epoch 13/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.3681 - accuracy: 0.4906 - val_loss: 1.3678 - val_accuracy: 0.4740\n",
      "Epoch 14/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.3358 - accuracy: 0.4990 - val_loss: 1.3441 - val_accuracy: 0.4798\n",
      "Epoch 15/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.3166 - accuracy: 0.5060 - val_loss: 1.3226 - val_accuracy: 0.4837\n",
      "Epoch 16/30\n",
      "4160/4160 [==============================] - 0s 73us/sample - loss: 1.2991 - accuracy: 0.5108 - val_loss: 1.3537 - val_accuracy: 0.4856\n",
      "Epoch 17/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.2959 - accuracy: 0.5115 - val_loss: 1.2935 - val_accuracy: 0.4962\n",
      "Epoch 18/30\n",
      "4160/4160 [==============================] - 0s 84us/sample - loss: 1.2755 - accuracy: 0.5108 - val_loss: 1.2836 - val_accuracy: 0.5096\n",
      "Epoch 19/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.2632 - accuracy: 0.5255 - val_loss: 1.2597 - val_accuracy: 0.5154\n",
      "Epoch 20/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.2478 - accuracy: 0.5219 - val_loss: 1.2544 - val_accuracy: 0.5192\n",
      "Epoch 21/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.2443 - accuracy: 0.5228 - val_loss: 1.2480 - val_accuracy: 0.5260\n",
      "Epoch 22/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.2301 - accuracy: 0.5288 - val_loss: 1.2392 - val_accuracy: 0.5154\n",
      "Epoch 23/30\n",
      "4160/4160 [==============================] - 0s 74us/sample - loss: 1.2237 - accuracy: 0.5291 - val_loss: 1.2418 - val_accuracy: 0.5337\n",
      "Epoch 24/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.2069 - accuracy: 0.5387 - val_loss: 1.2218 - val_accuracy: 0.5260\n",
      "Epoch 25/30\n",
      "4160/4160 [==============================] - 0s 74us/sample - loss: 1.2111 - accuracy: 0.5421 - val_loss: 1.2222 - val_accuracy: 0.5240\n",
      "Epoch 26/30\n",
      "4160/4160 [==============================] - 0s 74us/sample - loss: 1.2056 - accuracy: 0.5361 - val_loss: 1.2302 - val_accuracy: 0.5298\n",
      "Epoch 27/30\n",
      "4160/4160 [==============================] - 1s 129us/sample - loss: 1.2006 - accuracy: 0.5397 - val_loss: 1.2105 - val_accuracy: 0.5356\n",
      "Epoch 28/30\n",
      "4160/4160 [==============================] - 1s 298us/sample - loss: 1.1990 - accuracy: 0.5471 - val_loss: 1.2063 - val_accuracy: 0.5365\n",
      "Epoch 29/30\n",
      "4160/4160 [==============================] - 1s 289us/sample - loss: 1.1901 - accuracy: 0.5466 - val_loss: 1.2036 - val_accuracy: 0.5462\n",
      "Epoch 30/30\n",
      "4160/4160 [==============================] - 1s 288us/sample - loss: 1.1838 - accuracy: 0.5421 - val_loss: 1.1992 - val_accuracy: 0.5375\n",
      "Train on 4160 samples, validate on 1040 samples\n",
      "Epoch 1/30\n",
      "4160/4160 [==============================] - 1s 256us/sample - loss: 1.5831 - accuracy: 0.4353 - val_loss: 1.5945 - val_accuracy: 0.4000\n",
      "Epoch 2/30\n",
      "4160/4160 [==============================] - 0s 88us/sample - loss: 1.5559 - accuracy: 0.4387 - val_loss: 1.5862 - val_accuracy: 0.4000\n",
      "Epoch 3/30\n",
      "4160/4160 [==============================] - 0s 74us/sample - loss: 1.5587 - accuracy: 0.4387 - val_loss: 1.5892 - val_accuracy: 0.4000\n",
      "Epoch 4/30\n",
      "4160/4160 [==============================] - 0s 73us/sample - loss: 1.5531 - accuracy: 0.4387 - val_loss: 1.5951 - val_accuracy: 0.4000\n",
      "Epoch 5/30\n",
      "4160/4160 [==============================] - 0s 73us/sample - loss: 1.5517 - accuracy: 0.4387 - val_loss: 1.5987 - val_accuracy: 0.4000\n",
      "Epoch 6/30\n",
      "4160/4160 [==============================] - 0s 73us/sample - loss: 1.5526 - accuracy: 0.4387 - val_loss: 1.5865 - val_accuracy: 0.4000\n",
      "Epoch 7/30\n",
      "4160/4160 [==============================] - 0s 73us/sample - loss: 1.5493 - accuracy: 0.4387 - val_loss: 1.5933 - val_accuracy: 0.4000\n",
      "Epoch 8/30\n",
      "4160/4160 [==============================] - 0s 85us/sample - loss: 1.5466 - accuracy: 0.4387 - val_loss: 1.5825 - val_accuracy: 0.4000\n",
      "Epoch 9/30\n",
      "4160/4160 [==============================] - 0s 73us/sample - loss: 1.5329 - accuracy: 0.4387 - val_loss: 1.5830 - val_accuracy: 0.4000\n",
      "Epoch 10/30\n",
      "4160/4160 [==============================] - 0s 85us/sample - loss: 1.5122 - accuracy: 0.4425 - val_loss: 1.5226 - val_accuracy: 0.4279\n",
      "Epoch 11/30\n",
      "4160/4160 [==============================] - 0s 73us/sample - loss: 1.4902 - accuracy: 0.4601 - val_loss: 1.5240 - val_accuracy: 0.4471\n",
      "Epoch 12/30\n",
      "4160/4160 [==============================] - 0s 85us/sample - loss: 1.4618 - accuracy: 0.4673 - val_loss: 1.4836 - val_accuracy: 0.4452\n",
      "Epoch 13/30\n",
      "4160/4160 [==============================] - 0s 84us/sample - loss: 1.4275 - accuracy: 0.4757 - val_loss: 1.4571 - val_accuracy: 0.4500\n",
      "Epoch 14/30\n",
      "4160/4160 [==============================] - 0s 82us/sample - loss: 1.4069 - accuracy: 0.4791 - val_loss: 1.4212 - val_accuracy: 0.4673\n",
      "Epoch 15/30\n",
      "4160/4160 [==============================] - 0s 84us/sample - loss: 1.3693 - accuracy: 0.4897 - val_loss: 1.3904 - val_accuracy: 0.4817\n",
      "Epoch 16/30\n",
      "4160/4160 [==============================] - 0s 90us/sample - loss: 1.3483 - accuracy: 0.4954 - val_loss: 1.3578 - val_accuracy: 0.4827\n",
      "Epoch 17/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.3169 - accuracy: 0.5000 - val_loss: 1.3454 - val_accuracy: 0.4856\n",
      "Epoch 18/30\n",
      "4160/4160 [==============================] - 0s 84us/sample - loss: 1.3022 - accuracy: 0.5099 - val_loss: 1.3042 - val_accuracy: 0.4904\n",
      "Epoch 19/30\n",
      "4160/4160 [==============================] - 0s 73us/sample - loss: 1.2915 - accuracy: 0.5094 - val_loss: 1.3259 - val_accuracy: 0.4788\n",
      "Epoch 20/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.2737 - accuracy: 0.5130 - val_loss: 1.2833 - val_accuracy: 0.5048\n",
      "Epoch 21/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.2650 - accuracy: 0.5173 - val_loss: 1.2806 - val_accuracy: 0.5115\n",
      "Epoch 22/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.2476 - accuracy: 0.5243 - val_loss: 1.2561 - val_accuracy: 0.5125\n",
      "Epoch 23/30\n",
      "4160/4160 [==============================] - 0s 73us/sample - loss: 1.2522 - accuracy: 0.5240 - val_loss: 1.2593 - val_accuracy: 0.5029\n",
      "Epoch 24/30\n",
      "4160/4160 [==============================] - 0s 74us/sample - loss: 1.2385 - accuracy: 0.5269 - val_loss: 1.2675 - val_accuracy: 0.5058\n",
      "Epoch 25/30\n",
      "4160/4160 [==============================] - 0s 84us/sample - loss: 1.2326 - accuracy: 0.5281 - val_loss: 1.2398 - val_accuracy: 0.5231\n",
      "Epoch 26/30\n",
      "4160/4160 [==============================] - 0s 74us/sample - loss: 1.2215 - accuracy: 0.5320 - val_loss: 1.2444 - val_accuracy: 0.5106\n",
      "Epoch 27/30\n",
      "4160/4160 [==============================] - 0s 84us/sample - loss: 1.2214 - accuracy: 0.5276 - val_loss: 1.2338 - val_accuracy: 0.5202\n",
      "Epoch 28/30\n",
      "4160/4160 [==============================] - 0s 84us/sample - loss: 1.2095 - accuracy: 0.5368 - val_loss: 1.2329 - val_accuracy: 0.5240\n",
      "Epoch 29/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.2112 - accuracy: 0.5327 - val_loss: 1.2178 - val_accuracy: 0.5337\n",
      "Epoch 30/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.2065 - accuracy: 0.5341 - val_loss: 1.2109 - val_accuracy: 0.5346\n",
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4fbded93fc640289b6816a63590827c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5492 samples, validate on 1376 samples\n",
      "Epoch 1/30\n",
      "5492/5492 [==============================] - 1s 199us/sample - loss: 1.5840 - accuracy: 0.4306 - val_loss: 1.5803 - val_accuracy: 0.4179\n",
      "Epoch 2/30\n",
      "5492/5492 [==============================] - 0s 76us/sample - loss: 1.5655 - accuracy: 0.4345 - val_loss: 1.5804 - val_accuracy: 0.4179\n",
      "Epoch 3/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5626 - accuracy: 0.4345 - val_loss: 1.5756 - val_accuracy: 0.4179\n",
      "Epoch 4/30\n",
      "5492/5492 [==============================] - 0s 83us/sample - loss: 1.5585 - accuracy: 0.4345 - val_loss: 1.5698 - val_accuracy: 0.4179\n",
      "Epoch 5/30\n",
      "5492/5492 [==============================] - 0s 83us/sample - loss: 1.5545 - accuracy: 0.4345 - val_loss: 1.5688 - val_accuracy: 0.4179\n",
      "Epoch 6/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5426 - accuracy: 0.4345 - val_loss: 1.5450 - val_accuracy: 0.4179\n",
      "Epoch 7/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5028 - accuracy: 0.4405 - val_loss: 1.4881 - val_accuracy: 0.4411\n",
      "Epoch 8/30\n",
      "5492/5492 [==============================] - 0s 83us/sample - loss: 1.4772 - accuracy: 0.4599 - val_loss: 1.4398 - val_accuracy: 0.4571\n",
      "Epoch 9/30\n",
      "5492/5492 [==============================] - 0s 83us/sample - loss: 1.4342 - accuracy: 0.4703 - val_loss: 1.4071 - val_accuracy: 0.4775\n",
      "Epoch 10/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.4065 - accuracy: 0.4798 - val_loss: 1.3752 - val_accuracy: 0.4600\n",
      "Epoch 11/30\n",
      "5492/5492 [==============================] - 0s 83us/sample - loss: 1.3757 - accuracy: 0.4878 - val_loss: 1.3483 - val_accuracy: 0.4833\n",
      "Epoch 12/30\n",
      "5492/5492 [==============================] - 0s 83us/sample - loss: 1.3570 - accuracy: 0.4880 - val_loss: 1.3149 - val_accuracy: 0.4862\n",
      "Epoch 13/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3367 - accuracy: 0.4958 - val_loss: 1.3013 - val_accuracy: 0.4949\n",
      "Epoch 14/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3282 - accuracy: 0.5024 - val_loss: 1.2755 - val_accuracy: 0.4884\n",
      "Epoch 15/30\n",
      "5492/5492 [==============================] - 0s 83us/sample - loss: 1.3108 - accuracy: 0.5053 - val_loss: 1.2551 - val_accuracy: 0.4993\n",
      "Epoch 16/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3062 - accuracy: 0.5027 - val_loss: 1.2470 - val_accuracy: 0.5087\n",
      "Epoch 17/30\n",
      "5492/5492 [==============================] - 0s 83us/sample - loss: 1.2793 - accuracy: 0.5135 - val_loss: 1.2390 - val_accuracy: 0.5138\n",
      "Epoch 18/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2738 - accuracy: 0.5228 - val_loss: 1.2324 - val_accuracy: 0.5225\n",
      "Epoch 19/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2649 - accuracy: 0.5138 - val_loss: 1.2132 - val_accuracy: 0.5291\n",
      "Epoch 20/30\n",
      "5492/5492 [==============================] - 1s 247us/sample - loss: 1.2568 - accuracy: 0.5193 - val_loss: 1.1969 - val_accuracy: 0.5160\n",
      "Epoch 21/30\n",
      "5492/5492 [==============================] - 1s 252us/sample - loss: 1.2524 - accuracy: 0.5251 - val_loss: 1.1900 - val_accuracy: 0.5298\n",
      "Epoch 22/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.2453 - accuracy: 0.5262 - val_loss: 1.1906 - val_accuracy: 0.5254\n",
      "Epoch 23/30\n",
      "5492/5492 [==============================] - 1s 247us/sample - loss: 1.2385 - accuracy: 0.5311 - val_loss: 1.1845 - val_accuracy: 0.5400\n",
      "Epoch 24/30\n",
      "5492/5492 [==============================] - 1s 244us/sample - loss: 1.2377 - accuracy: 0.5299 - val_loss: 1.1728 - val_accuracy: 0.5385\n",
      "Epoch 25/30\n",
      "5492/5492 [==============================] - 0s 76us/sample - loss: 1.2312 - accuracy: 0.5271 - val_loss: 1.1781 - val_accuracy: 0.5385\n",
      "Epoch 26/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.2320 - accuracy: 0.5320 - val_loss: 1.1930 - val_accuracy: 0.5443\n",
      "Epoch 27/30\n",
      "5492/5492 [==============================] - 2s 302us/sample - loss: 1.2107 - accuracy: 0.5328 - val_loss: 1.1504 - val_accuracy: 0.5494\n",
      "Epoch 28/30\n",
      "5492/5492 [==============================] - 0s 76us/sample - loss: 1.2165 - accuracy: 0.5359 - val_loss: 1.1796 - val_accuracy: 0.5501\n",
      "Epoch 29/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.2107 - accuracy: 0.5335 - val_loss: 1.1526 - val_accuracy: 0.5356\n",
      "Epoch 30/30\n",
      "5492/5492 [==============================] - 2s 296us/sample - loss: 1.2115 - accuracy: 0.5346 - val_loss: 1.1472 - val_accuracy: 0.5443\n",
      "Train on 5492 samples, validate on 1376 samples\n",
      "Epoch 1/30\n",
      "5492/5492 [==============================] - 1s 189us/sample - loss: 1.5843 - accuracy: 0.4301 - val_loss: 1.5950 - val_accuracy: 0.4179\n",
      "Epoch 2/30\n",
      "5492/5492 [==============================] - 0s 85us/sample - loss: 1.5641 - accuracy: 0.4345 - val_loss: 1.5742 - val_accuracy: 0.4179\n",
      "Epoch 3/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.5624 - accuracy: 0.4345 - val_loss: 1.5804 - val_accuracy: 0.4179\n",
      "Epoch 4/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5596 - accuracy: 0.4345 - val_loss: 1.5733 - val_accuracy: 0.4179\n",
      "Epoch 5/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5561 - accuracy: 0.4345 - val_loss: 1.5669 - val_accuracy: 0.4179\n",
      "Epoch 6/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5483 - accuracy: 0.4345 - val_loss: 1.5526 - val_accuracy: 0.4179\n",
      "Epoch 7/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5235 - accuracy: 0.4385 - val_loss: 1.5247 - val_accuracy: 0.4608\n",
      "Epoch 8/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.4837 - accuracy: 0.4607 - val_loss: 1.4954 - val_accuracy: 0.4331\n",
      "Epoch 9/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.4523 - accuracy: 0.4665 - val_loss: 1.4252 - val_accuracy: 0.4709\n",
      "Epoch 10/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.4188 - accuracy: 0.4721 - val_loss: 1.3846 - val_accuracy: 0.4738\n",
      "Epoch 11/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3921 - accuracy: 0.4805 - val_loss: 1.3563 - val_accuracy: 0.4847\n",
      "Epoch 12/30\n",
      "5492/5492 [==============================] - 0s 83us/sample - loss: 1.3527 - accuracy: 0.4934 - val_loss: 1.3076 - val_accuracy: 0.4869\n",
      "Epoch 13/30\n",
      "5492/5492 [==============================] - 0s 83us/sample - loss: 1.3232 - accuracy: 0.5004 - val_loss: 1.2844 - val_accuracy: 0.4993\n",
      "Epoch 14/30\n",
      "5492/5492 [==============================] - 0s 76us/sample - loss: 1.3104 - accuracy: 0.4980 - val_loss: 1.2954 - val_accuracy: 0.4833\n",
      "Epoch 15/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2896 - accuracy: 0.5053 - val_loss: 1.2486 - val_accuracy: 0.5102\n",
      "Epoch 16/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.2737 - accuracy: 0.5118 - val_loss: 1.2488 - val_accuracy: 0.5218\n",
      "Epoch 17/30\n",
      "5492/5492 [==============================] - 0s 83us/sample - loss: 1.2594 - accuracy: 0.5138 - val_loss: 1.2066 - val_accuracy: 0.5312\n",
      "Epoch 18/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.2469 - accuracy: 0.5259 - val_loss: 1.2195 - val_accuracy: 0.5058\n",
      "Epoch 19/30\n",
      "5492/5492 [==============================] - 0s 83us/sample - loss: 1.2547 - accuracy: 0.5259 - val_loss: 1.1898 - val_accuracy: 0.5218\n",
      "Epoch 20/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2382 - accuracy: 0.5259 - val_loss: 1.1722 - val_accuracy: 0.5378\n",
      "Epoch 21/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.2285 - accuracy: 0.5269 - val_loss: 1.1798 - val_accuracy: 0.5160\n",
      "Epoch 22/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2269 - accuracy: 0.5264 - val_loss: 1.1709 - val_accuracy: 0.5465\n",
      "Epoch 23/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2203 - accuracy: 0.5375 - val_loss: 1.1668 - val_accuracy: 0.5203\n",
      "Epoch 24/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.2155 - accuracy: 0.5342 - val_loss: 1.1675 - val_accuracy: 0.5451\n",
      "Epoch 25/30\n",
      "5492/5492 [==============================] - 0s 83us/sample - loss: 1.2133 - accuracy: 0.5375 - val_loss: 1.1584 - val_accuracy: 0.5472\n",
      "Epoch 26/30\n",
      "5492/5492 [==============================] - 2s 300us/sample - loss: 1.2088 - accuracy: 0.5386 - val_loss: 1.1459 - val_accuracy: 0.5378\n",
      "Epoch 27/30\n",
      "5492/5492 [==============================] - 0s 76us/sample - loss: 1.2074 - accuracy: 0.5395 - val_loss: 1.1535 - val_accuracy: 0.5414\n",
      "Epoch 28/30\n",
      "5492/5492 [==============================] - 2s 311us/sample - loss: 1.1977 - accuracy: 0.5410 - val_loss: 1.1446 - val_accuracy: 0.5509\n",
      "Epoch 29/30\n",
      "5492/5492 [==============================] - 0s 76us/sample - loss: 1.1970 - accuracy: 0.5397 - val_loss: 1.1608 - val_accuracy: 0.5276\n",
      "Epoch 30/30\n",
      "5492/5492 [==============================] - 2s 300us/sample - loss: 1.1911 - accuracy: 0.5399 - val_loss: 1.1350 - val_accuracy: 0.5371\n",
      "Train on 5492 samples, validate on 1376 samples\n",
      "Epoch 1/30\n",
      "5492/5492 [==============================] - 1s 188us/sample - loss: 1.5821 - accuracy: 0.4314 - val_loss: 1.5744 - val_accuracy: 0.4179\n",
      "Epoch 2/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.5630 - accuracy: 0.4345 - val_loss: 1.5745 - val_accuracy: 0.4179\n",
      "Epoch 3/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5588 - accuracy: 0.4345 - val_loss: 1.5730 - val_accuracy: 0.4179\n",
      "Epoch 4/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5558 - accuracy: 0.4345 - val_loss: 1.5662 - val_accuracy: 0.4179\n",
      "Epoch 5/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5505 - accuracy: 0.4345 - val_loss: 1.5647 - val_accuracy: 0.4179\n",
      "Epoch 6/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5390 - accuracy: 0.4345 - val_loss: 1.5469 - val_accuracy: 0.4179\n",
      "Epoch 7/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5029 - accuracy: 0.4470 - val_loss: 1.5008 - val_accuracy: 0.4637\n",
      "Epoch 8/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.4626 - accuracy: 0.4636 - val_loss: 1.4418 - val_accuracy: 0.4738\n",
      "Epoch 9/30\n",
      "5492/5492 [==============================] - 0s 83us/sample - loss: 1.4222 - accuracy: 0.4769 - val_loss: 1.3770 - val_accuracy: 0.4782\n",
      "Epoch 10/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3835 - accuracy: 0.4812 - val_loss: 1.3417 - val_accuracy: 0.4818\n",
      "Epoch 11/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3446 - accuracy: 0.4960 - val_loss: 1.3130 - val_accuracy: 0.4797\n",
      "Epoch 12/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3293 - accuracy: 0.4971 - val_loss: 1.2686 - val_accuracy: 0.4949\n",
      "Epoch 13/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3016 - accuracy: 0.5044 - val_loss: 1.2510 - val_accuracy: 0.5029\n",
      "Epoch 14/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2860 - accuracy: 0.5124 - val_loss: 1.2411 - val_accuracy: 0.5094\n",
      "Epoch 15/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2780 - accuracy: 0.5137 - val_loss: 1.2254 - val_accuracy: 0.5102\n",
      "Epoch 16/30\n",
      "5492/5492 [==============================] - 0s 81us/sample - loss: 1.2782 - accuracy: 0.5158 - val_loss: 1.2212 - val_accuracy: 0.5182\n",
      "Epoch 17/30\n",
      "5492/5492 [==============================] - 0s 81us/sample - loss: 1.2583 - accuracy: 0.5186 - val_loss: 1.2056 - val_accuracy: 0.5247\n",
      "Epoch 18/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2540 - accuracy: 0.5226 - val_loss: 1.1826 - val_accuracy: 0.5312\n",
      "Epoch 19/30\n",
      "5492/5492 [==============================] - 0s 74us/sample - loss: 1.2493 - accuracy: 0.5235 - val_loss: 1.1966 - val_accuracy: 0.5218\n",
      "Epoch 20/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2259 - accuracy: 0.5284 - val_loss: 1.1705 - val_accuracy: 0.5371\n",
      "Epoch 21/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.2287 - accuracy: 0.5266 - val_loss: 1.1793 - val_accuracy: 0.5414\n",
      "Epoch 22/30\n",
      "5492/5492 [==============================] - 0s 81us/sample - loss: 1.2186 - accuracy: 0.5328 - val_loss: 1.1687 - val_accuracy: 0.5451\n",
      "Epoch 23/30\n",
      "5492/5492 [==============================] - 0s 74us/sample - loss: 1.2131 - accuracy: 0.5350 - val_loss: 1.1702 - val_accuracy: 0.5458\n",
      "Epoch 24/30\n",
      "5492/5492 [==============================] - 0s 81us/sample - loss: 1.2087 - accuracy: 0.5375 - val_loss: 1.1520 - val_accuracy: 0.5487\n",
      "Epoch 25/30\n",
      "5492/5492 [==============================] - 0s 74us/sample - loss: 1.2033 - accuracy: 0.5342 - val_loss: 1.1595 - val_accuracy: 0.5567\n",
      "Epoch 26/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2081 - accuracy: 0.5404 - val_loss: 1.1456 - val_accuracy: 0.5414\n",
      "Epoch 27/30\n",
      "5492/5492 [==============================] - 0s 81us/sample - loss: 1.1997 - accuracy: 0.5361 - val_loss: 1.1400 - val_accuracy: 0.5509\n",
      "Epoch 28/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.1968 - accuracy: 0.5377 - val_loss: 1.1399 - val_accuracy: 0.5443\n",
      "Epoch 29/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.1905 - accuracy: 0.5421 - val_loss: 1.1741 - val_accuracy: 0.5480\n",
      "Epoch 30/30\n",
      "5492/5492 [==============================] - 0s 74us/sample - loss: 1.1810 - accuracy: 0.5424 - val_loss: 1.1428 - val_accuracy: 0.5443\n",
      "Train on 5492 samples, validate on 1376 samples\n",
      "Epoch 1/30\n",
      "5492/5492 [==============================] - 1s 185us/sample - loss: 1.5748 - accuracy: 0.4306 - val_loss: 1.5765 - val_accuracy: 0.4179\n",
      "Epoch 2/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5599 - accuracy: 0.4345 - val_loss: 1.5712 - val_accuracy: 0.4179\n",
      "Epoch 3/30\n",
      "5492/5492 [==============================] - 0s 74us/sample - loss: 1.5565 - accuracy: 0.4345 - val_loss: 1.5738 - val_accuracy: 0.4179\n",
      "Epoch 4/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5538 - accuracy: 0.4345 - val_loss: 1.5599 - val_accuracy: 0.4179\n",
      "Epoch 5/30\n",
      "5492/5492 [==============================] - 0s 81us/sample - loss: 1.5418 - accuracy: 0.4345 - val_loss: 1.5321 - val_accuracy: 0.4179\n",
      "Epoch 6/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5072 - accuracy: 0.4466 - val_loss: 1.4818 - val_accuracy: 0.4469\n",
      "Epoch 7/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.4651 - accuracy: 0.4665 - val_loss: 1.4350 - val_accuracy: 0.4651\n",
      "Epoch 8/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.4377 - accuracy: 0.4667 - val_loss: 1.4030 - val_accuracy: 0.4731\n",
      "Epoch 9/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3835 - accuracy: 0.4843 - val_loss: 1.3748 - val_accuracy: 0.4586\n",
      "Epoch 10/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3490 - accuracy: 0.4882 - val_loss: 1.3022 - val_accuracy: 0.4818\n",
      "Epoch 11/30\n",
      "5492/5492 [==============================] - 0s 81us/sample - loss: 1.3155 - accuracy: 0.4973 - val_loss: 1.2700 - val_accuracy: 0.4956\n",
      "Epoch 12/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2971 - accuracy: 0.5027 - val_loss: 1.2501 - val_accuracy: 0.5015\n",
      "Epoch 13/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2854 - accuracy: 0.5106 - val_loss: 1.2289 - val_accuracy: 0.5073\n",
      "Epoch 14/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2643 - accuracy: 0.5155 - val_loss: 1.2048 - val_accuracy: 0.5218\n",
      "Epoch 15/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.2521 - accuracy: 0.5268 - val_loss: 1.2095 - val_accuracy: 0.5392\n",
      "Epoch 16/30\n",
      "5492/5492 [==============================] - 0s 81us/sample - loss: 1.2386 - accuracy: 0.5262 - val_loss: 1.1916 - val_accuracy: 0.5182\n",
      "Epoch 17/30\n",
      "5492/5492 [==============================] - 0s 81us/sample - loss: 1.2348 - accuracy: 0.5249 - val_loss: 1.1826 - val_accuracy: 0.5414\n",
      "Epoch 18/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2312 - accuracy: 0.5273 - val_loss: 1.1708 - val_accuracy: 0.5443\n",
      "Epoch 19/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.2231 - accuracy: 0.5340 - val_loss: 1.1808 - val_accuracy: 0.5371\n",
      "Epoch 20/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2148 - accuracy: 0.5322 - val_loss: 1.1691 - val_accuracy: 0.5291\n",
      "Epoch 21/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.2106 - accuracy: 0.5331 - val_loss: 1.1738 - val_accuracy: 0.5254\n",
      "Epoch 22/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2058 - accuracy: 0.5404 - val_loss: 1.1523 - val_accuracy: 0.5451\n",
      "Epoch 23/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.1889 - accuracy: 0.5401 - val_loss: 1.1425 - val_accuracy: 0.5560\n",
      "Epoch 24/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.1952 - accuracy: 0.5466 - val_loss: 1.1469 - val_accuracy: 0.5436\n",
      "Epoch 25/30\n",
      "5492/5492 [==============================] - 0s 88us/sample - loss: 1.1912 - accuracy: 0.5357 - val_loss: 1.1387 - val_accuracy: 0.5516\n",
      "Epoch 26/30\n",
      "5492/5492 [==============================] - 0s 88us/sample - loss: 1.1832 - accuracy: 0.5493 - val_loss: 1.1377 - val_accuracy: 0.5487\n",
      "Epoch 27/30\n",
      "5492/5492 [==============================] - 2s 313us/sample - loss: 1.1785 - accuracy: 0.5382 - val_loss: 1.1249 - val_accuracy: 0.5567\n",
      "Epoch 28/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.1662 - accuracy: 0.5490 - val_loss: 1.1257 - val_accuracy: 0.5552\n",
      "Epoch 29/30\n",
      "5492/5492 [==============================] - 0s 74us/sample - loss: 1.1909 - accuracy: 0.5470 - val_loss: 1.1384 - val_accuracy: 0.5545\n",
      "Epoch 30/30\n",
      "5492/5492 [==============================] - 2s 318us/sample - loss: 1.1637 - accuracy: 0.5510 - val_loss: 1.1218 - val_accuracy: 0.5531\n",
      "Train on 5492 samples, validate on 1376 samples\n",
      "Epoch 1/30\n",
      "5492/5492 [==============================] - 1s 213us/sample - loss: 1.5856 - accuracy: 0.4306 - val_loss: 1.5726 - val_accuracy: 0.4179\n",
      "Epoch 2/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.5603 - accuracy: 0.4345 - val_loss: 1.5762 - val_accuracy: 0.4179\n",
      "Epoch 3/30\n",
      "5492/5492 [==============================] - 0s 74us/sample - loss: 1.5608 - accuracy: 0.4345 - val_loss: 1.5741 - val_accuracy: 0.4179\n",
      "Epoch 4/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5560 - accuracy: 0.4345 - val_loss: 1.5699 - val_accuracy: 0.4179\n",
      "Epoch 5/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5535 - accuracy: 0.4345 - val_loss: 1.5649 - val_accuracy: 0.4179\n",
      "Epoch 6/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.5566 - accuracy: 0.4345 - val_loss: 1.5650 - val_accuracy: 0.4179\n",
      "Epoch 7/30\n",
      "5492/5492 [==============================] - 0s 81us/sample - loss: 1.5319 - accuracy: 0.4345 - val_loss: 1.5172 - val_accuracy: 0.4179\n",
      "Epoch 8/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5010 - accuracy: 0.4483 - val_loss: 1.4978 - val_accuracy: 0.4666\n",
      "Epoch 9/30\n",
      "5492/5492 [==============================] - 0s 81us/sample - loss: 1.4580 - accuracy: 0.4687 - val_loss: 1.4365 - val_accuracy: 0.4709\n",
      "Epoch 10/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.4268 - accuracy: 0.4771 - val_loss: 1.3957 - val_accuracy: 0.4782\n",
      "Epoch 11/30\n",
      "5492/5492 [==============================] - 0s 81us/sample - loss: 1.3898 - accuracy: 0.4796 - val_loss: 1.3528 - val_accuracy: 0.4775\n",
      "Epoch 12/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3570 - accuracy: 0.4909 - val_loss: 1.3199 - val_accuracy: 0.4840\n",
      "Epoch 13/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3331 - accuracy: 0.5000 - val_loss: 1.3147 - val_accuracy: 0.4913\n",
      "Epoch 14/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3171 - accuracy: 0.5064 - val_loss: 1.2640 - val_accuracy: 0.4927\n",
      "Epoch 15/30\n",
      "5492/5492 [==============================] - 0s 76us/sample - loss: 1.2931 - accuracy: 0.5080 - val_loss: 1.2675 - val_accuracy: 0.5080\n",
      "Epoch 16/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2870 - accuracy: 0.5102 - val_loss: 1.2351 - val_accuracy: 0.5087\n",
      "Epoch 17/30\n",
      "5492/5492 [==============================] - 0s 83us/sample - loss: 1.2792 - accuracy: 0.5109 - val_loss: 1.2316 - val_accuracy: 0.5174\n",
      "Epoch 18/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2684 - accuracy: 0.5218 - val_loss: 1.2134 - val_accuracy: 0.5291\n",
      "Epoch 19/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2597 - accuracy: 0.5175 - val_loss: 1.2075 - val_accuracy: 0.5233\n",
      "Epoch 20/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2528 - accuracy: 0.5200 - val_loss: 1.1990 - val_accuracy: 0.5312\n",
      "Epoch 21/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2420 - accuracy: 0.5233 - val_loss: 1.1913 - val_accuracy: 0.5233\n",
      "Epoch 22/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2408 - accuracy: 0.5300 - val_loss: 1.1870 - val_accuracy: 0.5276\n",
      "Epoch 23/30\n",
      "5492/5492 [==============================] - 0s 83us/sample - loss: 1.2299 - accuracy: 0.5231 - val_loss: 1.1695 - val_accuracy: 0.5334\n",
      "Epoch 24/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.2342 - accuracy: 0.5275 - val_loss: 1.1719 - val_accuracy: 0.5298\n",
      "Epoch 25/30\n",
      "5492/5492 [==============================] - 0s 74us/sample - loss: 1.2158 - accuracy: 0.5359 - val_loss: 1.2021 - val_accuracy: 0.5552\n",
      "Epoch 26/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.2209 - accuracy: 0.5304 - val_loss: 1.1724 - val_accuracy: 0.5494\n",
      "Epoch 27/30\n",
      "5492/5492 [==============================] - 0s 84us/sample - loss: 1.2126 - accuracy: 0.5386 - val_loss: 1.1502 - val_accuracy: 0.5465\n",
      "Epoch 28/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.2132 - accuracy: 0.5361 - val_loss: 1.1588 - val_accuracy: 0.5480\n",
      "Epoch 29/30\n",
      "5492/5492 [==============================] - 0s 74us/sample - loss: 1.2113 - accuracy: 0.5370 - val_loss: 1.1524 - val_accuracy: 0.5429\n",
      "Epoch 30/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.1994 - accuracy: 0.5410 - val_loss: 1.1509 - val_accuracy: 0.5538\n",
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6ce92a753d470aba801dbff017785a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 640 samples, validate on 160 samples\n",
      "Epoch 1/30\n",
      "640/640 [==============================] - 1s 1ms/sample - loss: 1.7111 - accuracy: 0.3781 - val_loss: 1.5870 - val_accuracy: 0.4125\n",
      "Epoch 2/30\n",
      "640/640 [==============================] - 0s 110us/sample - loss: 1.6126 - accuracy: 0.4062 - val_loss: 1.6110 - val_accuracy: 0.4125\n",
      "Epoch 3/30\n",
      "640/640 [==============================] - 0s 165us/sample - loss: 1.5989 - accuracy: 0.4062 - val_loss: 1.5799 - val_accuracy: 0.4125\n",
      "Epoch 4/30\n",
      "640/640 [==============================] - 0s 107us/sample - loss: 1.6040 - accuracy: 0.4062 - val_loss: 1.5864 - val_accuracy: 0.4125\n",
      "Epoch 5/30\n",
      "640/640 [==============================] - 0s 104us/sample - loss: 1.5877 - accuracy: 0.4062 - val_loss: 1.5988 - val_accuracy: 0.4125\n",
      "Epoch 6/30\n",
      "640/640 [==============================] - 0s 103us/sample - loss: 1.5900 - accuracy: 0.4062 - val_loss: 1.5840 - val_accuracy: 0.4125\n",
      "Epoch 7/30\n",
      "640/640 [==============================] - 0s 103us/sample - loss: 1.5919 - accuracy: 0.4062 - val_loss: 1.5857 - val_accuracy: 0.4125\n",
      "Epoch 8/30\n",
      "640/640 [==============================] - 0s 94us/sample - loss: 1.5910 - accuracy: 0.4062 - val_loss: 1.5828 - val_accuracy: 0.4125\n",
      "Epoch 9/30\n",
      "640/640 [==============================] - 0s 95us/sample - loss: 1.5927 - accuracy: 0.4062 - val_loss: 1.5848 - val_accuracy: 0.4125\n",
      "Epoch 10/30\n",
      "640/640 [==============================] - 0s 91us/sample - loss: 1.5952 - accuracy: 0.4062 - val_loss: 1.5896 - val_accuracy: 0.4125\n",
      "Epoch 11/30\n",
      "640/640 [==============================] - 0s 91us/sample - loss: 1.5897 - accuracy: 0.4062 - val_loss: 1.5854 - val_accuracy: 0.4125\n",
      "Epoch 12/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5912 - accuracy: 0.4062 - val_loss: 1.5904 - val_accuracy: 0.4125\n",
      "Epoch 13/30\n",
      "640/640 [==============================] - 0s 88us/sample - loss: 1.5919 - accuracy: 0.4062 - val_loss: 1.5848 - val_accuracy: 0.4125\n",
      "Epoch 14/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5961 - accuracy: 0.4062 - val_loss: 1.5937 - val_accuracy: 0.4125\n",
      "Epoch 15/30\n",
      "640/640 [==============================] - 0s 85us/sample - loss: 1.5835 - accuracy: 0.4062 - val_loss: 1.5831 - val_accuracy: 0.4125\n",
      "Epoch 16/30\n",
      "640/640 [==============================] - 0s 85us/sample - loss: 1.5895 - accuracy: 0.4062 - val_loss: 1.5918 - val_accuracy: 0.4125\n",
      "Epoch 17/30\n",
      "640/640 [==============================] - 0s 85us/sample - loss: 1.5919 - accuracy: 0.4062 - val_loss: 1.5817 - val_accuracy: 0.4125\n",
      "Epoch 18/30\n",
      "640/640 [==============================] - 0s 85us/sample - loss: 1.5872 - accuracy: 0.4062 - val_loss: 1.5837 - val_accuracy: 0.4125\n",
      "Epoch 19/30\n",
      "640/640 [==============================] - 0s 84us/sample - loss: 1.5818 - accuracy: 0.4062 - val_loss: 1.5869 - val_accuracy: 0.4125\n",
      "Epoch 20/30\n",
      "640/640 [==============================] - 0s 85us/sample - loss: 1.5871 - accuracy: 0.4062 - val_loss: 1.5837 - val_accuracy: 0.4125\n",
      "Epoch 21/30\n",
      "640/640 [==============================] - 0s 82us/sample - loss: 1.5818 - accuracy: 0.4062 - val_loss: 1.5853 - val_accuracy: 0.4125\n",
      "Epoch 22/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5854 - accuracy: 0.4062 - val_loss: 1.5833 - val_accuracy: 0.4125\n",
      "Epoch 23/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5805 - accuracy: 0.4062 - val_loss: 1.5819 - val_accuracy: 0.4125\n",
      "Epoch 24/30\n",
      "640/640 [==============================] - 0s 87us/sample - loss: 1.5823 - accuracy: 0.4062 - val_loss: 1.5843 - val_accuracy: 0.4125\n",
      "Epoch 25/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5893 - accuracy: 0.4062 - val_loss: 1.5844 - val_accuracy: 0.4125\n",
      "Epoch 26/30\n",
      "640/640 [==============================] - 0s 84us/sample - loss: 1.5808 - accuracy: 0.4062 - val_loss: 1.5823 - val_accuracy: 0.4125\n",
      "Epoch 27/30\n",
      "640/640 [==============================] - 0s 83us/sample - loss: 1.5986 - accuracy: 0.4062 - val_loss: 1.5931 - val_accuracy: 0.4125\n",
      "Epoch 28/30\n",
      "640/640 [==============================] - 0s 160us/sample - loss: 1.5852 - accuracy: 0.4062 - val_loss: 1.5795 - val_accuracy: 0.4125\n",
      "Epoch 29/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5889 - accuracy: 0.4062 - val_loss: 1.5872 - val_accuracy: 0.4125\n",
      "Epoch 30/30\n",
      "640/640 [==============================] - 0s 141us/sample - loss: 1.5788 - accuracy: 0.4062 - val_loss: 1.5792 - val_accuracy: 0.4125\n",
      "Train on 640 samples, validate on 160 samples\n",
      "Epoch 1/30\n",
      "640/640 [==============================] - 1s 1ms/sample - loss: 1.7159 - accuracy: 0.3859 - val_loss: 1.5890 - val_accuracy: 0.4125\n",
      "Epoch 2/30\n",
      "640/640 [==============================] - 0s 109us/sample - loss: 1.5992 - accuracy: 0.4062 - val_loss: 1.6020 - val_accuracy: 0.4125\n",
      "Epoch 3/30\n",
      "640/640 [==============================] - 0s 164us/sample - loss: 1.6005 - accuracy: 0.4062 - val_loss: 1.5823 - val_accuracy: 0.4125\n",
      "Epoch 4/30\n",
      "640/640 [==============================] - 0s 108us/sample - loss: 1.5884 - accuracy: 0.4062 - val_loss: 1.5936 - val_accuracy: 0.4125\n",
      "Epoch 5/30\n",
      "640/640 [==============================] - 0s 107us/sample - loss: 1.5931 - accuracy: 0.4062 - val_loss: 1.5933 - val_accuracy: 0.4125\n",
      "Epoch 6/30\n",
      "640/640 [==============================] - 0s 97us/sample - loss: 1.5935 - accuracy: 0.4062 - val_loss: 1.5947 - val_accuracy: 0.4125\n",
      "Epoch 7/30\n",
      "640/640 [==============================] - 0s 99us/sample - loss: 1.5897 - accuracy: 0.4062 - val_loss: 1.5865 - val_accuracy: 0.4125\n",
      "Epoch 8/30\n",
      "640/640 [==============================] - 0s 159us/sample - loss: 1.5976 - accuracy: 0.4062 - val_loss: 1.5805 - val_accuracy: 0.4125\n",
      "Epoch 9/30\n",
      "640/640 [==============================] - 0s 92us/sample - loss: 1.5839 - accuracy: 0.4062 - val_loss: 1.5927 - val_accuracy: 0.4125\n",
      "Epoch 10/30\n",
      "640/640 [==============================] - 0s 91us/sample - loss: 1.5863 - accuracy: 0.4062 - val_loss: 1.5882 - val_accuracy: 0.4125\n",
      "Epoch 11/30\n",
      "640/640 [==============================] - 0s 91us/sample - loss: 1.5934 - accuracy: 0.4062 - val_loss: 1.5875 - val_accuracy: 0.4125\n",
      "Epoch 12/30\n",
      "640/640 [==============================] - 0s 91us/sample - loss: 1.5978 - accuracy: 0.4062 - val_loss: 1.5882 - val_accuracy: 0.4125\n",
      "Epoch 13/30\n",
      "640/640 [==============================] - 0s 89us/sample - loss: 1.5936 - accuracy: 0.4062 - val_loss: 1.5943 - val_accuracy: 0.4125\n",
      "Epoch 14/30\n",
      "640/640 [==============================] - 0s 89us/sample - loss: 1.5925 - accuracy: 0.4062 - val_loss: 1.5810 - val_accuracy: 0.4125\n",
      "Epoch 15/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5924 - accuracy: 0.4062 - val_loss: 1.5948 - val_accuracy: 0.4125\n",
      "Epoch 16/30\n",
      "640/640 [==============================] - 0s 88us/sample - loss: 1.5823 - accuracy: 0.4062 - val_loss: 1.5834 - val_accuracy: 0.4125\n",
      "Epoch 17/30\n",
      "640/640 [==============================] - 0s 85us/sample - loss: 1.5867 - accuracy: 0.4062 - val_loss: 1.5942 - val_accuracy: 0.4125\n",
      "Epoch 18/30\n",
      "640/640 [==============================] - 0s 162us/sample - loss: 1.5860 - accuracy: 0.4062 - val_loss: 1.5805 - val_accuracy: 0.4125\n",
      "Epoch 19/30\n",
      "640/640 [==============================] - 0s 89us/sample - loss: 1.5818 - accuracy: 0.4062 - val_loss: 1.5873 - val_accuracy: 0.4125\n",
      "Epoch 20/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5865 - accuracy: 0.4062 - val_loss: 1.5839 - val_accuracy: 0.4125\n",
      "Epoch 21/30\n",
      "640/640 [==============================] - 0s 85us/sample - loss: 1.5905 - accuracy: 0.4062 - val_loss: 1.5862 - val_accuracy: 0.4125\n",
      "Epoch 22/30\n",
      "640/640 [==============================] - 0s 84us/sample - loss: 1.5876 - accuracy: 0.4062 - val_loss: 1.5831 - val_accuracy: 0.4125\n",
      "Epoch 23/30\n",
      "640/640 [==============================] - 0s 87us/sample - loss: 1.5805 - accuracy: 0.4062 - val_loss: 1.5855 - val_accuracy: 0.4125\n",
      "Epoch 24/30\n",
      "640/640 [==============================] - 0s 85us/sample - loss: 1.5827 - accuracy: 0.4062 - val_loss: 1.5827 - val_accuracy: 0.4125\n",
      "Epoch 25/30\n",
      "640/640 [==============================] - 0s 85us/sample - loss: 1.5906 - accuracy: 0.4062 - val_loss: 1.5939 - val_accuracy: 0.4125\n",
      "Epoch 26/30\n",
      "640/640 [==============================] - 0s 83us/sample - loss: 1.5888 - accuracy: 0.4062 - val_loss: 1.5837 - val_accuracy: 0.4125\n",
      "Epoch 27/30\n",
      "640/640 [==============================] - 0s 84us/sample - loss: 1.5893 - accuracy: 0.4062 - val_loss: 1.5862 - val_accuracy: 0.4125\n",
      "Epoch 28/30\n",
      "640/640 [==============================] - 0s 87us/sample - loss: 1.5785 - accuracy: 0.4062 - val_loss: 1.5827 - val_accuracy: 0.4125\n",
      "Epoch 29/30\n",
      "640/640 [==============================] - 0s 84us/sample - loss: 1.5775 - accuracy: 0.4062 - val_loss: 1.5824 - val_accuracy: 0.4125\n",
      "Epoch 30/30\n",
      "640/640 [==============================] - 0s 151us/sample - loss: 1.5789 - accuracy: 0.4062 - val_loss: 1.5801 - val_accuracy: 0.4125\n",
      "Train on 640 samples, validate on 160 samples\n",
      "Epoch 1/30\n",
      "640/640 [==============================] - 1s 906us/sample - loss: 1.6974 - accuracy: 0.3844 - val_loss: 1.5850 - val_accuracy: 0.4125\n",
      "Epoch 2/30\n",
      "640/640 [==============================] - 0s 111us/sample - loss: 1.5963 - accuracy: 0.4062 - val_loss: 1.6251 - val_accuracy: 0.4125\n",
      "Epoch 3/30\n",
      "640/640 [==============================] - 0s 175us/sample - loss: 1.5979 - accuracy: 0.4062 - val_loss: 1.5843 - val_accuracy: 0.4125\n",
      "Epoch 4/30\n",
      "640/640 [==============================] - 0s 106us/sample - loss: 1.5979 - accuracy: 0.4062 - val_loss: 1.5890 - val_accuracy: 0.4125\n",
      "Epoch 5/30\n",
      "640/640 [==============================] - 0s 172us/sample - loss: 1.5897 - accuracy: 0.4062 - val_loss: 1.5812 - val_accuracy: 0.4125\n",
      "Epoch 6/30\n",
      "640/640 [==============================] - 0s 101us/sample - loss: 1.5854 - accuracy: 0.4062 - val_loss: 1.5953 - val_accuracy: 0.4125\n",
      "Epoch 7/30\n",
      "640/640 [==============================] - 0s 98us/sample - loss: 1.5906 - accuracy: 0.4062 - val_loss: 1.5884 - val_accuracy: 0.4125\n",
      "Epoch 8/30\n",
      "640/640 [==============================] - 0s 97us/sample - loss: 1.5905 - accuracy: 0.4062 - val_loss: 1.5929 - val_accuracy: 0.4125\n",
      "Epoch 9/30\n",
      "640/640 [==============================] - 0s 101us/sample - loss: 1.5869 - accuracy: 0.4062 - val_loss: 1.5824 - val_accuracy: 0.4125\n",
      "Epoch 10/30\n",
      "640/640 [==============================] - 0s 93us/sample - loss: 1.5904 - accuracy: 0.4062 - val_loss: 1.5885 - val_accuracy: 0.4125\n",
      "Epoch 11/30\n",
      "640/640 [==============================] - 0s 90us/sample - loss: 1.5953 - accuracy: 0.4062 - val_loss: 1.5952 - val_accuracy: 0.4125\n",
      "Epoch 12/30\n",
      "640/640 [==============================] - 0s 88us/sample - loss: 1.5885 - accuracy: 0.4062 - val_loss: 1.5833 - val_accuracy: 0.4125\n",
      "Epoch 13/30\n",
      "640/640 [==============================] - 0s 89us/sample - loss: 1.5843 - accuracy: 0.4062 - val_loss: 1.5943 - val_accuracy: 0.4125\n",
      "Epoch 14/30\n",
      "640/640 [==============================] - 0s 85us/sample - loss: 1.5927 - accuracy: 0.4062 - val_loss: 1.5819 - val_accuracy: 0.4125\n",
      "Epoch 15/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5855 - accuracy: 0.4062 - val_loss: 1.5932 - val_accuracy: 0.4125\n",
      "Epoch 16/30\n",
      "640/640 [==============================] - 0s 84us/sample - loss: 1.5799 - accuracy: 0.4062 - val_loss: 1.5816 - val_accuracy: 0.4125\n",
      "Epoch 17/30\n",
      "640/640 [==============================] - 0s 83us/sample - loss: 1.5901 - accuracy: 0.4062 - val_loss: 1.5995 - val_accuracy: 0.4125\n",
      "Epoch 18/30\n",
      "640/640 [==============================] - 0s 153us/sample - loss: 1.5882 - accuracy: 0.4062 - val_loss: 1.5808 - val_accuracy: 0.4125\n",
      "Epoch 19/30\n",
      "640/640 [==============================] - 0s 90us/sample - loss: 1.5898 - accuracy: 0.4062 - val_loss: 1.5911 - val_accuracy: 0.4125\n",
      "Epoch 20/30\n",
      "640/640 [==============================] - 0s 200us/sample - loss: 1.5780 - accuracy: 0.4062 - val_loss: 1.5796 - val_accuracy: 0.4125\n",
      "Epoch 21/30\n",
      "640/640 [==============================] - 0s 89us/sample - loss: 1.5840 - accuracy: 0.4062 - val_loss: 1.5926 - val_accuracy: 0.4125\n",
      "Epoch 22/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5778 - accuracy: 0.4062 - val_loss: 1.5816 - val_accuracy: 0.4125\n",
      "Epoch 23/30\n",
      "640/640 [==============================] - 0s 84us/sample - loss: 1.5830 - accuracy: 0.4062 - val_loss: 1.5817 - val_accuracy: 0.4125\n",
      "Epoch 24/30\n",
      "640/640 [==============================] - 0s 84us/sample - loss: 1.5875 - accuracy: 0.4062 - val_loss: 1.5899 - val_accuracy: 0.4125\n",
      "Epoch 25/30\n",
      "640/640 [==============================] - 0s 83us/sample - loss: 1.5823 - accuracy: 0.4062 - val_loss: 1.5810 - val_accuracy: 0.4125\n",
      "Epoch 26/30\n",
      "640/640 [==============================] - 0s 85us/sample - loss: 1.5968 - accuracy: 0.4062 - val_loss: 1.5870 - val_accuracy: 0.4125\n",
      "Epoch 27/30\n",
      "640/640 [==============================] - 0s 257us/sample - loss: 1.5819 - accuracy: 0.4062 - val_loss: 1.5792 - val_accuracy: 0.4125\n",
      "Epoch 28/30\n",
      "640/640 [==============================] - 0s 85us/sample - loss: 1.5838 - accuracy: 0.4062 - val_loss: 1.5847 - val_accuracy: 0.4125\n",
      "Epoch 29/30\n",
      "640/640 [==============================] - 0s 83us/sample - loss: 1.5816 - accuracy: 0.4062 - val_loss: 1.5845 - val_accuracy: 0.4125\n",
      "Epoch 30/30\n",
      "640/640 [==============================] - 0s 82us/sample - loss: 1.5833 - accuracy: 0.4062 - val_loss: 1.5801 - val_accuracy: 0.4125\n",
      "Train on 640 samples, validate on 160 samples\n",
      "Epoch 1/30\n",
      "640/640 [==============================] - 1s 893us/sample - loss: 1.7036 - accuracy: 0.3891 - val_loss: 1.5896 - val_accuracy: 0.4125\n",
      "Epoch 2/30\n",
      "640/640 [==============================] - 0s 110us/sample - loss: 1.5942 - accuracy: 0.4062 - val_loss: 1.6088 - val_accuracy: 0.4125\n",
      "Epoch 3/30\n",
      "640/640 [==============================] - 0s 108us/sample - loss: 1.5973 - accuracy: 0.4062 - val_loss: 1.5902 - val_accuracy: 0.4125\n",
      "Epoch 4/30\n",
      "640/640 [==============================] - 0s 107us/sample - loss: 1.5835 - accuracy: 0.4062 - val_loss: 1.5931 - val_accuracy: 0.4125\n",
      "Epoch 5/30\n",
      "640/640 [==============================] - 0s 174us/sample - loss: 1.5887 - accuracy: 0.4062 - val_loss: 1.5888 - val_accuracy: 0.4125\n",
      "Epoch 6/30\n",
      "640/640 [==============================] - 0s 158us/sample - loss: 1.5950 - accuracy: 0.4062 - val_loss: 1.5804 - val_accuracy: 0.4125\n",
      "Epoch 7/30\n",
      "640/640 [==============================] - 0s 98us/sample - loss: 1.5979 - accuracy: 0.4062 - val_loss: 1.5920 - val_accuracy: 0.4125\n",
      "Epoch 8/30\n",
      "640/640 [==============================] - 0s 96us/sample - loss: 1.5915 - accuracy: 0.4062 - val_loss: 1.5931 - val_accuracy: 0.4125\n",
      "Epoch 9/30\n",
      "640/640 [==============================] - 0s 96us/sample - loss: 1.5860 - accuracy: 0.4062 - val_loss: 1.5846 - val_accuracy: 0.4125\n",
      "Epoch 10/30\n",
      "640/640 [==============================] - 0s 96us/sample - loss: 1.5862 - accuracy: 0.4062 - val_loss: 1.5943 - val_accuracy: 0.4125\n",
      "Epoch 11/30\n",
      "640/640 [==============================] - 0s 91us/sample - loss: 1.5890 - accuracy: 0.4062 - val_loss: 1.5866 - val_accuracy: 0.4125\n",
      "Epoch 12/30\n",
      "640/640 [==============================] - 0s 87us/sample - loss: 1.5828 - accuracy: 0.4062 - val_loss: 1.5853 - val_accuracy: 0.4125\n",
      "Epoch 13/30\n",
      "640/640 [==============================] - 0s 87us/sample - loss: 1.5831 - accuracy: 0.4062 - val_loss: 1.5857 - val_accuracy: 0.4125\n",
      "Epoch 14/30\n",
      "640/640 [==============================] - 0s 89us/sample - loss: 1.5883 - accuracy: 0.4062 - val_loss: 1.5907 - val_accuracy: 0.4125\n",
      "Epoch 15/30\n",
      "640/640 [==============================] - 0s 85us/sample - loss: 1.5783 - accuracy: 0.4062 - val_loss: 1.5855 - val_accuracy: 0.4125\n",
      "Epoch 16/30\n",
      "640/640 [==============================] - 0s 84us/sample - loss: 1.5862 - accuracy: 0.4062 - val_loss: 1.5891 - val_accuracy: 0.4125\n",
      "Epoch 17/30\n",
      "640/640 [==============================] - 0s 84us/sample - loss: 1.5853 - accuracy: 0.4062 - val_loss: 1.5871 - val_accuracy: 0.4125\n",
      "Epoch 18/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5788 - accuracy: 0.4062 - val_loss: 1.5833 - val_accuracy: 0.4125\n",
      "Epoch 19/30\n",
      "640/640 [==============================] - 0s 83us/sample - loss: 1.5802 - accuracy: 0.4062 - val_loss: 1.5882 - val_accuracy: 0.4125\n",
      "Epoch 20/30\n",
      "640/640 [==============================] - 0s 85us/sample - loss: 1.5908 - accuracy: 0.4062 - val_loss: 1.5899 - val_accuracy: 0.4125\n",
      "Epoch 21/30\n",
      "640/640 [==============================] - 0s 148us/sample - loss: 1.5817 - accuracy: 0.4062 - val_loss: 1.5792 - val_accuracy: 0.4125\n",
      "Epoch 22/30\n",
      "640/640 [==============================] - 0s 87us/sample - loss: 1.5851 - accuracy: 0.4062 - val_loss: 1.5869 - val_accuracy: 0.4125\n",
      "Epoch 23/30\n",
      "640/640 [==============================] - 0s 85us/sample - loss: 1.5765 - accuracy: 0.4062 - val_loss: 1.5823 - val_accuracy: 0.4125\n",
      "Epoch 24/30\n",
      "640/640 [==============================] - 0s 84us/sample - loss: 1.5839 - accuracy: 0.4062 - val_loss: 1.5882 - val_accuracy: 0.4125\n",
      "Epoch 25/30\n",
      "640/640 [==============================] - 0s 315us/sample - loss: 1.5767 - accuracy: 0.4062 - val_loss: 1.5758 - val_accuracy: 0.4125\n",
      "Epoch 26/30\n",
      "640/640 [==============================] - 0s 90us/sample - loss: 1.5851 - accuracy: 0.4062 - val_loss: 1.5875 - val_accuracy: 0.4125\n",
      "Epoch 27/30\n",
      "640/640 [==============================] - 0s 333us/sample - loss: 1.5804 - accuracy: 0.4062 - val_loss: 1.5756 - val_accuracy: 0.4125\n",
      "Epoch 28/30\n",
      "640/640 [==============================] - 0s 88us/sample - loss: 1.5844 - accuracy: 0.4062 - val_loss: 1.5789 - val_accuracy: 0.4125\n",
      "Epoch 29/30\n",
      "640/640 [==============================] - 0s 350us/sample - loss: 1.5913 - accuracy: 0.4062 - val_loss: 1.5751 - val_accuracy: 0.4125\n",
      "Epoch 30/30\n",
      "640/640 [==============================] - 0s 88us/sample - loss: 1.5748 - accuracy: 0.4062 - val_loss: 1.5861 - val_accuracy: 0.4125\n",
      "Train on 640 samples, validate on 160 samples\n",
      "Epoch 1/30\n",
      "640/640 [==============================] - 1s 1ms/sample - loss: 1.7104 - accuracy: 0.3734 - val_loss: 1.5995 - val_accuracy: 0.4125\n",
      "Epoch 2/30\n",
      "640/640 [==============================] - 0s 169us/sample - loss: 1.6052 - accuracy: 0.4062 - val_loss: 1.5975 - val_accuracy: 0.4125\n",
      "Epoch 3/30\n",
      "640/640 [==============================] - 0s 168us/sample - loss: 1.6051 - accuracy: 0.4062 - val_loss: 1.5855 - val_accuracy: 0.4125\n",
      "Epoch 4/30\n",
      "640/640 [==============================] - 0s 108us/sample - loss: 1.6025 - accuracy: 0.4062 - val_loss: 1.5974 - val_accuracy: 0.4125\n",
      "Epoch 5/30\n",
      "640/640 [==============================] - 0s 175us/sample - loss: 1.5975 - accuracy: 0.4062 - val_loss: 1.5839 - val_accuracy: 0.4125\n",
      "Epoch 6/30\n",
      "640/640 [==============================] - 0s 106us/sample - loss: 1.5888 - accuracy: 0.4062 - val_loss: 1.5963 - val_accuracy: 0.4125\n",
      "Epoch 7/30\n",
      "640/640 [==============================] - 0s 166us/sample - loss: 1.5882 - accuracy: 0.4062 - val_loss: 1.5837 - val_accuracy: 0.4125\n",
      "Epoch 8/30\n",
      "640/640 [==============================] - 0s 104us/sample - loss: 1.5923 - accuracy: 0.4062 - val_loss: 1.5912 - val_accuracy: 0.4125\n",
      "Epoch 9/30\n",
      "640/640 [==============================] - 0s 164us/sample - loss: 1.5821 - accuracy: 0.4062 - val_loss: 1.5831 - val_accuracy: 0.4125\n",
      "Epoch 10/30\n",
      "640/640 [==============================] - 0s 103us/sample - loss: 1.5894 - accuracy: 0.4062 - val_loss: 1.5892 - val_accuracy: 0.4125\n",
      "Epoch 11/30\n",
      "640/640 [==============================] - 0s 200us/sample - loss: 1.5857 - accuracy: 0.4062 - val_loss: 1.5829 - val_accuracy: 0.4125\n",
      "Epoch 12/30\n",
      "640/640 [==============================] - 0s 99us/sample - loss: 1.5812 - accuracy: 0.4062 - val_loss: 1.5844 - val_accuracy: 0.4125\n",
      "Epoch 13/30\n",
      "640/640 [==============================] - 0s 99us/sample - loss: 1.5842 - accuracy: 0.4062 - val_loss: 1.5886 - val_accuracy: 0.4125\n",
      "Epoch 14/30\n",
      "640/640 [==============================] - 0s 97us/sample - loss: 1.5836 - accuracy: 0.4062 - val_loss: 1.5858 - val_accuracy: 0.4125\n",
      "Epoch 15/30\n",
      "640/640 [==============================] - 0s 95us/sample - loss: 1.5956 - accuracy: 0.4062 - val_loss: 1.5915 - val_accuracy: 0.4125\n",
      "Epoch 16/30\n",
      "640/640 [==============================] - 0s 88us/sample - loss: 1.5879 - accuracy: 0.4062 - val_loss: 1.5832 - val_accuracy: 0.4125\n",
      "Epoch 17/30\n",
      "640/640 [==============================] - 0s 88us/sample - loss: 1.5809 - accuracy: 0.4062 - val_loss: 1.5833 - val_accuracy: 0.4125\n",
      "Epoch 18/30\n",
      "640/640 [==============================] - 0s 90us/sample - loss: 1.5885 - accuracy: 0.4062 - val_loss: 1.5878 - val_accuracy: 0.4125\n",
      "Epoch 19/30\n",
      "640/640 [==============================] - 0s 87us/sample - loss: 1.5795 - accuracy: 0.4062 - val_loss: 1.5879 - val_accuracy: 0.4125\n",
      "Epoch 20/30\n",
      "640/640 [==============================] - 0s 87us/sample - loss: 1.5867 - accuracy: 0.4062 - val_loss: 1.5836 - val_accuracy: 0.4125\n",
      "Epoch 21/30\n",
      "640/640 [==============================] - 0s 85us/sample - loss: 1.5835 - accuracy: 0.4062 - val_loss: 1.5928 - val_accuracy: 0.4125\n",
      "Epoch 22/30\n",
      "640/640 [==============================] - 0s 85us/sample - loss: 1.5879 - accuracy: 0.4062 - val_loss: 1.5831 - val_accuracy: 0.4125\n",
      "Epoch 23/30\n",
      "640/640 [==============================] - 0s 85us/sample - loss: 1.5892 - accuracy: 0.4062 - val_loss: 1.5914 - val_accuracy: 0.4125\n",
      "Epoch 24/30\n",
      "640/640 [==============================] - 0s 155us/sample - loss: 1.5861 - accuracy: 0.4062 - val_loss: 1.5792 - val_accuracy: 0.4125\n",
      "Epoch 25/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5788 - accuracy: 0.4062 - val_loss: 1.5868 - val_accuracy: 0.4125\n",
      "Epoch 26/30\n",
      "640/640 [==============================] - 0s 143us/sample - loss: 1.5913 - accuracy: 0.4062 - val_loss: 1.5776 - val_accuracy: 0.4125\n",
      "Epoch 27/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5823 - accuracy: 0.4062 - val_loss: 1.5848 - val_accuracy: 0.4125\n",
      "Epoch 28/30\n",
      "640/640 [==============================] - 0s 85us/sample - loss: 1.5891 - accuracy: 0.4062 - val_loss: 1.5785 - val_accuracy: 0.4125\n",
      "Epoch 29/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5962 - accuracy: 0.4062 - val_loss: 1.5882 - val_accuracy: 0.4125\n",
      "Epoch 30/30\n",
      "640/640 [==============================] - 0s 86us/sample - loss: 1.5929 - accuracy: 0.4062 - val_loss: 1.5783 - val_accuracy: 0.4125\n",
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a16003b9b8c4141a8840cfd1d3b9ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/30\n",
      "1600/1600 [==============================] - 1s 738us/sample - loss: 1.6344 - accuracy: 0.4112 - val_loss: 1.5672 - val_accuracy: 0.4500\n",
      "Epoch 2/30\n",
      "1600/1600 [==============================] - 0s 232us/sample - loss: 1.5902 - accuracy: 0.4187 - val_loss: 1.5642 - val_accuracy: 0.4500\n",
      "Epoch 3/30\n",
      "1600/1600 [==============================] - 0s 95us/sample - loss: 1.5849 - accuracy: 0.4187 - val_loss: 1.5691 - val_accuracy: 0.4500\n",
      "Epoch 4/30\n",
      "1600/1600 [==============================] - 0s 241us/sample - loss: 1.5879 - accuracy: 0.4187 - val_loss: 1.5474 - val_accuracy: 0.4500\n",
      "Epoch 5/30\n",
      "1600/1600 [==============================] - 0s 223us/sample - loss: 1.5884 - accuracy: 0.4187 - val_loss: 1.5348 - val_accuracy: 0.4500\n",
      "Epoch 6/30\n",
      "1600/1600 [==============================] - 0s 240us/sample - loss: 1.5869 - accuracy: 0.4187 - val_loss: 1.5333 - val_accuracy: 0.4500\n",
      "Epoch 7/30\n",
      "1600/1600 [==============================] - 0s 245us/sample - loss: 1.5877 - accuracy: 0.4187 - val_loss: 1.5315 - val_accuracy: 0.4500\n",
      "Epoch 8/30\n",
      "1600/1600 [==============================] - 0s 84us/sample - loss: 1.5905 - accuracy: 0.4187 - val_loss: 1.5379 - val_accuracy: 0.4500\n",
      "Epoch 9/30\n",
      "1600/1600 [==============================] - 0s 82us/sample - loss: 1.5814 - accuracy: 0.4187 - val_loss: 1.5484 - val_accuracy: 0.4500\n",
      "Epoch 10/30\n",
      "1600/1600 [==============================] - 0s 76us/sample - loss: 1.5806 - accuracy: 0.4187 - val_loss: 1.5359 - val_accuracy: 0.4500\n",
      "Epoch 11/30\n",
      "1600/1600 [==============================] - 0s 217us/sample - loss: 1.5781 - accuracy: 0.4187 - val_loss: 1.5311 - val_accuracy: 0.4500\n",
      "Epoch 12/30\n",
      "1600/1600 [==============================] - 0s 78us/sample - loss: 1.5871 - accuracy: 0.4187 - val_loss: 1.5426 - val_accuracy: 0.4500\n",
      "Epoch 13/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5897 - accuracy: 0.4187 - val_loss: 1.5393 - val_accuracy: 0.4500\n",
      "Epoch 14/30\n",
      "1600/1600 [==============================] - 0s 78us/sample - loss: 1.5820 - accuracy: 0.4187 - val_loss: 1.5401 - val_accuracy: 0.4500\n",
      "Epoch 15/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5835 - accuracy: 0.4187 - val_loss: 1.5312 - val_accuracy: 0.4500\n",
      "Epoch 16/30\n",
      "1600/1600 [==============================] - 0s 224us/sample - loss: 1.5848 - accuracy: 0.4187 - val_loss: 1.5284 - val_accuracy: 0.4500\n",
      "Epoch 17/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5791 - accuracy: 0.4187 - val_loss: 1.5294 - val_accuracy: 0.4500\n",
      "Epoch 18/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5782 - accuracy: 0.4187 - val_loss: 1.5339 - val_accuracy: 0.4500\n",
      "Epoch 19/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5835 - accuracy: 0.4187 - val_loss: 1.5470 - val_accuracy: 0.4500\n",
      "Epoch 20/30\n",
      "1600/1600 [==============================] - 0s 76us/sample - loss: 1.5804 - accuracy: 0.4187 - val_loss: 1.5294 - val_accuracy: 0.4500\n",
      "Epoch 21/30\n",
      "1600/1600 [==============================] - 0s 216us/sample - loss: 1.5834 - accuracy: 0.4187 - val_loss: 1.5257 - val_accuracy: 0.4500\n",
      "Epoch 22/30\n",
      "1600/1600 [==============================] - 0s 78us/sample - loss: 1.5793 - accuracy: 0.4187 - val_loss: 1.5288 - val_accuracy: 0.4500\n",
      "Epoch 23/30\n",
      "1600/1600 [==============================] - 0s 76us/sample - loss: 1.5668 - accuracy: 0.4187 - val_loss: 1.5397 - val_accuracy: 0.4500\n",
      "Epoch 24/30\n",
      "1600/1600 [==============================] - 0s 76us/sample - loss: 1.5737 - accuracy: 0.4187 - val_loss: 1.5355 - val_accuracy: 0.4500\n",
      "Epoch 25/30\n",
      "1600/1600 [==============================] - 0s 223us/sample - loss: 1.5653 - accuracy: 0.4187 - val_loss: 1.5160 - val_accuracy: 0.4500\n",
      "Epoch 26/30\n",
      "1600/1600 [==============================] - 0s 220us/sample - loss: 1.5571 - accuracy: 0.4187 - val_loss: 1.5089 - val_accuracy: 0.4500\n",
      "Epoch 27/30\n",
      "1600/1600 [==============================] - 0s 78us/sample - loss: 1.5530 - accuracy: 0.4187 - val_loss: 1.5140 - val_accuracy: 0.4500\n",
      "Epoch 28/30\n",
      "1600/1600 [==============================] - 0s 218us/sample - loss: 1.5439 - accuracy: 0.4206 - val_loss: 1.4860 - val_accuracy: 0.4500\n",
      "Epoch 29/30\n",
      "1600/1600 [==============================] - 0s 241us/sample - loss: 1.5342 - accuracy: 0.4219 - val_loss: 1.4847 - val_accuracy: 0.4775\n",
      "Epoch 30/30\n",
      "1600/1600 [==============================] - 0s 222us/sample - loss: 1.5163 - accuracy: 0.4294 - val_loss: 1.4517 - val_accuracy: 0.4850\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/30\n",
      "1600/1600 [==============================] - 1s 605us/sample - loss: 1.6523 - accuracy: 0.4013 - val_loss: 1.5576 - val_accuracy: 0.4500\n",
      "Epoch 2/30\n",
      "1600/1600 [==============================] - 0s 125us/sample - loss: 1.5905 - accuracy: 0.4187 - val_loss: 1.5398 - val_accuracy: 0.4500\n",
      "Epoch 3/30\n",
      "1600/1600 [==============================] - 0s 91us/sample - loss: 1.5853 - accuracy: 0.4187 - val_loss: 1.5628 - val_accuracy: 0.4500\n",
      "Epoch 4/30\n",
      "1600/1600 [==============================] - 0s 112us/sample - loss: 1.5867 - accuracy: 0.4187 - val_loss: 1.5381 - val_accuracy: 0.4500\n",
      "Epoch 5/30\n",
      "1600/1600 [==============================] - 0s 83us/sample - loss: 1.5941 - accuracy: 0.4187 - val_loss: 1.5589 - val_accuracy: 0.4500\n",
      "Epoch 6/30\n",
      "1600/1600 [==============================] - 0s 81us/sample - loss: 1.5910 - accuracy: 0.4187 - val_loss: 1.5596 - val_accuracy: 0.4500\n",
      "Epoch 7/30\n",
      "1600/1600 [==============================] - 0s 76us/sample - loss: 1.5863 - accuracy: 0.4187 - val_loss: 1.5435 - val_accuracy: 0.4500\n",
      "Epoch 8/30\n",
      "1600/1600 [==============================] - 0s 76us/sample - loss: 1.5813 - accuracy: 0.4187 - val_loss: 1.5720 - val_accuracy: 0.4500\n",
      "Epoch 9/30\n",
      "1600/1600 [==============================] - 0s 106us/sample - loss: 1.5816 - accuracy: 0.4187 - val_loss: 1.5361 - val_accuracy: 0.4500\n",
      "Epoch 10/30\n",
      "1600/1600 [==============================] - 0s 101us/sample - loss: 1.5794 - accuracy: 0.4187 - val_loss: 1.5346 - val_accuracy: 0.4500\n",
      "Epoch 11/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5841 - accuracy: 0.4187 - val_loss: 1.5475 - val_accuracy: 0.4500\n",
      "Epoch 12/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5852 - accuracy: 0.4187 - val_loss: 1.5553 - val_accuracy: 0.4500\n",
      "Epoch 13/30\n",
      "1600/1600 [==============================] - 0s 78us/sample - loss: 1.5817 - accuracy: 0.4187 - val_loss: 1.5550 - val_accuracy: 0.4500\n",
      "Epoch 14/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5854 - accuracy: 0.4187 - val_loss: 1.5460 - val_accuracy: 0.4500\n",
      "Epoch 15/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5788 - accuracy: 0.4187 - val_loss: 1.5428 - val_accuracy: 0.4500\n",
      "Epoch 16/30\n",
      "1600/1600 [==============================] - 0s 108us/sample - loss: 1.5814 - accuracy: 0.4187 - val_loss: 1.5319 - val_accuracy: 0.4500\n",
      "Epoch 17/30\n",
      "1600/1600 [==============================] - 0s 79us/sample - loss: 1.5810 - accuracy: 0.4187 - val_loss: 1.5347 - val_accuracy: 0.4500\n",
      "Epoch 18/30\n",
      "1600/1600 [==============================] - 0s 102us/sample - loss: 1.5858 - accuracy: 0.4187 - val_loss: 1.5258 - val_accuracy: 0.4500\n",
      "Epoch 19/30\n",
      "1600/1600 [==============================] - 0s 78us/sample - loss: 1.5820 - accuracy: 0.4187 - val_loss: 1.5278 - val_accuracy: 0.4500\n",
      "Epoch 20/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5752 - accuracy: 0.4187 - val_loss: 1.5286 - val_accuracy: 0.4500\n",
      "Epoch 21/30\n",
      "1600/1600 [==============================] - 0s 102us/sample - loss: 1.5745 - accuracy: 0.4187 - val_loss: 1.5235 - val_accuracy: 0.4500\n",
      "Epoch 22/30\n",
      "1600/1600 [==============================] - 0s 102us/sample - loss: 1.5668 - accuracy: 0.4187 - val_loss: 1.5139 - val_accuracy: 0.4500\n",
      "Epoch 23/30\n",
      "1600/1600 [==============================] - 0s 101us/sample - loss: 1.5674 - accuracy: 0.4187 - val_loss: 1.5136 - val_accuracy: 0.4500\n",
      "Epoch 24/30\n",
      "1600/1600 [==============================] - 0s 102us/sample - loss: 1.5548 - accuracy: 0.4187 - val_loss: 1.5079 - val_accuracy: 0.4500\n",
      "Epoch 25/30\n",
      "1600/1600 [==============================] - 0s 78us/sample - loss: 1.5524 - accuracy: 0.4187 - val_loss: 1.5690 - val_accuracy: 0.4500\n",
      "Epoch 26/30\n",
      "1600/1600 [==============================] - 0s 107us/sample - loss: 1.5553 - accuracy: 0.4187 - val_loss: 1.5034 - val_accuracy: 0.4500\n",
      "Epoch 27/30\n",
      "1600/1600 [==============================] - 0s 100us/sample - loss: 1.5267 - accuracy: 0.4212 - val_loss: 1.4800 - val_accuracy: 0.4800\n",
      "Epoch 28/30\n",
      "1600/1600 [==============================] - 0s 268us/sample - loss: 1.5119 - accuracy: 0.4406 - val_loss: 1.4396 - val_accuracy: 0.4850\n",
      "Epoch 29/30\n",
      "1600/1600 [==============================] - 0s 243us/sample - loss: 1.4890 - accuracy: 0.4519 - val_loss: 1.4346 - val_accuracy: 0.4800\n",
      "Epoch 30/30\n",
      "1600/1600 [==============================] - 0s 244us/sample - loss: 1.4787 - accuracy: 0.4475 - val_loss: 1.4182 - val_accuracy: 0.4925\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/30\n",
      "1600/1600 [==============================] - 1s 524us/sample - loss: 1.6295 - accuracy: 0.4081 - val_loss: 1.5449 - val_accuracy: 0.4500\n",
      "Epoch 2/30\n",
      "1600/1600 [==============================] - 0s 118us/sample - loss: 1.5989 - accuracy: 0.4187 - val_loss: 1.5321 - val_accuracy: 0.4500\n",
      "Epoch 3/30\n",
      "1600/1600 [==============================] - 0s 89us/sample - loss: 1.5945 - accuracy: 0.4187 - val_loss: 1.5412 - val_accuracy: 0.4500\n",
      "Epoch 4/30\n",
      "1600/1600 [==============================] - 0s 84us/sample - loss: 1.5883 - accuracy: 0.4187 - val_loss: 1.5857 - val_accuracy: 0.4500\n",
      "Epoch 5/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5871 - accuracy: 0.4187 - val_loss: 1.5334 - val_accuracy: 0.4500\n",
      "Epoch 6/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5864 - accuracy: 0.4187 - val_loss: 1.5447 - val_accuracy: 0.4500\n",
      "Epoch 7/30\n",
      "1600/1600 [==============================] - 0s 76us/sample - loss: 1.5850 - accuracy: 0.4187 - val_loss: 1.5426 - val_accuracy: 0.4500\n",
      "Epoch 8/30\n",
      "1600/1600 [==============================] - 0s 78us/sample - loss: 1.5826 - accuracy: 0.4187 - val_loss: 1.5630 - val_accuracy: 0.4500\n",
      "Epoch 9/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5884 - accuracy: 0.4187 - val_loss: 1.5327 - val_accuracy: 0.4500\n",
      "Epoch 10/30\n",
      "1600/1600 [==============================] - 0s 101us/sample - loss: 1.5866 - accuracy: 0.4187 - val_loss: 1.5300 - val_accuracy: 0.4500\n",
      "Epoch 11/30\n",
      "1600/1600 [==============================] - 0s 75us/sample - loss: 1.5839 - accuracy: 0.4187 - val_loss: 1.5327 - val_accuracy: 0.4500\n",
      "Epoch 12/30\n",
      "1600/1600 [==============================] - 0s 100us/sample - loss: 1.5873 - accuracy: 0.4187 - val_loss: 1.5300 - val_accuracy: 0.4500\n",
      "Epoch 13/30\n",
      "1600/1600 [==============================] - 0s 78us/sample - loss: 1.5833 - accuracy: 0.4187 - val_loss: 1.5309 - val_accuracy: 0.4500\n",
      "Epoch 14/30\n",
      "1600/1600 [==============================] - 0s 76us/sample - loss: 1.5753 - accuracy: 0.4187 - val_loss: 1.5357 - val_accuracy: 0.4500\n",
      "Epoch 15/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5803 - accuracy: 0.4187 - val_loss: 1.5360 - val_accuracy: 0.4500\n",
      "Epoch 16/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5821 - accuracy: 0.4187 - val_loss: 1.5327 - val_accuracy: 0.4500\n",
      "Epoch 17/30\n",
      "1600/1600 [==============================] - 0s 76us/sample - loss: 1.5813 - accuracy: 0.4187 - val_loss: 1.5338 - val_accuracy: 0.4500\n",
      "Epoch 18/30\n",
      "1600/1600 [==============================] - 0s 101us/sample - loss: 1.5740 - accuracy: 0.4187 - val_loss: 1.5288 - val_accuracy: 0.4500\n",
      "Epoch 19/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5755 - accuracy: 0.4187 - val_loss: 1.5298 - val_accuracy: 0.4500\n",
      "Epoch 20/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5764 - accuracy: 0.4187 - val_loss: 1.5419 - val_accuracy: 0.4500\n",
      "Epoch 21/30\n",
      "1600/1600 [==============================] - 0s 76us/sample - loss: 1.5742 - accuracy: 0.4187 - val_loss: 1.5388 - val_accuracy: 0.4500\n",
      "Epoch 22/30\n",
      "1600/1600 [==============================] - 0s 100us/sample - loss: 1.5723 - accuracy: 0.4187 - val_loss: 1.5238 - val_accuracy: 0.4500\n",
      "Epoch 23/30\n",
      "1600/1600 [==============================] - 0s 101us/sample - loss: 1.5701 - accuracy: 0.4187 - val_loss: 1.5117 - val_accuracy: 0.4500\n",
      "Epoch 24/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5753 - accuracy: 0.4187 - val_loss: 1.5366 - val_accuracy: 0.4500\n",
      "Epoch 25/30\n",
      "1600/1600 [==============================] - 0s 101us/sample - loss: 1.5587 - accuracy: 0.4187 - val_loss: 1.4963 - val_accuracy: 0.4500\n",
      "Epoch 26/30\n",
      "1600/1600 [==============================] - 0s 106us/sample - loss: 1.5437 - accuracy: 0.4187 - val_loss: 1.4798 - val_accuracy: 0.4500\n",
      "Epoch 27/30\n",
      "1600/1600 [==============================] - 0s 102us/sample - loss: 1.5275 - accuracy: 0.4288 - val_loss: 1.4622 - val_accuracy: 0.4775\n",
      "Epoch 28/30\n",
      "1600/1600 [==============================] - 0s 101us/sample - loss: 1.5137 - accuracy: 0.4431 - val_loss: 1.4529 - val_accuracy: 0.4900\n",
      "Epoch 29/30\n",
      "1600/1600 [==============================] - 0s 100us/sample - loss: 1.4954 - accuracy: 0.4462 - val_loss: 1.4252 - val_accuracy: 0.4950\n",
      "Epoch 30/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.4803 - accuracy: 0.4437 - val_loss: 1.4881 - val_accuracy: 0.4325\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/30\n",
      "1600/1600 [==============================] - 1s 502us/sample - loss: 1.6385 - accuracy: 0.4112 - val_loss: 1.5417 - val_accuracy: 0.4500\n",
      "Epoch 2/30\n",
      "1600/1600 [==============================] - 0s 101us/sample - loss: 1.5855 - accuracy: 0.4187 - val_loss: 1.5583 - val_accuracy: 0.4500\n",
      "Epoch 3/30\n",
      "1600/1600 [==============================] - 0s 91us/sample - loss: 1.5838 - accuracy: 0.4187 - val_loss: 1.5547 - val_accuracy: 0.4500\n",
      "Epoch 4/30\n",
      "1600/1600 [==============================] - 0s 108us/sample - loss: 1.5886 - accuracy: 0.4187 - val_loss: 1.5414 - val_accuracy: 0.4500\n",
      "Epoch 5/30\n",
      "1600/1600 [==============================] - 0s 103us/sample - loss: 1.5848 - accuracy: 0.4187 - val_loss: 1.5360 - val_accuracy: 0.4500\n",
      "Epoch 6/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5873 - accuracy: 0.4187 - val_loss: 1.5402 - val_accuracy: 0.4500\n",
      "Epoch 7/30\n",
      "1600/1600 [==============================] - 0s 76us/sample - loss: 1.5848 - accuracy: 0.4187 - val_loss: 1.5517 - val_accuracy: 0.4500\n",
      "Epoch 8/30\n",
      "1600/1600 [==============================] - 0s 75us/sample - loss: 1.5870 - accuracy: 0.4187 - val_loss: 1.5642 - val_accuracy: 0.4500\n",
      "Epoch 9/30\n",
      "1600/1600 [==============================] - 0s 116us/sample - loss: 1.5870 - accuracy: 0.4187 - val_loss: 1.5337 - val_accuracy: 0.4500\n",
      "Epoch 10/30\n",
      "1600/1600 [==============================] - 0s 101us/sample - loss: 1.5889 - accuracy: 0.4187 - val_loss: 1.5292 - val_accuracy: 0.4500\n",
      "Epoch 11/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5851 - accuracy: 0.4187 - val_loss: 1.5332 - val_accuracy: 0.4500\n",
      "Epoch 12/30\n",
      "1600/1600 [==============================] - 0s 75us/sample - loss: 1.5800 - accuracy: 0.4187 - val_loss: 1.5376 - val_accuracy: 0.4500\n",
      "Epoch 13/30\n",
      "1600/1600 [==============================] - 0s 75us/sample - loss: 1.5808 - accuracy: 0.4187 - val_loss: 1.5599 - val_accuracy: 0.4500\n",
      "Epoch 14/30\n",
      "1600/1600 [==============================] - 0s 76us/sample - loss: 1.5840 - accuracy: 0.4187 - val_loss: 1.5340 - val_accuracy: 0.4500\n",
      "Epoch 15/30\n",
      "1600/1600 [==============================] - 0s 102us/sample - loss: 1.5783 - accuracy: 0.4187 - val_loss: 1.5271 - val_accuracy: 0.4500\n",
      "Epoch 16/30\n",
      "1600/1600 [==============================] - 0s 99us/sample - loss: 1.5759 - accuracy: 0.4187 - val_loss: 1.5270 - val_accuracy: 0.4500\n",
      "Epoch 17/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5781 - accuracy: 0.4187 - val_loss: 1.5444 - val_accuracy: 0.4500\n",
      "Epoch 18/30\n",
      "1600/1600 [==============================] - 0s 98us/sample - loss: 1.5751 - accuracy: 0.4187 - val_loss: 1.5252 - val_accuracy: 0.4500\n",
      "Epoch 19/30\n",
      "1600/1600 [==============================] - 0s 76us/sample - loss: 1.5748 - accuracy: 0.4187 - val_loss: 1.5337 - val_accuracy: 0.4500\n",
      "Epoch 20/30\n",
      "1600/1600 [==============================] - 0s 99us/sample - loss: 1.5615 - accuracy: 0.4187 - val_loss: 1.5104 - val_accuracy: 0.4500\n",
      "Epoch 21/30\n",
      "1600/1600 [==============================] - 0s 76us/sample - loss: 1.5595 - accuracy: 0.4187 - val_loss: 1.5267 - val_accuracy: 0.4500\n",
      "Epoch 22/30\n",
      "1600/1600 [==============================] - 0s 102us/sample - loss: 1.5408 - accuracy: 0.4187 - val_loss: 1.4838 - val_accuracy: 0.4500\n",
      "Epoch 23/30\n",
      "1600/1600 [==============================] - 0s 102us/sample - loss: 1.5245 - accuracy: 0.4244 - val_loss: 1.4712 - val_accuracy: 0.4525\n",
      "Epoch 24/30\n",
      "1600/1600 [==============================] - 0s 100us/sample - loss: 1.5134 - accuracy: 0.4387 - val_loss: 1.4416 - val_accuracy: 0.4850\n",
      "Epoch 25/30\n",
      "1600/1600 [==============================] - 0s 101us/sample - loss: 1.4986 - accuracy: 0.4425 - val_loss: 1.4320 - val_accuracy: 0.4825\n",
      "Epoch 26/30\n",
      "1600/1600 [==============================] - 0s 124us/sample - loss: 1.4975 - accuracy: 0.4456 - val_loss: 1.4233 - val_accuracy: 0.4825\n",
      "Epoch 27/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.4732 - accuracy: 0.4462 - val_loss: 1.4413 - val_accuracy: 0.4800\n",
      "Epoch 28/30\n",
      "1600/1600 [==============================] - 0s 281us/sample - loss: 1.4534 - accuracy: 0.4550 - val_loss: 1.4156 - val_accuracy: 0.4925\n",
      "Epoch 29/30\n",
      "1600/1600 [==============================] - 0s 282us/sample - loss: 1.4340 - accuracy: 0.4613 - val_loss: 1.3841 - val_accuracy: 0.4975\n",
      "Epoch 30/30\n",
      "1600/1600 [==============================] - 0s 297us/sample - loss: 1.4262 - accuracy: 0.4569 - val_loss: 1.3611 - val_accuracy: 0.4925\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/30\n",
      "1600/1600 [==============================] - 1s 501us/sample - loss: 1.6278 - accuracy: 0.4069 - val_loss: 1.5372 - val_accuracy: 0.4500\n",
      "Epoch 2/30\n",
      "1600/1600 [==============================] - 0s 96us/sample - loss: 1.5988 - accuracy: 0.4187 - val_loss: 1.5897 - val_accuracy: 0.4500\n",
      "Epoch 3/30\n",
      "1600/1600 [==============================] - 0s 91us/sample - loss: 1.6012 - accuracy: 0.4187 - val_loss: 1.5640 - val_accuracy: 0.4500\n",
      "Epoch 4/30\n",
      "1600/1600 [==============================] - 0s 81us/sample - loss: 1.5857 - accuracy: 0.4187 - val_loss: 1.5668 - val_accuracy: 0.4500\n",
      "Epoch 5/30\n",
      "1600/1600 [==============================] - 0s 79us/sample - loss: 1.5843 - accuracy: 0.4187 - val_loss: 1.5806 - val_accuracy: 0.4500\n",
      "Epoch 6/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5927 - accuracy: 0.4187 - val_loss: 1.5544 - val_accuracy: 0.4500\n",
      "Epoch 7/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5839 - accuracy: 0.4187 - val_loss: 1.5389 - val_accuracy: 0.4500\n",
      "Epoch 8/30\n",
      "1600/1600 [==============================] - 0s 76us/sample - loss: 1.5815 - accuracy: 0.4187 - val_loss: 1.5572 - val_accuracy: 0.4500\n",
      "Epoch 9/30\n",
      "1600/1600 [==============================] - 0s 102us/sample - loss: 1.5899 - accuracy: 0.4187 - val_loss: 1.5317 - val_accuracy: 0.4500\n",
      "Epoch 10/30\n",
      "1600/1600 [==============================] - 0s 78us/sample - loss: 1.5834 - accuracy: 0.4187 - val_loss: 1.5387 - val_accuracy: 0.4500\n",
      "Epoch 11/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5841 - accuracy: 0.4187 - val_loss: 1.5333 - val_accuracy: 0.4500\n",
      "Epoch 12/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5830 - accuracy: 0.4187 - val_loss: 1.5384 - val_accuracy: 0.4500\n",
      "Epoch 13/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5790 - accuracy: 0.4187 - val_loss: 1.5386 - val_accuracy: 0.4500\n",
      "Epoch 14/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5795 - accuracy: 0.4187 - val_loss: 1.5347 - val_accuracy: 0.4500\n",
      "Epoch 15/30\n",
      "1600/1600 [==============================] - 0s 103us/sample - loss: 1.5761 - accuracy: 0.4187 - val_loss: 1.5306 - val_accuracy: 0.4500\n",
      "Epoch 16/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5814 - accuracy: 0.4187 - val_loss: 1.5422 - val_accuracy: 0.4500\n",
      "Epoch 17/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5802 - accuracy: 0.4187 - val_loss: 1.5403 - val_accuracy: 0.4500\n",
      "Epoch 18/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.5804 - accuracy: 0.4187 - val_loss: 1.5365 - val_accuracy: 0.4500\n",
      "Epoch 19/30\n",
      "1600/1600 [==============================] - 0s 76us/sample - loss: 1.5760 - accuracy: 0.4187 - val_loss: 1.5322 - val_accuracy: 0.4500\n",
      "Epoch 20/30\n",
      "1600/1600 [==============================] - 0s 104us/sample - loss: 1.5787 - accuracy: 0.4187 - val_loss: 1.5210 - val_accuracy: 0.4500\n",
      "Epoch 21/30\n",
      "1600/1600 [==============================] - 0s 102us/sample - loss: 1.5642 - accuracy: 0.4187 - val_loss: 1.5089 - val_accuracy: 0.4500\n",
      "Epoch 22/30\n",
      "1600/1600 [==============================] - 0s 106us/sample - loss: 1.5579 - accuracy: 0.4187 - val_loss: 1.5053 - val_accuracy: 0.4500\n",
      "Epoch 23/30\n",
      "1600/1600 [==============================] - 0s 78us/sample - loss: 1.5533 - accuracy: 0.4225 - val_loss: 1.5089 - val_accuracy: 0.4500\n",
      "Epoch 24/30\n",
      "1600/1600 [==============================] - 0s 100us/sample - loss: 1.5399 - accuracy: 0.4263 - val_loss: 1.4953 - val_accuracy: 0.4800\n",
      "Epoch 25/30\n",
      "1600/1600 [==============================] - 0s 118us/sample - loss: 1.5306 - accuracy: 0.4363 - val_loss: 1.4575 - val_accuracy: 0.4775\n",
      "Epoch 26/30\n",
      "1600/1600 [==============================] - 0s 99us/sample - loss: 1.5155 - accuracy: 0.4387 - val_loss: 1.4492 - val_accuracy: 0.4800\n",
      "Epoch 27/30\n",
      "1600/1600 [==============================] - 0s 102us/sample - loss: 1.4863 - accuracy: 0.4406 - val_loss: 1.4315 - val_accuracy: 0.4925\n",
      "Epoch 28/30\n",
      "1600/1600 [==============================] - 0s 101us/sample - loss: 1.4793 - accuracy: 0.4525 - val_loss: 1.4084 - val_accuracy: 0.4875\n",
      "Epoch 29/30\n",
      "1600/1600 [==============================] - 0s 77us/sample - loss: 1.4667 - accuracy: 0.4481 - val_loss: 1.4814 - val_accuracy: 0.4400\n",
      "Epoch 30/30\n",
      "1600/1600 [==============================] - 0s 103us/sample - loss: 1.4566 - accuracy: 0.4525 - val_loss: 1.4009 - val_accuracy: 0.4850\n",
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36af9387a9a43cebb1a517b925f938a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2240 samples, validate on 560 samples\n",
      "Epoch 1/30\n",
      "2240/2240 [==============================] - 1s 379us/sample - loss: 1.6237 - accuracy: 0.4183 - val_loss: 1.5803 - val_accuracy: 0.4232\n",
      "Epoch 2/30\n",
      "2240/2240 [==============================] - 0s 113us/sample - loss: 1.5776 - accuracy: 0.4268 - val_loss: 1.5701 - val_accuracy: 0.4232\n",
      "Epoch 3/30\n",
      "2240/2240 [==============================] - 0s 85us/sample - loss: 1.5774 - accuracy: 0.4268 - val_loss: 1.5701 - val_accuracy: 0.4232\n",
      "Epoch 4/30\n",
      "2240/2240 [==============================] - 0s 79us/sample - loss: 1.5790 - accuracy: 0.4268 - val_loss: 1.5720 - val_accuracy: 0.4232\n",
      "Epoch 5/30\n",
      "2240/2240 [==============================] - 0s 93us/sample - loss: 1.5763 - accuracy: 0.4268 - val_loss: 1.5695 - val_accuracy: 0.4232\n",
      "Epoch 6/30\n",
      "2240/2240 [==============================] - 0s 75us/sample - loss: 1.5688 - accuracy: 0.4268 - val_loss: 1.5764 - val_accuracy: 0.4232\n",
      "Epoch 7/30\n",
      "2240/2240 [==============================] - 0s 75us/sample - loss: 1.5686 - accuracy: 0.4268 - val_loss: 1.5800 - val_accuracy: 0.4232\n",
      "Epoch 8/30\n",
      "2240/2240 [==============================] - 0s 75us/sample - loss: 1.5744 - accuracy: 0.4268 - val_loss: 1.5737 - val_accuracy: 0.4232\n",
      "Epoch 9/30\n",
      "2240/2240 [==============================] - 0s 75us/sample - loss: 1.5730 - accuracy: 0.4268 - val_loss: 1.5697 - val_accuracy: 0.4232\n",
      "Epoch 10/30\n",
      "2240/2240 [==============================] - 0s 97us/sample - loss: 1.5659 - accuracy: 0.4268 - val_loss: 1.5610 - val_accuracy: 0.4232\n",
      "Epoch 11/30\n",
      "2240/2240 [==============================] - 0s 93us/sample - loss: 1.5662 - accuracy: 0.4268 - val_loss: 1.5583 - val_accuracy: 0.4232\n",
      "Epoch 12/30\n",
      "2240/2240 [==============================] - 0s 93us/sample - loss: 1.5509 - accuracy: 0.4268 - val_loss: 1.5375 - val_accuracy: 0.4232\n",
      "Epoch 13/30\n",
      "2240/2240 [==============================] - 0s 91us/sample - loss: 1.5295 - accuracy: 0.4272 - val_loss: 1.5105 - val_accuracy: 0.4232\n",
      "Epoch 14/30\n",
      "2240/2240 [==============================] - 0s 94us/sample - loss: 1.5137 - accuracy: 0.4393 - val_loss: 1.4972 - val_accuracy: 0.4607\n",
      "Epoch 15/30\n",
      "2240/2240 [==============================] - 0s 93us/sample - loss: 1.5008 - accuracy: 0.4549 - val_loss: 1.4719 - val_accuracy: 0.4482\n",
      "Epoch 16/30\n",
      "2240/2240 [==============================] - 0s 93us/sample - loss: 1.4809 - accuracy: 0.4558 - val_loss: 1.4604 - val_accuracy: 0.4464\n",
      "Epoch 17/30\n",
      "2240/2240 [==============================] - 0s 93us/sample - loss: 1.4530 - accuracy: 0.4647 - val_loss: 1.4395 - val_accuracy: 0.4482\n",
      "Epoch 18/30\n",
      "2240/2240 [==============================] - 0s 75us/sample - loss: 1.4400 - accuracy: 0.4621 - val_loss: 1.4591 - val_accuracy: 0.4446\n",
      "Epoch 19/30\n",
      "2240/2240 [==============================] - 0s 93us/sample - loss: 1.4507 - accuracy: 0.4540 - val_loss: 1.4151 - val_accuracy: 0.4589\n",
      "Epoch 20/30\n",
      "2240/2240 [==============================] - 0s 96us/sample - loss: 1.4132 - accuracy: 0.4741 - val_loss: 1.4021 - val_accuracy: 0.4696\n",
      "Epoch 21/30\n",
      "2240/2240 [==============================] - 0s 110us/sample - loss: 1.4089 - accuracy: 0.4688 - val_loss: 1.3893 - val_accuracy: 0.4607\n",
      "Epoch 22/30\n",
      "2240/2240 [==============================] - 1s 253us/sample - loss: 1.3878 - accuracy: 0.4746 - val_loss: 1.3475 - val_accuracy: 0.4714\n",
      "Epoch 23/30\n",
      "2240/2240 [==============================] - 1s 272us/sample - loss: 1.3706 - accuracy: 0.4763 - val_loss: 1.3405 - val_accuracy: 0.4750\n",
      "Epoch 24/30\n",
      "2240/2240 [==============================] - 1s 276us/sample - loss: 1.3609 - accuracy: 0.4759 - val_loss: 1.3320 - val_accuracy: 0.4804\n",
      "Epoch 25/30\n",
      "2240/2240 [==============================] - 1s 308us/sample - loss: 1.3465 - accuracy: 0.4848 - val_loss: 1.3142 - val_accuracy: 0.4929\n",
      "Epoch 26/30\n",
      "2240/2240 [==============================] - 1s 268us/sample - loss: 1.3420 - accuracy: 0.4888 - val_loss: 1.3076 - val_accuracy: 0.4857\n",
      "Epoch 27/30\n",
      "2240/2240 [==============================] - 1s 259us/sample - loss: 1.3273 - accuracy: 0.4915 - val_loss: 1.2915 - val_accuracy: 0.4857\n",
      "Epoch 28/30\n",
      "2240/2240 [==============================] - 1s 286us/sample - loss: 1.3243 - accuracy: 0.4821 - val_loss: 1.2912 - val_accuracy: 0.4946\n",
      "Epoch 29/30\n",
      "2240/2240 [==============================] - 1s 278us/sample - loss: 1.3055 - accuracy: 0.4902 - val_loss: 1.2745 - val_accuracy: 0.4929\n",
      "Epoch 30/30\n",
      "2240/2240 [==============================] - 1s 262us/sample - loss: 1.3079 - accuracy: 0.5004 - val_loss: 1.2636 - val_accuracy: 0.4982\n",
      "Train on 2240 samples, validate on 560 samples\n",
      "Epoch 1/30\n",
      "2240/2240 [==============================] - 1s 391us/sample - loss: 1.6247 - accuracy: 0.4187 - val_loss: 1.5728 - val_accuracy: 0.4232\n",
      "Epoch 2/30\n",
      "2240/2240 [==============================] - 0s 83us/sample - loss: 1.5758 - accuracy: 0.4268 - val_loss: 1.5790 - val_accuracy: 0.4232\n",
      "Epoch 3/30\n",
      "2240/2240 [==============================] - 0s 76us/sample - loss: 1.5749 - accuracy: 0.4268 - val_loss: 1.5750 - val_accuracy: 0.4232\n",
      "Epoch 4/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5713 - accuracy: 0.4268 - val_loss: 1.5829 - val_accuracy: 0.4232\n",
      "Epoch 5/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5784 - accuracy: 0.4268 - val_loss: 1.5778 - val_accuracy: 0.4232\n",
      "Epoch 6/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5744 - accuracy: 0.4268 - val_loss: 1.5809 - val_accuracy: 0.4232\n",
      "Epoch 7/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5731 - accuracy: 0.4268 - val_loss: 1.5734 - val_accuracy: 0.4232\n",
      "Epoch 8/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5785 - accuracy: 0.4268 - val_loss: 1.5668 - val_accuracy: 0.4232\n",
      "Epoch 9/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5720 - accuracy: 0.4268 - val_loss: 1.5644 - val_accuracy: 0.4232\n",
      "Epoch 10/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5681 - accuracy: 0.4268 - val_loss: 1.5636 - val_accuracy: 0.4232\n",
      "Epoch 11/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5655 - accuracy: 0.4268 - val_loss: 1.5576 - val_accuracy: 0.4232\n",
      "Epoch 12/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5557 - accuracy: 0.4268 - val_loss: 1.5615 - val_accuracy: 0.4232\n",
      "Epoch 13/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5560 - accuracy: 0.4268 - val_loss: 1.5591 - val_accuracy: 0.4232\n",
      "Epoch 14/30\n",
      "2240/2240 [==============================] - 0s 88us/sample - loss: 1.5435 - accuracy: 0.4268 - val_loss: 1.5306 - val_accuracy: 0.4232\n",
      "Epoch 15/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5337 - accuracy: 0.4259 - val_loss: 1.5110 - val_accuracy: 0.4232\n",
      "Epoch 16/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5095 - accuracy: 0.4379 - val_loss: 1.4927 - val_accuracy: 0.4464\n",
      "Epoch 17/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5199 - accuracy: 0.4375 - val_loss: 1.5014 - val_accuracy: 0.4268\n",
      "Epoch 18/30\n",
      "2240/2240 [==============================] - 0s 88us/sample - loss: 1.4918 - accuracy: 0.4567 - val_loss: 1.4604 - val_accuracy: 0.4536\n",
      "Epoch 19/30\n",
      "2240/2240 [==============================] - 0s 93us/sample - loss: 1.4632 - accuracy: 0.4629 - val_loss: 1.4355 - val_accuracy: 0.4607\n",
      "Epoch 20/30\n",
      "2240/2240 [==============================] - 0s 94us/sample - loss: 1.4553 - accuracy: 0.4563 - val_loss: 1.4235 - val_accuracy: 0.4679\n",
      "Epoch 21/30\n",
      "2240/2240 [==============================] - 0s 97us/sample - loss: 1.4368 - accuracy: 0.4638 - val_loss: 1.4082 - val_accuracy: 0.4714\n",
      "Epoch 22/30\n",
      "2240/2240 [==============================] - 0s 78us/sample - loss: 1.4239 - accuracy: 0.4746 - val_loss: 1.4295 - val_accuracy: 0.4589\n",
      "Epoch 23/30\n",
      "2240/2240 [==============================] - 0s 97us/sample - loss: 1.4116 - accuracy: 0.4647 - val_loss: 1.3861 - val_accuracy: 0.4750\n",
      "Epoch 24/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.4016 - accuracy: 0.4714 - val_loss: 1.3754 - val_accuracy: 0.4696\n",
      "Epoch 25/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.3817 - accuracy: 0.4705 - val_loss: 1.3489 - val_accuracy: 0.4857\n",
      "Epoch 26/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.3690 - accuracy: 0.4812 - val_loss: 1.3447 - val_accuracy: 0.4804\n",
      "Epoch 27/30\n",
      "2240/2240 [==============================] - 0s 88us/sample - loss: 1.3665 - accuracy: 0.4817 - val_loss: 1.3302 - val_accuracy: 0.4821\n",
      "Epoch 28/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.3662 - accuracy: 0.4821 - val_loss: 1.3186 - val_accuracy: 0.4875\n",
      "Epoch 29/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.3525 - accuracy: 0.4862 - val_loss: 1.3157 - val_accuracy: 0.4893\n",
      "Epoch 30/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.3472 - accuracy: 0.4897 - val_loss: 1.3144 - val_accuracy: 0.4893\n",
      "Train on 2240 samples, validate on 560 samples\n",
      "Epoch 1/30\n",
      "2240/2240 [==============================] - 1s 376us/sample - loss: 1.6205 - accuracy: 0.4179 - val_loss: 1.5704 - val_accuracy: 0.4232\n",
      "Epoch 2/30\n",
      "2240/2240 [==============================] - 0s 82us/sample - loss: 1.5737 - accuracy: 0.4268 - val_loss: 1.5779 - val_accuracy: 0.4232\n",
      "Epoch 3/30\n",
      "2240/2240 [==============================] - 0s 75us/sample - loss: 1.5785 - accuracy: 0.4268 - val_loss: 1.5738 - val_accuracy: 0.4232\n",
      "Epoch 4/30\n",
      "2240/2240 [==============================] - 0s 73us/sample - loss: 1.5787 - accuracy: 0.4268 - val_loss: 1.5857 - val_accuracy: 0.4232\n",
      "Epoch 5/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5798 - accuracy: 0.4268 - val_loss: 1.5795 - val_accuracy: 0.4232\n",
      "Epoch 6/30\n",
      "2240/2240 [==============================] - 0s 71us/sample - loss: 1.5817 - accuracy: 0.4268 - val_loss: 1.5738 - val_accuracy: 0.4232\n",
      "Epoch 7/30\n",
      "2240/2240 [==============================] - 0s 90us/sample - loss: 1.5776 - accuracy: 0.4268 - val_loss: 1.5695 - val_accuracy: 0.4232\n",
      "Epoch 8/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5724 - accuracy: 0.4268 - val_loss: 1.5720 - val_accuracy: 0.4232\n",
      "Epoch 9/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5754 - accuracy: 0.4268 - val_loss: 1.5761 - val_accuracy: 0.4232\n",
      "Epoch 10/30\n",
      "2240/2240 [==============================] - 0s 88us/sample - loss: 1.5655 - accuracy: 0.4268 - val_loss: 1.5668 - val_accuracy: 0.4232\n",
      "Epoch 11/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5675 - accuracy: 0.4268 - val_loss: 1.5569 - val_accuracy: 0.4232\n",
      "Epoch 12/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5500 - accuracy: 0.4268 - val_loss: 1.5609 - val_accuracy: 0.4232\n",
      "Epoch 13/30\n",
      "2240/2240 [==============================] - 0s 88us/sample - loss: 1.5366 - accuracy: 0.4272 - val_loss: 1.5155 - val_accuracy: 0.4232\n",
      "Epoch 14/30\n",
      "2240/2240 [==============================] - 0s 95us/sample - loss: 1.5168 - accuracy: 0.4402 - val_loss: 1.4920 - val_accuracy: 0.4446\n",
      "Epoch 15/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5020 - accuracy: 0.4518 - val_loss: 1.4799 - val_accuracy: 0.4643\n",
      "Epoch 16/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.4977 - accuracy: 0.4536 - val_loss: 1.4626 - val_accuracy: 0.4589\n",
      "Epoch 17/30\n",
      "2240/2240 [==============================] - 0s 88us/sample - loss: 1.4751 - accuracy: 0.4518 - val_loss: 1.4428 - val_accuracy: 0.4589\n",
      "Epoch 18/30\n",
      "2240/2240 [==============================] - 0s 88us/sample - loss: 1.4581 - accuracy: 0.4670 - val_loss: 1.4333 - val_accuracy: 0.4643\n",
      "Epoch 19/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.4239 - accuracy: 0.4728 - val_loss: 1.4227 - val_accuracy: 0.4607\n",
      "Epoch 20/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.4159 - accuracy: 0.4737 - val_loss: 1.3906 - val_accuracy: 0.4589\n",
      "Epoch 21/30\n",
      "2240/2240 [==============================] - 0s 88us/sample - loss: 1.4018 - accuracy: 0.4741 - val_loss: 1.3824 - val_accuracy: 0.4643\n",
      "Epoch 22/30\n",
      "2240/2240 [==============================] - 0s 88us/sample - loss: 1.3902 - accuracy: 0.4839 - val_loss: 1.3457 - val_accuracy: 0.4786\n",
      "Epoch 23/30\n",
      "2240/2240 [==============================] - 0s 90us/sample - loss: 1.3843 - accuracy: 0.4723 - val_loss: 1.3433 - val_accuracy: 0.4893\n",
      "Epoch 24/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.3586 - accuracy: 0.4830 - val_loss: 1.3184 - val_accuracy: 0.4839\n",
      "Epoch 25/30\n",
      "2240/2240 [==============================] - 0s 105us/sample - loss: 1.3442 - accuracy: 0.4857 - val_loss: 1.3123 - val_accuracy: 0.4911\n",
      "Epoch 26/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.3505 - accuracy: 0.4737 - val_loss: 1.3330 - val_accuracy: 0.4929\n",
      "Epoch 27/30\n",
      "2240/2240 [==============================] - 0s 104us/sample - loss: 1.3387 - accuracy: 0.4871 - val_loss: 1.2976 - val_accuracy: 0.4929\n",
      "Epoch 28/30\n",
      "2240/2240 [==============================] - 0s 105us/sample - loss: 1.3223 - accuracy: 0.4924 - val_loss: 1.2863 - val_accuracy: 0.4964\n",
      "Epoch 29/30\n",
      "2240/2240 [==============================] - 0s 104us/sample - loss: 1.3128 - accuracy: 0.4902 - val_loss: 1.2745 - val_accuracy: 0.5018\n",
      "Epoch 30/30\n",
      "2240/2240 [==============================] - 1s 278us/sample - loss: 1.3074 - accuracy: 0.4915 - val_loss: 1.2624 - val_accuracy: 0.5089\n",
      "Train on 2240 samples, validate on 560 samples\n",
      "Epoch 1/30\n",
      "2240/2240 [==============================] - 1s 383us/sample - loss: 1.6083 - accuracy: 0.4201 - val_loss: 1.5765 - val_accuracy: 0.4232\n",
      "Epoch 2/30\n",
      "2240/2240 [==============================] - 0s 99us/sample - loss: 1.5804 - accuracy: 0.4268 - val_loss: 1.5723 - val_accuracy: 0.4232\n",
      "Epoch 3/30\n",
      "2240/2240 [==============================] - 0s 75us/sample - loss: 1.5805 - accuracy: 0.4268 - val_loss: 1.5733 - val_accuracy: 0.4232\n",
      "Epoch 4/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5802 - accuracy: 0.4268 - val_loss: 1.5942 - val_accuracy: 0.4232\n",
      "Epoch 5/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5743 - accuracy: 0.4268 - val_loss: 1.5726 - val_accuracy: 0.4232\n",
      "Epoch 6/30\n",
      "2240/2240 [==============================] - 0s 90us/sample - loss: 1.5800 - accuracy: 0.4268 - val_loss: 1.5702 - val_accuracy: 0.4232\n",
      "Epoch 7/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5761 - accuracy: 0.4268 - val_loss: 1.5781 - val_accuracy: 0.4232\n",
      "Epoch 8/30\n",
      "2240/2240 [==============================] - 0s 88us/sample - loss: 1.5681 - accuracy: 0.4268 - val_loss: 1.5693 - val_accuracy: 0.4232\n",
      "Epoch 9/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5746 - accuracy: 0.4268 - val_loss: 1.5831 - val_accuracy: 0.4232\n",
      "Epoch 10/30\n",
      "2240/2240 [==============================] - 0s 88us/sample - loss: 1.5685 - accuracy: 0.4268 - val_loss: 1.5671 - val_accuracy: 0.4232\n",
      "Epoch 11/30\n",
      "2240/2240 [==============================] - 0s 73us/sample - loss: 1.5720 - accuracy: 0.4268 - val_loss: 1.5709 - val_accuracy: 0.4232\n",
      "Epoch 12/30\n",
      "2240/2240 [==============================] - 0s 71us/sample - loss: 1.5741 - accuracy: 0.4268 - val_loss: 1.5706 - val_accuracy: 0.4232\n",
      "Epoch 13/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5588 - accuracy: 0.4268 - val_loss: 1.5551 - val_accuracy: 0.4232\n",
      "Epoch 14/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5524 - accuracy: 0.4268 - val_loss: 1.5428 - val_accuracy: 0.4232\n",
      "Epoch 15/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5398 - accuracy: 0.4268 - val_loss: 1.5507 - val_accuracy: 0.4232\n",
      "Epoch 16/30\n",
      "2240/2240 [==============================] - 0s 88us/sample - loss: 1.5423 - accuracy: 0.4277 - val_loss: 1.5231 - val_accuracy: 0.4232\n",
      "Epoch 17/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5194 - accuracy: 0.4330 - val_loss: 1.4980 - val_accuracy: 0.4482\n",
      "Epoch 18/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.4923 - accuracy: 0.4531 - val_loss: 1.4753 - val_accuracy: 0.4482\n",
      "Epoch 19/30\n",
      "2240/2240 [==============================] - 0s 73us/sample - loss: 1.4937 - accuracy: 0.4460 - val_loss: 1.5047 - val_accuracy: 0.4429\n",
      "Epoch 20/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.4587 - accuracy: 0.4580 - val_loss: 1.4392 - val_accuracy: 0.4607\n",
      "Epoch 21/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.4530 - accuracy: 0.4612 - val_loss: 1.4180 - val_accuracy: 0.4643\n",
      "Epoch 22/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.4391 - accuracy: 0.4607 - val_loss: 1.4182 - val_accuracy: 0.4571\n",
      "Epoch 23/30\n",
      "2240/2240 [==============================] - 0s 88us/sample - loss: 1.4277 - accuracy: 0.4679 - val_loss: 1.3897 - val_accuracy: 0.4696\n",
      "Epoch 24/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.4198 - accuracy: 0.4737 - val_loss: 1.3738 - val_accuracy: 0.4625\n",
      "Epoch 25/30\n",
      "2240/2240 [==============================] - 0s 88us/sample - loss: 1.3884 - accuracy: 0.4777 - val_loss: 1.3627 - val_accuracy: 0.4643\n",
      "Epoch 26/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.3774 - accuracy: 0.4844 - val_loss: 1.3410 - val_accuracy: 0.4732\n",
      "Epoch 27/30\n",
      "2240/2240 [==============================] - 0s 90us/sample - loss: 1.3645 - accuracy: 0.4830 - val_loss: 1.3326 - val_accuracy: 0.4768\n",
      "Epoch 28/30\n",
      "2240/2240 [==============================] - 0s 73us/sample - loss: 1.3582 - accuracy: 0.4790 - val_loss: 1.3392 - val_accuracy: 0.4750\n",
      "Epoch 29/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.3549 - accuracy: 0.4826 - val_loss: 1.3098 - val_accuracy: 0.4821\n",
      "Epoch 30/30\n",
      "2240/2240 [==============================] - 0s 73us/sample - loss: 1.3463 - accuracy: 0.4830 - val_loss: 1.3236 - val_accuracy: 0.4857\n",
      "Train on 2240 samples, validate on 560 samples\n",
      "Epoch 1/30\n",
      "2240/2240 [==============================] - 1s 380us/sample - loss: 1.6341 - accuracy: 0.4179 - val_loss: 1.5734 - val_accuracy: 0.4232\n",
      "Epoch 2/30\n",
      "2240/2240 [==============================] - 0s 94us/sample - loss: 1.5750 - accuracy: 0.4268 - val_loss: 1.5790 - val_accuracy: 0.4232\n",
      "Epoch 3/30\n",
      "2240/2240 [==============================] - 0s 80us/sample - loss: 1.5814 - accuracy: 0.4268 - val_loss: 1.5747 - val_accuracy: 0.4232\n",
      "Epoch 4/30\n",
      "2240/2240 [==============================] - 0s 90us/sample - loss: 1.5810 - accuracy: 0.4268 - val_loss: 1.5687 - val_accuracy: 0.4232\n",
      "Epoch 5/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5788 - accuracy: 0.4268 - val_loss: 1.5747 - val_accuracy: 0.4232\n",
      "Epoch 6/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5715 - accuracy: 0.4268 - val_loss: 1.5932 - val_accuracy: 0.4232\n",
      "Epoch 7/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5715 - accuracy: 0.4268 - val_loss: 1.5721 - val_accuracy: 0.4232\n",
      "Epoch 8/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5750 - accuracy: 0.4268 - val_loss: 1.5765 - val_accuracy: 0.4232\n",
      "Epoch 9/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5790 - accuracy: 0.4268 - val_loss: 1.5694 - val_accuracy: 0.4232\n",
      "Epoch 10/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5714 - accuracy: 0.4268 - val_loss: 1.5704 - val_accuracy: 0.4232\n",
      "Epoch 11/30\n",
      "2240/2240 [==============================] - 0s 90us/sample - loss: 1.5706 - accuracy: 0.4268 - val_loss: 1.5685 - val_accuracy: 0.4232\n",
      "Epoch 12/30\n",
      "2240/2240 [==============================] - 0s 73us/sample - loss: 1.5762 - accuracy: 0.4268 - val_loss: 1.5688 - val_accuracy: 0.4232\n",
      "Epoch 13/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5750 - accuracy: 0.4268 - val_loss: 1.5693 - val_accuracy: 0.4232\n",
      "Epoch 14/30\n",
      "2240/2240 [==============================] - 0s 71us/sample - loss: 1.5712 - accuracy: 0.4268 - val_loss: 1.5691 - val_accuracy: 0.4232\n",
      "Epoch 15/30\n",
      "2240/2240 [==============================] - 0s 90us/sample - loss: 1.5696 - accuracy: 0.4268 - val_loss: 1.5669 - val_accuracy: 0.4232\n",
      "Epoch 16/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5699 - accuracy: 0.4268 - val_loss: 1.5692 - val_accuracy: 0.4232\n",
      "Epoch 17/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5679 - accuracy: 0.4268 - val_loss: 1.5641 - val_accuracy: 0.4232\n",
      "Epoch 18/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5682 - accuracy: 0.4268 - val_loss: 1.5613 - val_accuracy: 0.4232\n",
      "Epoch 19/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5605 - accuracy: 0.4268 - val_loss: 1.5569 - val_accuracy: 0.4232\n",
      "Epoch 20/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5520 - accuracy: 0.4268 - val_loss: 1.5459 - val_accuracy: 0.4232\n",
      "Epoch 21/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5439 - accuracy: 0.4268 - val_loss: 1.5347 - val_accuracy: 0.4232\n",
      "Epoch 22/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5339 - accuracy: 0.4304 - val_loss: 1.5131 - val_accuracy: 0.4232\n",
      "Epoch 23/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.5237 - accuracy: 0.4371 - val_loss: 1.5188 - val_accuracy: 0.4232\n",
      "Epoch 24/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.5015 - accuracy: 0.4536 - val_loss: 1.4787 - val_accuracy: 0.4518\n",
      "Epoch 25/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.4824 - accuracy: 0.4563 - val_loss: 1.4566 - val_accuracy: 0.4589\n",
      "Epoch 26/30\n",
      "2240/2240 [==============================] - 0s 90us/sample - loss: 1.4685 - accuracy: 0.4576 - val_loss: 1.4428 - val_accuracy: 0.4482\n",
      "Epoch 27/30\n",
      "2240/2240 [==============================] - 0s 90us/sample - loss: 1.4503 - accuracy: 0.4661 - val_loss: 1.4249 - val_accuracy: 0.4554\n",
      "Epoch 28/30\n",
      "2240/2240 [==============================] - 0s 90us/sample - loss: 1.4313 - accuracy: 0.4674 - val_loss: 1.4021 - val_accuracy: 0.4518\n",
      "Epoch 29/30\n",
      "2240/2240 [==============================] - 0s 72us/sample - loss: 1.4191 - accuracy: 0.4688 - val_loss: 1.4068 - val_accuracy: 0.4714\n",
      "Epoch 30/30\n",
      "2240/2240 [==============================] - 0s 89us/sample - loss: 1.4006 - accuracy: 0.4768 - val_loss: 1.3704 - val_accuracy: 0.4661\n",
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476c3fdc2d284bada60b60847fddfd6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/30\n",
      "3200/3200 [==============================] - 1s 250us/sample - loss: 1.6066 - accuracy: 0.4259 - val_loss: 1.5783 - val_accuracy: 0.4175\n",
      "Epoch 2/30\n",
      "3200/3200 [==============================] - 0s 88us/sample - loss: 1.5743 - accuracy: 0.4325 - val_loss: 1.5750 - val_accuracy: 0.4175\n",
      "Epoch 3/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.5638 - accuracy: 0.4325 - val_loss: 1.5823 - val_accuracy: 0.4175\n",
      "Epoch 4/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.5660 - accuracy: 0.4325 - val_loss: 1.5751 - val_accuracy: 0.4175\n",
      "Epoch 5/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.5641 - accuracy: 0.4325 - val_loss: 1.5856 - val_accuracy: 0.4175\n",
      "Epoch 6/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.5668 - accuracy: 0.4325 - val_loss: 1.5714 - val_accuracy: 0.4175\n",
      "Epoch 7/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5609 - accuracy: 0.4325 - val_loss: 1.5694 - val_accuracy: 0.4175\n",
      "Epoch 8/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5591 - accuracy: 0.4325 - val_loss: 1.5664 - val_accuracy: 0.4175\n",
      "Epoch 9/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.5523 - accuracy: 0.4325 - val_loss: 1.5713 - val_accuracy: 0.4175\n",
      "Epoch 10/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.5484 - accuracy: 0.4325 - val_loss: 1.5492 - val_accuracy: 0.4175\n",
      "Epoch 11/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5205 - accuracy: 0.4328 - val_loss: 1.5302 - val_accuracy: 0.4175\n",
      "Epoch 12/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5060 - accuracy: 0.4506 - val_loss: 1.4899 - val_accuracy: 0.4475\n",
      "Epoch 13/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.4745 - accuracy: 0.4594 - val_loss: 1.4951 - val_accuracy: 0.4450\n",
      "Epoch 14/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.4514 - accuracy: 0.4603 - val_loss: 1.4518 - val_accuracy: 0.4525\n",
      "Epoch 15/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.4273 - accuracy: 0.4700 - val_loss: 1.4300 - val_accuracy: 0.4600\n",
      "Epoch 16/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.4105 - accuracy: 0.4722 - val_loss: 1.4098 - val_accuracy: 0.4638\n",
      "Epoch 17/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.3819 - accuracy: 0.4797 - val_loss: 1.3843 - val_accuracy: 0.4650\n",
      "Epoch 18/30\n",
      "3200/3200 [==============================] - 0s 96us/sample - loss: 1.3708 - accuracy: 0.4775 - val_loss: 1.3664 - val_accuracy: 0.4737\n",
      "Epoch 19/30\n",
      "3200/3200 [==============================] - 0s 95us/sample - loss: 1.3444 - accuracy: 0.4834 - val_loss: 1.3452 - val_accuracy: 0.4787\n",
      "Epoch 20/30\n",
      "3200/3200 [==============================] - 0s 99us/sample - loss: 1.3380 - accuracy: 0.4897 - val_loss: 1.3170 - val_accuracy: 0.4825\n",
      "Epoch 21/30\n",
      "3200/3200 [==============================] - 0s 115us/sample - loss: 1.3196 - accuracy: 0.4991 - val_loss: 1.3032 - val_accuracy: 0.4975\n",
      "Epoch 22/30\n",
      "3200/3200 [==============================] - 0s 112us/sample - loss: 1.3076 - accuracy: 0.4959 - val_loss: 1.3013 - val_accuracy: 0.4975\n",
      "Epoch 23/30\n",
      "3200/3200 [==============================] - 0s 106us/sample - loss: 1.2818 - accuracy: 0.5134 - val_loss: 1.2763 - val_accuracy: 0.5150\n",
      "Epoch 24/30\n",
      "3200/3200 [==============================] - 0s 72us/sample - loss: 1.2845 - accuracy: 0.5056 - val_loss: 1.2952 - val_accuracy: 0.5050\n",
      "Epoch 25/30\n",
      "3200/3200 [==============================] - 1s 268us/sample - loss: 1.2791 - accuracy: 0.5013 - val_loss: 1.2592 - val_accuracy: 0.5088\n",
      "Epoch 26/30\n",
      "3200/3200 [==============================] - 0s 72us/sample - loss: 1.2764 - accuracy: 0.5078 - val_loss: 1.2622 - val_accuracy: 0.5175\n",
      "Epoch 27/30\n",
      "3200/3200 [==============================] - 1s 253us/sample - loss: 1.2746 - accuracy: 0.5147 - val_loss: 1.2427 - val_accuracy: 0.5113\n",
      "Epoch 28/30\n",
      "3200/3200 [==============================] - 1s 257us/sample - loss: 1.2570 - accuracy: 0.5163 - val_loss: 1.2313 - val_accuracy: 0.5275\n",
      "Epoch 29/30\n",
      "3200/3200 [==============================] - 0s 72us/sample - loss: 1.2499 - accuracy: 0.5119 - val_loss: 1.2437 - val_accuracy: 0.5138\n",
      "Epoch 30/30\n",
      "3200/3200 [==============================] - 1s 253us/sample - loss: 1.2395 - accuracy: 0.5166 - val_loss: 1.2287 - val_accuracy: 0.5325\n",
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/30\n",
      "3200/3200 [==============================] - 1s 308us/sample - loss: 1.5965 - accuracy: 0.4250 - val_loss: 1.5762 - val_accuracy: 0.4175\n",
      "Epoch 2/30\n",
      "3200/3200 [==============================] - 0s 88us/sample - loss: 1.5712 - accuracy: 0.4325 - val_loss: 1.5744 - val_accuracy: 0.4175\n",
      "Epoch 3/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5693 - accuracy: 0.4325 - val_loss: 1.5734 - val_accuracy: 0.4175\n",
      "Epoch 4/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.5640 - accuracy: 0.4325 - val_loss: 1.5782 - val_accuracy: 0.4175\n",
      "Epoch 5/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5651 - accuracy: 0.4325 - val_loss: 1.5702 - val_accuracy: 0.4175\n",
      "Epoch 6/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.5661 - accuracy: 0.4325 - val_loss: 1.5738 - val_accuracy: 0.4175\n",
      "Epoch 7/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5608 - accuracy: 0.4325 - val_loss: 1.5678 - val_accuracy: 0.4175\n",
      "Epoch 8/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5527 - accuracy: 0.4325 - val_loss: 1.5506 - val_accuracy: 0.4175\n",
      "Epoch 9/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.5328 - accuracy: 0.4328 - val_loss: 1.5319 - val_accuracy: 0.4175\n",
      "Epoch 10/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5020 - accuracy: 0.4425 - val_loss: 1.4990 - val_accuracy: 0.4525\n",
      "Epoch 11/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.4878 - accuracy: 0.4547 - val_loss: 1.5063 - val_accuracy: 0.4563\n",
      "Epoch 12/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.4550 - accuracy: 0.4672 - val_loss: 1.4558 - val_accuracy: 0.4550\n",
      "Epoch 13/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.4298 - accuracy: 0.4722 - val_loss: 1.4328 - val_accuracy: 0.4525\n",
      "Epoch 14/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.4102 - accuracy: 0.4716 - val_loss: 1.4075 - val_accuracy: 0.4663\n",
      "Epoch 15/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.3880 - accuracy: 0.4725 - val_loss: 1.3822 - val_accuracy: 0.4700\n",
      "Epoch 16/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.3682 - accuracy: 0.4816 - val_loss: 1.3767 - val_accuracy: 0.4725\n",
      "Epoch 17/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.3512 - accuracy: 0.4822 - val_loss: 1.3435 - val_accuracy: 0.4775\n",
      "Epoch 18/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.3350 - accuracy: 0.4894 - val_loss: 1.3166 - val_accuracy: 0.4850\n",
      "Epoch 19/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.3307 - accuracy: 0.4897 - val_loss: 1.2963 - val_accuracy: 0.4863\n",
      "Epoch 20/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.3111 - accuracy: 0.4994 - val_loss: 1.2918 - val_accuracy: 0.4988\n",
      "Epoch 21/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.2979 - accuracy: 0.5038 - val_loss: 1.2819 - val_accuracy: 0.4988\n",
      "Epoch 22/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.2768 - accuracy: 0.5047 - val_loss: 1.2569 - val_accuracy: 0.5088\n",
      "Epoch 23/30\n",
      "3200/3200 [==============================] - 0s 72us/sample - loss: 1.2861 - accuracy: 0.5041 - val_loss: 1.2795 - val_accuracy: 0.5213\n",
      "Epoch 24/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.2591 - accuracy: 0.5203 - val_loss: 1.2372 - val_accuracy: 0.5175\n",
      "Epoch 25/30\n",
      "3200/3200 [==============================] - 1s 267us/sample - loss: 1.2619 - accuracy: 0.5128 - val_loss: 1.2284 - val_accuracy: 0.5200\n",
      "Epoch 26/30\n",
      "3200/3200 [==============================] - 0s 72us/sample - loss: 1.2590 - accuracy: 0.5172 - val_loss: 1.2429 - val_accuracy: 0.5312\n",
      "Epoch 27/30\n",
      "3200/3200 [==============================] - 1s 267us/sample - loss: 1.2443 - accuracy: 0.5128 - val_loss: 1.2153 - val_accuracy: 0.5275\n",
      "Epoch 28/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.2378 - accuracy: 0.5206 - val_loss: 1.2198 - val_accuracy: 0.5462\n",
      "Epoch 29/30\n",
      "3200/3200 [==============================] - 1s 268us/sample - loss: 1.2348 - accuracy: 0.5225 - val_loss: 1.2078 - val_accuracy: 0.5300\n",
      "Epoch 30/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.2371 - accuracy: 0.5184 - val_loss: 1.2086 - val_accuracy: 0.5325\n",
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/30\n",
      "3200/3200 [==============================] - 1s 289us/sample - loss: 1.5974 - accuracy: 0.4272 - val_loss: 1.5932 - val_accuracy: 0.4175\n",
      "Epoch 2/30\n",
      "3200/3200 [==============================] - 0s 91us/sample - loss: 1.5692 - accuracy: 0.4325 - val_loss: 1.5780 - val_accuracy: 0.4175\n",
      "Epoch 3/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.5661 - accuracy: 0.4325 - val_loss: 1.5754 - val_accuracy: 0.4175\n",
      "Epoch 4/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.5646 - accuracy: 0.4325 - val_loss: 1.5798 - val_accuracy: 0.4175\n",
      "Epoch 5/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.5618 - accuracy: 0.4325 - val_loss: 1.5771 - val_accuracy: 0.4175\n",
      "Epoch 6/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.5575 - accuracy: 0.4325 - val_loss: 1.5862 - val_accuracy: 0.4175\n",
      "Epoch 7/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.5648 - accuracy: 0.4325 - val_loss: 1.5675 - val_accuracy: 0.4175\n",
      "Epoch 8/30\n",
      "3200/3200 [==============================] - 0s 72us/sample - loss: 1.5522 - accuracy: 0.4325 - val_loss: 1.5707 - val_accuracy: 0.4175\n",
      "Epoch 9/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5469 - accuracy: 0.4325 - val_loss: 1.5380 - val_accuracy: 0.4175\n",
      "Epoch 10/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5318 - accuracy: 0.4331 - val_loss: 1.5322 - val_accuracy: 0.4175\n",
      "Epoch 11/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5097 - accuracy: 0.4431 - val_loss: 1.5252 - val_accuracy: 0.4187\n",
      "Epoch 12/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.4893 - accuracy: 0.4522 - val_loss: 1.4793 - val_accuracy: 0.4462\n",
      "Epoch 13/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.4504 - accuracy: 0.4644 - val_loss: 1.4496 - val_accuracy: 0.4588\n",
      "Epoch 14/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.4280 - accuracy: 0.4697 - val_loss: 1.4239 - val_accuracy: 0.4613\n",
      "Epoch 15/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.4024 - accuracy: 0.4756 - val_loss: 1.3921 - val_accuracy: 0.4650\n",
      "Epoch 16/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.3829 - accuracy: 0.4759 - val_loss: 1.3750 - val_accuracy: 0.4737\n",
      "Epoch 17/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.3634 - accuracy: 0.4900 - val_loss: 1.3448 - val_accuracy: 0.4775\n",
      "Epoch 18/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.3482 - accuracy: 0.4847 - val_loss: 1.3216 - val_accuracy: 0.4875\n",
      "Epoch 19/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.3220 - accuracy: 0.4950 - val_loss: 1.2967 - val_accuracy: 0.4963\n",
      "Epoch 20/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.3031 - accuracy: 0.5034 - val_loss: 1.2871 - val_accuracy: 0.5050\n",
      "Epoch 21/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.2949 - accuracy: 0.5031 - val_loss: 1.2693 - val_accuracy: 0.5088\n",
      "Epoch 22/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.2818 - accuracy: 0.5072 - val_loss: 1.2640 - val_accuracy: 0.5063\n",
      "Epoch 23/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.2790 - accuracy: 0.5053 - val_loss: 1.2623 - val_accuracy: 0.5075\n",
      "Epoch 24/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.2758 - accuracy: 0.5119 - val_loss: 1.2654 - val_accuracy: 0.5350\n",
      "Epoch 25/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.2657 - accuracy: 0.5169 - val_loss: 1.2494 - val_accuracy: 0.5050\n",
      "Epoch 26/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.2586 - accuracy: 0.5050 - val_loss: 1.2317 - val_accuracy: 0.5213\n",
      "Epoch 27/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.2555 - accuracy: 0.5072 - val_loss: 1.2264 - val_accuracy: 0.5350\n",
      "Epoch 28/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.2438 - accuracy: 0.5184 - val_loss: 1.2135 - val_accuracy: 0.5225\n",
      "Epoch 29/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.2398 - accuracy: 0.5238 - val_loss: 1.2247 - val_accuracy: 0.5437\n",
      "Epoch 30/30\n",
      "3200/3200 [==============================] - 1s 278us/sample - loss: 1.2356 - accuracy: 0.5213 - val_loss: 1.2038 - val_accuracy: 0.5188\n",
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/30\n",
      "3200/3200 [==============================] - 1s 290us/sample - loss: 1.5960 - accuracy: 0.4253 - val_loss: 1.5852 - val_accuracy: 0.4175\n",
      "Epoch 2/30\n",
      "3200/3200 [==============================] - 0s 87us/sample - loss: 1.5723 - accuracy: 0.4325 - val_loss: 1.5768 - val_accuracy: 0.4175\n",
      "Epoch 3/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.5722 - accuracy: 0.4325 - val_loss: 1.5945 - val_accuracy: 0.4175\n",
      "Epoch 4/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.5638 - accuracy: 0.4325 - val_loss: 1.5738 - val_accuracy: 0.4175\n",
      "Epoch 5/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5657 - accuracy: 0.4325 - val_loss: 1.5727 - val_accuracy: 0.4175\n",
      "Epoch 6/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.5638 - accuracy: 0.4325 - val_loss: 1.5744 - val_accuracy: 0.4175\n",
      "Epoch 7/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.5625 - accuracy: 0.4325 - val_loss: 1.5726 - val_accuracy: 0.4175\n",
      "Epoch 8/30\n",
      "3200/3200 [==============================] - 0s 89us/sample - loss: 1.5600 - accuracy: 0.4325 - val_loss: 1.5693 - val_accuracy: 0.4175\n",
      "Epoch 9/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.5618 - accuracy: 0.4325 - val_loss: 1.5705 - val_accuracy: 0.4175\n",
      "Epoch 10/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5615 - accuracy: 0.4325 - val_loss: 1.5639 - val_accuracy: 0.4175\n",
      "Epoch 11/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.5510 - accuracy: 0.4325 - val_loss: 1.5698 - val_accuracy: 0.4175\n",
      "Epoch 12/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5487 - accuracy: 0.4325 - val_loss: 1.5404 - val_accuracy: 0.4175\n",
      "Epoch 13/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.5162 - accuracy: 0.4350 - val_loss: 1.5094 - val_accuracy: 0.4313\n",
      "Epoch 14/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.4933 - accuracy: 0.4466 - val_loss: 1.5071 - val_accuracy: 0.4350\n",
      "Epoch 15/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.4779 - accuracy: 0.4519 - val_loss: 1.4737 - val_accuracy: 0.4512\n",
      "Epoch 16/30\n",
      "3200/3200 [==============================] - 0s 72us/sample - loss: 1.4522 - accuracy: 0.4594 - val_loss: 1.4855 - val_accuracy: 0.4425\n",
      "Epoch 17/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.4274 - accuracy: 0.4681 - val_loss: 1.4260 - val_accuracy: 0.4575\n",
      "Epoch 18/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.4045 - accuracy: 0.4697 - val_loss: 1.4008 - val_accuracy: 0.4625\n",
      "Epoch 19/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.3839 - accuracy: 0.4766 - val_loss: 1.3786 - val_accuracy: 0.4712\n",
      "Epoch 20/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.3525 - accuracy: 0.4844 - val_loss: 1.3591 - val_accuracy: 0.4762\n",
      "Epoch 21/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.3422 - accuracy: 0.4769 - val_loss: 1.3389 - val_accuracy: 0.4712\n",
      "Epoch 22/30\n",
      "3200/3200 [==============================] - 0s 87us/sample - loss: 1.3226 - accuracy: 0.4922 - val_loss: 1.3204 - val_accuracy: 0.4913\n",
      "Epoch 23/30\n",
      "3200/3200 [==============================] - 0s 90us/sample - loss: 1.2991 - accuracy: 0.4994 - val_loss: 1.2913 - val_accuracy: 0.4925\n",
      "Epoch 24/30\n",
      "3200/3200 [==============================] - 0s 89us/sample - loss: 1.2991 - accuracy: 0.5022 - val_loss: 1.2898 - val_accuracy: 0.4925\n",
      "Epoch 25/30\n",
      "3200/3200 [==============================] - 0s 88us/sample - loss: 1.2815 - accuracy: 0.4969 - val_loss: 1.2791 - val_accuracy: 0.5075\n",
      "Epoch 26/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.2746 - accuracy: 0.5091 - val_loss: 1.2565 - val_accuracy: 0.5050\n",
      "Epoch 27/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.2660 - accuracy: 0.5116 - val_loss: 1.2459 - val_accuracy: 0.5213\n",
      "Epoch 28/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.2646 - accuracy: 0.5150 - val_loss: 1.2364 - val_accuracy: 0.5238\n",
      "Epoch 29/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.2525 - accuracy: 0.5181 - val_loss: 1.2380 - val_accuracy: 0.5300\n",
      "Epoch 30/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.2462 - accuracy: 0.5134 - val_loss: 1.2307 - val_accuracy: 0.5075\n",
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/30\n",
      "3200/3200 [==============================] - 1s 294us/sample - loss: 1.5951 - accuracy: 0.4238 - val_loss: 1.5788 - val_accuracy: 0.4175\n",
      "Epoch 2/30\n",
      "3200/3200 [==============================] - 0s 95us/sample - loss: 1.5702 - accuracy: 0.4325 - val_loss: 1.5755 - val_accuracy: 0.4175\n",
      "Epoch 3/30\n",
      "3200/3200 [==============================] - 0s 94us/sample - loss: 1.5695 - accuracy: 0.4325 - val_loss: 1.5735 - val_accuracy: 0.4175\n",
      "Epoch 4/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.5663 - accuracy: 0.4325 - val_loss: 1.5748 - val_accuracy: 0.4175\n",
      "Epoch 5/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5654 - accuracy: 0.4325 - val_loss: 1.5728 - val_accuracy: 0.4175\n",
      "Epoch 6/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.5644 - accuracy: 0.4325 - val_loss: 1.5830 - val_accuracy: 0.4175\n",
      "Epoch 7/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5664 - accuracy: 0.4325 - val_loss: 1.5721 - val_accuracy: 0.4175\n",
      "Epoch 8/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.5599 - accuracy: 0.4325 - val_loss: 1.5693 - val_accuracy: 0.4175\n",
      "Epoch 9/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5595 - accuracy: 0.4325 - val_loss: 1.5676 - val_accuracy: 0.4175\n",
      "Epoch 10/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5544 - accuracy: 0.4325 - val_loss: 1.5534 - val_accuracy: 0.4175\n",
      "Epoch 11/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5415 - accuracy: 0.4325 - val_loss: 1.5457 - val_accuracy: 0.4175\n",
      "Epoch 12/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.5230 - accuracy: 0.4334 - val_loss: 1.5126 - val_accuracy: 0.4175\n",
      "Epoch 13/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.4979 - accuracy: 0.4550 - val_loss: 1.4909 - val_accuracy: 0.4525\n",
      "Epoch 14/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.4750 - accuracy: 0.4619 - val_loss: 1.4779 - val_accuracy: 0.4550\n",
      "Epoch 15/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.4438 - accuracy: 0.4669 - val_loss: 1.4502 - val_accuracy: 0.4563\n",
      "Epoch 16/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.4292 - accuracy: 0.4725 - val_loss: 1.4351 - val_accuracy: 0.4588\n",
      "Epoch 17/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.4080 - accuracy: 0.4744 - val_loss: 1.3964 - val_accuracy: 0.4688\n",
      "Epoch 18/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.3783 - accuracy: 0.4881 - val_loss: 1.3733 - val_accuracy: 0.4700\n",
      "Epoch 19/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.3600 - accuracy: 0.4869 - val_loss: 1.3439 - val_accuracy: 0.4787\n",
      "Epoch 20/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.3404 - accuracy: 0.4950 - val_loss: 1.3258 - val_accuracy: 0.4863\n",
      "Epoch 21/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.3151 - accuracy: 0.4928 - val_loss: 1.3139 - val_accuracy: 0.4925\n",
      "Epoch 22/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.3225 - accuracy: 0.4900 - val_loss: 1.2931 - val_accuracy: 0.4975\n",
      "Epoch 23/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.2998 - accuracy: 0.5066 - val_loss: 1.2800 - val_accuracy: 0.4963\n",
      "Epoch 24/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.3034 - accuracy: 0.5022 - val_loss: 1.2851 - val_accuracy: 0.5063\n",
      "Epoch 25/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.2952 - accuracy: 0.5022 - val_loss: 1.2735 - val_accuracy: 0.5038\n",
      "Epoch 26/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.2864 - accuracy: 0.5041 - val_loss: 1.2530 - val_accuracy: 0.5113\n",
      "Epoch 27/30\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 1.2728 - accuracy: 0.5081 - val_loss: 1.2580 - val_accuracy: 0.5163\n",
      "Epoch 28/30\n",
      "3200/3200 [==============================] - 0s 84us/sample - loss: 1.2742 - accuracy: 0.5084 - val_loss: 1.2455 - val_accuracy: 0.5075\n",
      "Epoch 29/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.2632 - accuracy: 0.5122 - val_loss: 1.2443 - val_accuracy: 0.5113\n",
      "Epoch 30/30\n",
      "3200/3200 [==============================] - 0s 83us/sample - loss: 1.2616 - accuracy: 0.5113 - val_loss: 1.2367 - val_accuracy: 0.5250\n",
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd2203613e924e9b9c9c1eeca83b1271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4160 samples, validate on 1040 samples\n",
      "Epoch 1/30\n",
      "4160/4160 [==============================] - 1s 208us/sample - loss: 1.6072 - accuracy: 0.4202 - val_loss: 1.5716 - val_accuracy: 0.4125\n",
      "Epoch 2/30\n",
      "4160/4160 [==============================] - 0s 89us/sample - loss: 1.5798 - accuracy: 0.4260 - val_loss: 1.5691 - val_accuracy: 0.4125\n",
      "Epoch 3/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.5693 - accuracy: 0.4260 - val_loss: 1.5687 - val_accuracy: 0.4125\n",
      "Epoch 4/30\n",
      "4160/4160 [==============================] - 0s 81us/sample - loss: 1.5758 - accuracy: 0.4260 - val_loss: 1.5677 - val_accuracy: 0.4125\n",
      "Epoch 5/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.5703 - accuracy: 0.4260 - val_loss: 1.5658 - val_accuracy: 0.4125\n",
      "Epoch 6/30\n",
      "4160/4160 [==============================] - 0s 71us/sample - loss: 1.5697 - accuracy: 0.4260 - val_loss: 1.5686 - val_accuracy: 0.4125\n",
      "Epoch 7/30\n",
      "4160/4160 [==============================] - 0s 71us/sample - loss: 1.5691 - accuracy: 0.4260 - val_loss: 1.5726 - val_accuracy: 0.4125\n",
      "Epoch 8/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.5610 - accuracy: 0.4260 - val_loss: 1.5462 - val_accuracy: 0.4125\n",
      "Epoch 9/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.5377 - accuracy: 0.4269 - val_loss: 1.5168 - val_accuracy: 0.4365\n",
      "Epoch 10/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.5099 - accuracy: 0.4440 - val_loss: 1.4922 - val_accuracy: 0.4327\n",
      "Epoch 11/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.4759 - accuracy: 0.4577 - val_loss: 1.4528 - val_accuracy: 0.4538\n",
      "Epoch 12/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.4475 - accuracy: 0.4623 - val_loss: 1.4122 - val_accuracy: 0.4587\n",
      "Epoch 13/30\n",
      "4160/4160 [==============================] - 0s 71us/sample - loss: 1.4023 - accuracy: 0.4736 - val_loss: 1.4185 - val_accuracy: 0.4433\n",
      "Epoch 14/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.3773 - accuracy: 0.4817 - val_loss: 1.3465 - val_accuracy: 0.4788\n",
      "Epoch 15/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.3539 - accuracy: 0.4829 - val_loss: 1.3184 - val_accuracy: 0.4856\n",
      "Epoch 16/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.3344 - accuracy: 0.4906 - val_loss: 1.3154 - val_accuracy: 0.4942\n",
      "Epoch 17/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.3190 - accuracy: 0.4923 - val_loss: 1.2924 - val_accuracy: 0.4827\n",
      "Epoch 18/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.2996 - accuracy: 0.5053 - val_loss: 1.2815 - val_accuracy: 0.4923\n",
      "Epoch 19/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.2948 - accuracy: 0.5053 - val_loss: 1.2753 - val_accuracy: 0.5048\n",
      "Epoch 20/30\n",
      "4160/4160 [==============================] - 0s 90us/sample - loss: 1.2811 - accuracy: 0.5058 - val_loss: 1.2337 - val_accuracy: 0.5240\n",
      "Epoch 21/30\n",
      "4160/4160 [==============================] - 0s 71us/sample - loss: 1.2658 - accuracy: 0.5139 - val_loss: 1.2574 - val_accuracy: 0.5144\n",
      "Epoch 22/30\n",
      "4160/4160 [==============================] - 0s 70us/sample - loss: 1.2535 - accuracy: 0.5168 - val_loss: 1.2402 - val_accuracy: 0.5144\n",
      "Epoch 23/30\n",
      "4160/4160 [==============================] - 0s 89us/sample - loss: 1.2564 - accuracy: 0.5149 - val_loss: 1.2325 - val_accuracy: 0.5173\n",
      "Epoch 24/30\n",
      "4160/4160 [==============================] - 0s 98us/sample - loss: 1.2520 - accuracy: 0.5156 - val_loss: 1.2097 - val_accuracy: 0.5288\n",
      "Epoch 25/30\n",
      "4160/4160 [==============================] - 0s 100us/sample - loss: 1.2362 - accuracy: 0.5221 - val_loss: 1.2076 - val_accuracy: 0.5308\n",
      "Epoch 26/30\n",
      "4160/4160 [==============================] - 1s 269us/sample - loss: 1.2409 - accuracy: 0.5212 - val_loss: 1.2016 - val_accuracy: 0.5308\n",
      "Epoch 27/30\n",
      "4160/4160 [==============================] - 0s 71us/sample - loss: 1.2234 - accuracy: 0.5240 - val_loss: 1.2039 - val_accuracy: 0.5173\n",
      "Epoch 28/30\n",
      "4160/4160 [==============================] - 1s 262us/sample - loss: 1.2276 - accuracy: 0.5305 - val_loss: 1.1957 - val_accuracy: 0.5327\n",
      "Epoch 29/30\n",
      "4160/4160 [==============================] - 0s 71us/sample - loss: 1.2177 - accuracy: 0.5219 - val_loss: 1.2151 - val_accuracy: 0.5327\n",
      "Epoch 30/30\n",
      "4160/4160 [==============================] - 0s 70us/sample - loss: 1.2274 - accuracy: 0.5284 - val_loss: 1.1972 - val_accuracy: 0.5452\n",
      "Train on 4160 samples, validate on 1040 samples\n",
      "Epoch 1/30\n",
      "4160/4160 [==============================] - 1s 247us/sample - loss: 1.6057 - accuracy: 0.4214 - val_loss: 1.6080 - val_accuracy: 0.4125\n",
      "Epoch 2/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.5789 - accuracy: 0.4260 - val_loss: 1.5739 - val_accuracy: 0.4125\n",
      "Epoch 3/30\n",
      "4160/4160 [==============================] - 0s 70us/sample - loss: 1.5743 - accuracy: 0.4260 - val_loss: 1.5792 - val_accuracy: 0.4125\n",
      "Epoch 4/30\n",
      "4160/4160 [==============================] - 0s 70us/sample - loss: 1.5710 - accuracy: 0.4260 - val_loss: 1.5823 - val_accuracy: 0.4125\n",
      "Epoch 5/30\n",
      "4160/4160 [==============================] - 0s 70us/sample - loss: 1.5724 - accuracy: 0.4260 - val_loss: 1.5749 - val_accuracy: 0.4125\n",
      "Epoch 6/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.5701 - accuracy: 0.4260 - val_loss: 1.5695 - val_accuracy: 0.4125\n",
      "Epoch 7/30\n",
      "4160/4160 [==============================] - 0s 71us/sample - loss: 1.5706 - accuracy: 0.4260 - val_loss: 1.5698 - val_accuracy: 0.4125\n",
      "Epoch 8/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.5745 - accuracy: 0.4260 - val_loss: 1.5684 - val_accuracy: 0.4125\n",
      "Epoch 9/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.5691 - accuracy: 0.4260 - val_loss: 1.5656 - val_accuracy: 0.4125\n",
      "Epoch 10/30\n",
      "4160/4160 [==============================] - 0s 71us/sample - loss: 1.5653 - accuracy: 0.4260 - val_loss: 1.5841 - val_accuracy: 0.4125\n",
      "Epoch 11/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.5688 - accuracy: 0.4260 - val_loss: 1.5625 - val_accuracy: 0.4125\n",
      "Epoch 12/30\n",
      "4160/4160 [==============================] - 0s 79us/sample - loss: 1.5634 - accuracy: 0.4260 - val_loss: 1.5613 - val_accuracy: 0.4125\n",
      "Epoch 13/30\n",
      "4160/4160 [==============================] - 0s 70us/sample - loss: 1.5534 - accuracy: 0.4260 - val_loss: 1.5667 - val_accuracy: 0.4125\n",
      "Epoch 14/30\n",
      "4160/4160 [==============================] - 0s 82us/sample - loss: 1.5416 - accuracy: 0.4260 - val_loss: 1.5280 - val_accuracy: 0.4125\n",
      "Epoch 15/30\n",
      "4160/4160 [==============================] - 0s 85us/sample - loss: 1.5155 - accuracy: 0.4375 - val_loss: 1.5064 - val_accuracy: 0.4500\n",
      "Epoch 16/30\n",
      "4160/4160 [==============================] - 0s 84us/sample - loss: 1.4961 - accuracy: 0.4507 - val_loss: 1.4781 - val_accuracy: 0.4519\n",
      "Epoch 17/30\n",
      "4160/4160 [==============================] - 0s 81us/sample - loss: 1.4830 - accuracy: 0.4507 - val_loss: 1.4753 - val_accuracy: 0.4548\n",
      "Epoch 18/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.4610 - accuracy: 0.4603 - val_loss: 1.4590 - val_accuracy: 0.4510\n",
      "Epoch 19/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.4475 - accuracy: 0.4637 - val_loss: 1.4237 - val_accuracy: 0.4548\n",
      "Epoch 20/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.4329 - accuracy: 0.4632 - val_loss: 1.4198 - val_accuracy: 0.4558\n",
      "Epoch 21/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.4133 - accuracy: 0.4716 - val_loss: 1.3916 - val_accuracy: 0.4567\n",
      "Epoch 22/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.3927 - accuracy: 0.4690 - val_loss: 1.3867 - val_accuracy: 0.4663\n",
      "Epoch 23/30\n",
      "4160/4160 [==============================] - 0s 81us/sample - loss: 1.3764 - accuracy: 0.4772 - val_loss: 1.3540 - val_accuracy: 0.4702\n",
      "Epoch 24/30\n",
      "4160/4160 [==============================] - 0s 79us/sample - loss: 1.3628 - accuracy: 0.4764 - val_loss: 1.3524 - val_accuracy: 0.4721\n",
      "Epoch 25/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.3566 - accuracy: 0.4863 - val_loss: 1.3420 - val_accuracy: 0.4750\n",
      "Epoch 26/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.3538 - accuracy: 0.4798 - val_loss: 1.3265 - val_accuracy: 0.4769\n",
      "Epoch 27/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.3379 - accuracy: 0.4873 - val_loss: 1.3214 - val_accuracy: 0.4846\n",
      "Epoch 28/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.3336 - accuracy: 0.4856 - val_loss: 1.3006 - val_accuracy: 0.4885\n",
      "Epoch 29/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.3250 - accuracy: 0.4957 - val_loss: 1.2970 - val_accuracy: 0.4865\n",
      "Epoch 30/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.3266 - accuracy: 0.4928 - val_loss: 1.2924 - val_accuracy: 0.4971\n",
      "Train on 4160 samples, validate on 1040 samples\n",
      "Epoch 1/30\n",
      "4160/4160 [==============================] - 1s 209us/sample - loss: 1.5933 - accuracy: 0.4226 - val_loss: 1.5937 - val_accuracy: 0.4125\n",
      "Epoch 2/30\n",
      "4160/4160 [==============================] - 0s 88us/sample - loss: 1.5766 - accuracy: 0.4260 - val_loss: 1.5788 - val_accuracy: 0.4125\n",
      "Epoch 3/30\n",
      "4160/4160 [==============================] - 0s 71us/sample - loss: 1.5774 - accuracy: 0.4260 - val_loss: 1.5792 - val_accuracy: 0.4125\n",
      "Epoch 4/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.5722 - accuracy: 0.4260 - val_loss: 1.5734 - val_accuracy: 0.4125\n",
      "Epoch 5/30\n",
      "4160/4160 [==============================] - 0s 79us/sample - loss: 1.5676 - accuracy: 0.4260 - val_loss: 1.5671 - val_accuracy: 0.4125\n",
      "Epoch 6/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.5684 - accuracy: 0.4260 - val_loss: 1.5665 - val_accuracy: 0.4125\n",
      "Epoch 7/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.5709 - accuracy: 0.4260 - val_loss: 1.5627 - val_accuracy: 0.4125\n",
      "Epoch 8/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.5620 - accuracy: 0.4260 - val_loss: 1.5624 - val_accuracy: 0.4125\n",
      "Epoch 9/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.5500 - accuracy: 0.4260 - val_loss: 1.5411 - val_accuracy: 0.4125\n",
      "Epoch 10/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.5321 - accuracy: 0.4303 - val_loss: 1.5221 - val_accuracy: 0.4346\n",
      "Epoch 11/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.5048 - accuracy: 0.4394 - val_loss: 1.4897 - val_accuracy: 0.4442\n",
      "Epoch 12/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.4645 - accuracy: 0.4654 - val_loss: 1.4388 - val_accuracy: 0.4548\n",
      "Epoch 13/30\n",
      "4160/4160 [==============================] - 0s 86us/sample - loss: 1.4390 - accuracy: 0.4659 - val_loss: 1.4066 - val_accuracy: 0.4567\n",
      "Epoch 14/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.4106 - accuracy: 0.4752 - val_loss: 1.3930 - val_accuracy: 0.4635\n",
      "Epoch 15/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.3859 - accuracy: 0.4784 - val_loss: 1.3631 - val_accuracy: 0.4635\n",
      "Epoch 16/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.3507 - accuracy: 0.4827 - val_loss: 1.3244 - val_accuracy: 0.4798\n",
      "Epoch 17/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.3407 - accuracy: 0.4868 - val_loss: 1.3072 - val_accuracy: 0.4856\n",
      "Epoch 18/30\n",
      "4160/4160 [==============================] - 0s 89us/sample - loss: 1.3096 - accuracy: 0.4993 - val_loss: 1.2788 - val_accuracy: 0.4990\n",
      "Epoch 19/30\n",
      "4160/4160 [==============================] - 0s 89us/sample - loss: 1.3080 - accuracy: 0.4990 - val_loss: 1.2692 - val_accuracy: 0.4990\n",
      "Epoch 20/30\n",
      "4160/4160 [==============================] - 0s 89us/sample - loss: 1.2981 - accuracy: 0.5077 - val_loss: 1.2532 - val_accuracy: 0.5077\n",
      "Epoch 21/30\n",
      "4160/4160 [==============================] - 0s 89us/sample - loss: 1.2832 - accuracy: 0.5082 - val_loss: 1.2451 - val_accuracy: 0.5096\n",
      "Epoch 22/30\n",
      "4160/4160 [==============================] - 0s 71us/sample - loss: 1.2673 - accuracy: 0.5075 - val_loss: 1.2483 - val_accuracy: 0.5058\n",
      "Epoch 23/30\n",
      "4160/4160 [==============================] - 0s 71us/sample - loss: 1.2839 - accuracy: 0.5026 - val_loss: 1.2462 - val_accuracy: 0.5048\n",
      "Epoch 24/30\n",
      "4160/4160 [==============================] - 0s 94us/sample - loss: 1.2597 - accuracy: 0.5101 - val_loss: 1.2242 - val_accuracy: 0.5260\n",
      "Epoch 25/30\n",
      "4160/4160 [==============================] - 0s 89us/sample - loss: 1.2451 - accuracy: 0.5173 - val_loss: 1.2164 - val_accuracy: 0.5154\n",
      "Epoch 26/30\n",
      "4160/4160 [==============================] - 0s 71us/sample - loss: 1.2412 - accuracy: 0.5209 - val_loss: 1.2188 - val_accuracy: 0.5298\n",
      "Epoch 27/30\n",
      "4160/4160 [==============================] - 0s 95us/sample - loss: 1.2374 - accuracy: 0.5195 - val_loss: 1.2124 - val_accuracy: 0.5125\n",
      "Epoch 28/30\n",
      "4160/4160 [==============================] - 0s 71us/sample - loss: 1.2489 - accuracy: 0.5161 - val_loss: 1.2175 - val_accuracy: 0.5269\n",
      "Epoch 29/30\n",
      "4160/4160 [==============================] - 1s 278us/sample - loss: 1.2360 - accuracy: 0.5260 - val_loss: 1.1925 - val_accuracy: 0.5250\n",
      "Epoch 30/30\n",
      "4160/4160 [==============================] - 1s 288us/sample - loss: 1.2250 - accuracy: 0.5264 - val_loss: 1.1915 - val_accuracy: 0.5337\n",
      "Train on 4160 samples, validate on 1040 samples\n",
      "Epoch 1/30\n",
      "4160/4160 [==============================] - 1s 209us/sample - loss: 1.5927 - accuracy: 0.4214 - val_loss: 1.5688 - val_accuracy: 0.4125\n",
      "Epoch 2/30\n",
      "4160/4160 [==============================] - 0s 83us/sample - loss: 1.5813 - accuracy: 0.4260 - val_loss: 1.5675 - val_accuracy: 0.4125\n",
      "Epoch 3/30\n",
      "4160/4160 [==============================] - 0s 71us/sample - loss: 1.5738 - accuracy: 0.4260 - val_loss: 1.5712 - val_accuracy: 0.4125\n",
      "Epoch 4/30\n",
      "4160/4160 [==============================] - 0s 71us/sample - loss: 1.5744 - accuracy: 0.4260 - val_loss: 1.5690 - val_accuracy: 0.4125\n",
      "Epoch 5/30\n",
      "4160/4160 [==============================] - 0s 71us/sample - loss: 1.5727 - accuracy: 0.4260 - val_loss: 1.5716 - val_accuracy: 0.4125\n",
      "Epoch 6/30\n",
      "4160/4160 [==============================] - 0s 81us/sample - loss: 1.5664 - accuracy: 0.4260 - val_loss: 1.5649 - val_accuracy: 0.4125\n",
      "Epoch 7/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.5622 - accuracy: 0.4260 - val_loss: 1.5501 - val_accuracy: 0.4125\n",
      "Epoch 8/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.5344 - accuracy: 0.4281 - val_loss: 1.5216 - val_accuracy: 0.4125\n",
      "Epoch 9/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.5100 - accuracy: 0.4483 - val_loss: 1.4926 - val_accuracy: 0.4538\n",
      "Epoch 10/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.4691 - accuracy: 0.4538 - val_loss: 1.4527 - val_accuracy: 0.4548\n",
      "Epoch 11/30\n",
      "4160/4160 [==============================] - 0s 71us/sample - loss: 1.4535 - accuracy: 0.4577 - val_loss: 1.4568 - val_accuracy: 0.4471\n",
      "Epoch 12/30\n",
      "4160/4160 [==============================] - 0s 81us/sample - loss: 1.4295 - accuracy: 0.4642 - val_loss: 1.4027 - val_accuracy: 0.4625\n",
      "Epoch 13/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.3848 - accuracy: 0.4740 - val_loss: 1.3571 - val_accuracy: 0.4644\n",
      "Epoch 14/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.3628 - accuracy: 0.4764 - val_loss: 1.3241 - val_accuracy: 0.4904\n",
      "Epoch 15/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.3380 - accuracy: 0.4820 - val_loss: 1.2949 - val_accuracy: 0.4971\n",
      "Epoch 16/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.3204 - accuracy: 0.4947 - val_loss: 1.2843 - val_accuracy: 0.4971\n",
      "Epoch 17/30\n",
      "4160/4160 [==============================] - 0s 81us/sample - loss: 1.3054 - accuracy: 0.5007 - val_loss: 1.2788 - val_accuracy: 0.5029\n",
      "Epoch 18/30\n",
      "4160/4160 [==============================] - 0s 81us/sample - loss: 1.2851 - accuracy: 0.5055 - val_loss: 1.2713 - val_accuracy: 0.5077\n",
      "Epoch 19/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.2815 - accuracy: 0.5029 - val_loss: 1.2408 - val_accuracy: 0.5106\n",
      "Epoch 20/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.2609 - accuracy: 0.5147 - val_loss: 1.2356 - val_accuracy: 0.5144\n",
      "Epoch 21/30\n",
      "4160/4160 [==============================] - 0s 81us/sample - loss: 1.2598 - accuracy: 0.5144 - val_loss: 1.2313 - val_accuracy: 0.5173\n",
      "Epoch 22/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.2426 - accuracy: 0.5175 - val_loss: 1.2205 - val_accuracy: 0.5115\n",
      "Epoch 23/30\n",
      "4160/4160 [==============================] - 0s 71us/sample - loss: 1.2435 - accuracy: 0.5185 - val_loss: 1.2353 - val_accuracy: 0.5221\n",
      "Epoch 24/30\n",
      "4160/4160 [==============================] - 0s 81us/sample - loss: 1.2358 - accuracy: 0.5183 - val_loss: 1.2119 - val_accuracy: 0.5125\n",
      "Epoch 25/30\n",
      "4160/4160 [==============================] - 1s 288us/sample - loss: 1.2157 - accuracy: 0.5293 - val_loss: 1.1892 - val_accuracy: 0.5385\n",
      "Epoch 26/30\n",
      "4160/4160 [==============================] - 0s 72us/sample - loss: 1.2286 - accuracy: 0.5154 - val_loss: 1.1987 - val_accuracy: 0.5375\n",
      "Epoch 27/30\n",
      "4160/4160 [==============================] - 0s 71us/sample - loss: 1.2148 - accuracy: 0.5322 - val_loss: 1.1956 - val_accuracy: 0.5317\n",
      "Epoch 28/30\n",
      "4160/4160 [==============================] - 1s 300us/sample - loss: 1.2176 - accuracy: 0.5236 - val_loss: 1.1881 - val_accuracy: 0.5346\n",
      "Epoch 29/30\n",
      "4160/4160 [==============================] - 1s 287us/sample - loss: 1.2086 - accuracy: 0.5337 - val_loss: 1.1864 - val_accuracy: 0.5327\n",
      "Epoch 30/30\n",
      "4160/4160 [==============================] - 0s 71us/sample - loss: 1.2039 - accuracy: 0.5349 - val_loss: 1.1888 - val_accuracy: 0.5346\n",
      "Train on 4160 samples, validate on 1040 samples\n",
      "Epoch 1/30\n",
      "4160/4160 [==============================] - 1s 210us/sample - loss: 1.5990 - accuracy: 0.4216 - val_loss: 1.5729 - val_accuracy: 0.4125\n",
      "Epoch 2/30\n",
      "4160/4160 [==============================] - 0s 73us/sample - loss: 1.5745 - accuracy: 0.4260 - val_loss: 1.6025 - val_accuracy: 0.4125\n",
      "Epoch 3/30\n",
      "4160/4160 [==============================] - 0s 70us/sample - loss: 1.5735 - accuracy: 0.4260 - val_loss: 1.5732 - val_accuracy: 0.4125\n",
      "Epoch 4/30\n",
      "4160/4160 [==============================] - 0s 70us/sample - loss: 1.5712 - accuracy: 0.4260 - val_loss: 1.5831 - val_accuracy: 0.4125\n",
      "Epoch 5/30\n",
      "4160/4160 [==============================] - 0s 71us/sample - loss: 1.5725 - accuracy: 0.4260 - val_loss: 1.5799 - val_accuracy: 0.4125\n",
      "Epoch 6/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.5696 - accuracy: 0.4260 - val_loss: 1.5653 - val_accuracy: 0.4125\n",
      "Epoch 7/30\n",
      "4160/4160 [==============================] - 0s 71us/sample - loss: 1.5681 - accuracy: 0.4260 - val_loss: 1.5657 - val_accuracy: 0.4125\n",
      "Epoch 8/30\n",
      "4160/4160 [==============================] - 0s 86us/sample - loss: 1.5648 - accuracy: 0.4260 - val_loss: 1.5628 - val_accuracy: 0.4125\n",
      "Epoch 9/30\n",
      "4160/4160 [==============================] - 0s 71us/sample - loss: 1.5632 - accuracy: 0.4260 - val_loss: 1.5630 - val_accuracy: 0.4125\n",
      "Epoch 10/30\n",
      "4160/4160 [==============================] - 0s 86us/sample - loss: 1.5636 - accuracy: 0.4260 - val_loss: 1.5529 - val_accuracy: 0.4125\n",
      "Epoch 11/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.5425 - accuracy: 0.4260 - val_loss: 1.5355 - val_accuracy: 0.4125\n",
      "Epoch 12/30\n",
      "4160/4160 [==============================] - 0s 85us/sample - loss: 1.5173 - accuracy: 0.4361 - val_loss: 1.4908 - val_accuracy: 0.4538\n",
      "Epoch 13/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.4814 - accuracy: 0.4570 - val_loss: 1.4654 - val_accuracy: 0.4500\n",
      "Epoch 14/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.4599 - accuracy: 0.4538 - val_loss: 1.4409 - val_accuracy: 0.4596\n",
      "Epoch 15/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.4380 - accuracy: 0.4553 - val_loss: 1.3990 - val_accuracy: 0.4625\n",
      "Epoch 16/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.3974 - accuracy: 0.4755 - val_loss: 1.3657 - val_accuracy: 0.4788\n",
      "Epoch 17/30\n",
      "4160/4160 [==============================] - 0s 96us/sample - loss: 1.3612 - accuracy: 0.4873 - val_loss: 1.3476 - val_accuracy: 0.4865\n",
      "Epoch 18/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.3428 - accuracy: 0.4851 - val_loss: 1.3116 - val_accuracy: 0.4865\n",
      "Epoch 19/30\n",
      "4160/4160 [==============================] - 0s 87us/sample - loss: 1.3255 - accuracy: 0.4938 - val_loss: 1.2860 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "4160/4160 [==============================] - 0s 71us/sample - loss: 1.3103 - accuracy: 0.4983 - val_loss: 1.2926 - val_accuracy: 0.4981\n",
      "Epoch 21/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.3022 - accuracy: 0.5017 - val_loss: 1.2711 - val_accuracy: 0.5058\n",
      "Epoch 22/30\n",
      "4160/4160 [==============================] - 0s 81us/sample - loss: 1.2942 - accuracy: 0.5072 - val_loss: 1.2586 - val_accuracy: 0.5038\n",
      "Epoch 23/30\n",
      "4160/4160 [==============================] - 0s 71us/sample - loss: 1.2803 - accuracy: 0.5060 - val_loss: 1.2671 - val_accuracy: 0.5115\n",
      "Epoch 24/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.2878 - accuracy: 0.5072 - val_loss: 1.2442 - val_accuracy: 0.5144\n",
      "Epoch 25/30\n",
      "4160/4160 [==============================] - 0s 71us/sample - loss: 1.2737 - accuracy: 0.5127 - val_loss: 1.2575 - val_accuracy: 0.5154\n",
      "Epoch 26/30\n",
      "4160/4160 [==============================] - 0s 81us/sample - loss: 1.2704 - accuracy: 0.5111 - val_loss: 1.2309 - val_accuracy: 0.5202\n",
      "Epoch 27/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.2566 - accuracy: 0.5142 - val_loss: 1.2271 - val_accuracy: 0.5154\n",
      "Epoch 28/30\n",
      "4160/4160 [==============================] - 0s 71us/sample - loss: 1.2522 - accuracy: 0.5111 - val_loss: 1.2302 - val_accuracy: 0.5212\n",
      "Epoch 29/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.2467 - accuracy: 0.5156 - val_loss: 1.2117 - val_accuracy: 0.5212\n",
      "Epoch 30/30\n",
      "4160/4160 [==============================] - 0s 80us/sample - loss: 1.2447 - accuracy: 0.5183 - val_loss: 1.2074 - val_accuracy: 0.5269\n",
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a9945effddd4a288905c3be5f320908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5492 samples, validate on 1376 samples\n",
      "Epoch 1/30\n",
      "5492/5492 [==============================] - 1s 187us/sample - loss: 1.5958 - accuracy: 0.4201 - val_loss: 1.5845 - val_accuracy: 0.4251\n",
      "Epoch 2/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5759 - accuracy: 0.4223 - val_loss: 1.5705 - val_accuracy: 0.4251\n",
      "Epoch 3/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5694 - accuracy: 0.4223 - val_loss: 1.5557 - val_accuracy: 0.4251\n",
      "Epoch 4/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.5700 - accuracy: 0.4223 - val_loss: 1.5606 - val_accuracy: 0.4251\n",
      "Epoch 5/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5692 - accuracy: 0.4223 - val_loss: 1.5502 - val_accuracy: 0.4251\n",
      "Epoch 6/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5621 - accuracy: 0.4223 - val_loss: 1.5354 - val_accuracy: 0.4251\n",
      "Epoch 7/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5326 - accuracy: 0.4241 - val_loss: 1.5120 - val_accuracy: 0.4251\n",
      "Epoch 8/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.4996 - accuracy: 0.4461 - val_loss: 1.4639 - val_accuracy: 0.4608\n",
      "Epoch 9/30\n",
      "5492/5492 [==============================] - 0s 86us/sample - loss: 1.4622 - accuracy: 0.4585 - val_loss: 1.4277 - val_accuracy: 0.4826\n",
      "Epoch 10/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.4245 - accuracy: 0.4652 - val_loss: 1.3873 - val_accuracy: 0.4920\n",
      "Epoch 11/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3906 - accuracy: 0.4731 - val_loss: 1.3801 - val_accuracy: 0.4898\n",
      "Epoch 12/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3638 - accuracy: 0.4825 - val_loss: 1.3246 - val_accuracy: 0.5029\n",
      "Epoch 13/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3390 - accuracy: 0.4863 - val_loss: 1.2959 - val_accuracy: 0.5094\n",
      "Epoch 14/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3210 - accuracy: 0.4944 - val_loss: 1.2681 - val_accuracy: 0.5116\n",
      "Epoch 15/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3001 - accuracy: 0.5027 - val_loss: 1.2556 - val_accuracy: 0.5124\n",
      "Epoch 16/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2795 - accuracy: 0.5020 - val_loss: 1.2398 - val_accuracy: 0.5262\n",
      "Epoch 17/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2772 - accuracy: 0.5018 - val_loss: 1.2351 - val_accuracy: 0.5305\n",
      "Epoch 18/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.2667 - accuracy: 0.5118 - val_loss: 1.2491 - val_accuracy: 0.5342\n",
      "Epoch 19/30\n",
      "5492/5492 [==============================] - 0s 87us/sample - loss: 1.2605 - accuracy: 0.5102 - val_loss: 1.2201 - val_accuracy: 0.5363\n",
      "Epoch 20/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2497 - accuracy: 0.5168 - val_loss: 1.2119 - val_accuracy: 0.5371\n",
      "Epoch 21/30\n",
      "5492/5492 [==============================] - 0s 89us/sample - loss: 1.2402 - accuracy: 0.5153 - val_loss: 1.2039 - val_accuracy: 0.5371\n",
      "Epoch 22/30\n",
      "5492/5492 [==============================] - 0s 89us/sample - loss: 1.2316 - accuracy: 0.5175 - val_loss: 1.1920 - val_accuracy: 0.5436\n",
      "Epoch 23/30\n",
      "5492/5492 [==============================] - 1s 93us/sample - loss: 1.2357 - accuracy: 0.5220 - val_loss: 1.1878 - val_accuracy: 0.5443\n",
      "Epoch 24/30\n",
      "5492/5492 [==============================] - 1s 251us/sample - loss: 1.2132 - accuracy: 0.5264 - val_loss: 1.1760 - val_accuracy: 0.5523\n",
      "Epoch 25/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.2194 - accuracy: 0.5257 - val_loss: 1.1776 - val_accuracy: 0.5581\n",
      "Epoch 26/30\n",
      "5492/5492 [==============================] - 1s 255us/sample - loss: 1.2095 - accuracy: 0.5266 - val_loss: 1.1680 - val_accuracy: 0.5523\n",
      "Epoch 27/30\n",
      "5492/5492 [==============================] - 1s 250us/sample - loss: 1.2133 - accuracy: 0.5251 - val_loss: 1.1587 - val_accuracy: 0.5552\n",
      "Epoch 28/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.2111 - accuracy: 0.5266 - val_loss: 1.1665 - val_accuracy: 0.5552\n",
      "Epoch 29/30\n",
      "5492/5492 [==============================] - 1s 244us/sample - loss: 1.2044 - accuracy: 0.5313 - val_loss: 1.1517 - val_accuracy: 0.5531\n",
      "Epoch 30/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.1967 - accuracy: 0.5320 - val_loss: 1.1520 - val_accuracy: 0.5625\n",
      "Train on 5492 samples, validate on 1376 samples\n",
      "Epoch 1/30\n",
      "5492/5492 [==============================] - 1s 188us/sample - loss: 1.5967 - accuracy: 0.4179 - val_loss: 1.5685 - val_accuracy: 0.4251\n",
      "Epoch 2/30\n",
      "5492/5492 [==============================] - 0s 88us/sample - loss: 1.5749 - accuracy: 0.4223 - val_loss: 1.5646 - val_accuracy: 0.4251\n",
      "Epoch 3/30\n",
      "5492/5492 [==============================] - 0s 79us/sample - loss: 1.5726 - accuracy: 0.4223 - val_loss: 1.5718 - val_accuracy: 0.4251\n",
      "Epoch 4/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5725 - accuracy: 0.4223 - val_loss: 1.5549 - val_accuracy: 0.4251\n",
      "Epoch 5/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5716 - accuracy: 0.4223 - val_loss: 1.5534 - val_accuracy: 0.4251\n",
      "Epoch 6/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5667 - accuracy: 0.4223 - val_loss: 1.5512 - val_accuracy: 0.4251\n",
      "Epoch 7/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5457 - accuracy: 0.4226 - val_loss: 1.5188 - val_accuracy: 0.4251\n",
      "Epoch 8/30\n",
      "5492/5492 [==============================] - 0s 83us/sample - loss: 1.5151 - accuracy: 0.4361 - val_loss: 1.4808 - val_accuracy: 0.4717\n",
      "Epoch 9/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.4781 - accuracy: 0.4519 - val_loss: 1.4739 - val_accuracy: 0.4695\n",
      "Epoch 10/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.4472 - accuracy: 0.4601 - val_loss: 1.4302 - val_accuracy: 0.4775\n",
      "Epoch 11/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.4314 - accuracy: 0.4605 - val_loss: 1.3945 - val_accuracy: 0.4869\n",
      "Epoch 12/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3958 - accuracy: 0.4685 - val_loss: 1.3597 - val_accuracy: 0.4906\n",
      "Epoch 13/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3709 - accuracy: 0.4729 - val_loss: 1.3435 - val_accuracy: 0.4985\n",
      "Epoch 14/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3439 - accuracy: 0.4834 - val_loss: 1.3020 - val_accuracy: 0.5044\n",
      "Epoch 15/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3335 - accuracy: 0.4887 - val_loss: 1.2849 - val_accuracy: 0.5073\n",
      "Epoch 16/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3192 - accuracy: 0.4853 - val_loss: 1.2680 - val_accuracy: 0.5124\n",
      "Epoch 17/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3002 - accuracy: 0.4985 - val_loss: 1.2533 - val_accuracy: 0.5189\n",
      "Epoch 18/30\n",
      "5492/5492 [==============================] - 0s 83us/sample - loss: 1.2892 - accuracy: 0.5024 - val_loss: 1.2444 - val_accuracy: 0.5334\n",
      "Epoch 19/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2660 - accuracy: 0.5076 - val_loss: 1.2266 - val_accuracy: 0.5327\n",
      "Epoch 20/30\n",
      "5492/5492 [==============================] - 0s 76us/sample - loss: 1.2560 - accuracy: 0.5091 - val_loss: 1.2324 - val_accuracy: 0.5276\n",
      "Epoch 21/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2670 - accuracy: 0.5084 - val_loss: 1.2153 - val_accuracy: 0.5392\n",
      "Epoch 22/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2454 - accuracy: 0.5146 - val_loss: 1.2088 - val_accuracy: 0.5443\n",
      "Epoch 23/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2394 - accuracy: 0.5231 - val_loss: 1.1908 - val_accuracy: 0.5458\n",
      "Epoch 24/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.2365 - accuracy: 0.5164 - val_loss: 1.1925 - val_accuracy: 0.5392\n",
      "Epoch 25/30\n",
      "5492/5492 [==============================] - 0s 83us/sample - loss: 1.2259 - accuracy: 0.5237 - val_loss: 1.1792 - val_accuracy: 0.5531\n",
      "Epoch 26/30\n",
      "5492/5492 [==============================] - 0s 76us/sample - loss: 1.2237 - accuracy: 0.5271 - val_loss: 1.1920 - val_accuracy: 0.5349\n",
      "Epoch 27/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2290 - accuracy: 0.5224 - val_loss: 1.1688 - val_accuracy: 0.5523\n",
      "Epoch 28/30\n",
      "5492/5492 [==============================] - 0s 76us/sample - loss: 1.2169 - accuracy: 0.5269 - val_loss: 1.1793 - val_accuracy: 0.5422\n",
      "Epoch 29/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2101 - accuracy: 0.5244 - val_loss: 1.1670 - val_accuracy: 0.5574\n",
      "Epoch 30/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.1998 - accuracy: 0.5242 - val_loss: 1.1643 - val_accuracy: 0.5523\n",
      "Train on 5492 samples, validate on 1376 samples\n",
      "Epoch 1/30\n",
      "5492/5492 [==============================] - 1s 188us/sample - loss: 1.5933 - accuracy: 0.4193 - val_loss: 1.5555 - val_accuracy: 0.4251\n",
      "Epoch 2/30\n",
      "5492/5492 [==============================] - 0s 76us/sample - loss: 1.5773 - accuracy: 0.4223 - val_loss: 1.5592 - val_accuracy: 0.4251\n",
      "Epoch 3/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.5706 - accuracy: 0.4223 - val_loss: 1.5562 - val_accuracy: 0.4251\n",
      "Epoch 4/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.5752 - accuracy: 0.4223 - val_loss: 1.5562 - val_accuracy: 0.4251\n",
      "Epoch 5/30\n",
      "5492/5492 [==============================] - 0s 83us/sample - loss: 1.5657 - accuracy: 0.4223 - val_loss: 1.5476 - val_accuracy: 0.4251\n",
      "Epoch 6/30\n",
      "5492/5492 [==============================] - 0s 74us/sample - loss: 1.5539 - accuracy: 0.4223 - val_loss: 1.5504 - val_accuracy: 0.4251\n",
      "Epoch 7/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5365 - accuracy: 0.4230 - val_loss: 1.4964 - val_accuracy: 0.4251\n",
      "Epoch 8/30\n",
      "5492/5492 [==============================] - 0s 85us/sample - loss: 1.5025 - accuracy: 0.4459 - val_loss: 1.4743 - val_accuracy: 0.4738\n",
      "Epoch 9/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.4629 - accuracy: 0.4570 - val_loss: 1.4298 - val_accuracy: 0.4818\n",
      "Epoch 10/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.4178 - accuracy: 0.4681 - val_loss: 1.3812 - val_accuracy: 0.4891\n",
      "Epoch 11/30\n",
      "5492/5492 [==============================] - 0s 84us/sample - loss: 1.3809 - accuracy: 0.4734 - val_loss: 1.3322 - val_accuracy: 0.4985\n",
      "Epoch 12/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3424 - accuracy: 0.4878 - val_loss: 1.2999 - val_accuracy: 0.5116\n",
      "Epoch 13/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3235 - accuracy: 0.4900 - val_loss: 1.2801 - val_accuracy: 0.5094\n",
      "Epoch 14/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3039 - accuracy: 0.4967 - val_loss: 1.2590 - val_accuracy: 0.5153\n",
      "Epoch 15/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2866 - accuracy: 0.4971 - val_loss: 1.2449 - val_accuracy: 0.5203\n",
      "Epoch 16/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2749 - accuracy: 0.5047 - val_loss: 1.2243 - val_accuracy: 0.5247\n",
      "Epoch 17/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2650 - accuracy: 0.5098 - val_loss: 1.2180 - val_accuracy: 0.5334\n",
      "Epoch 18/30\n",
      "5492/5492 [==============================] - 0s 76us/sample - loss: 1.2594 - accuracy: 0.5188 - val_loss: 1.2221 - val_accuracy: 0.5276\n",
      "Epoch 19/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.2538 - accuracy: 0.5113 - val_loss: 1.2205 - val_accuracy: 0.5298\n",
      "Epoch 20/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2384 - accuracy: 0.5160 - val_loss: 1.1952 - val_accuracy: 0.5349\n",
      "Epoch 21/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2386 - accuracy: 0.5204 - val_loss: 1.1933 - val_accuracy: 0.5407\n",
      "Epoch 22/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2315 - accuracy: 0.5262 - val_loss: 1.1923 - val_accuracy: 0.5574\n",
      "Epoch 23/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.2215 - accuracy: 0.5217 - val_loss: 1.1958 - val_accuracy: 0.5589\n",
      "Epoch 24/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2121 - accuracy: 0.5239 - val_loss: 1.1716 - val_accuracy: 0.5560\n",
      "Epoch 25/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2087 - accuracy: 0.5317 - val_loss: 1.1708 - val_accuracy: 0.5494\n",
      "Epoch 26/30\n",
      "5492/5492 [==============================] - 0s 89us/sample - loss: 1.2038 - accuracy: 0.5286 - val_loss: 1.1626 - val_accuracy: 0.5618\n",
      "Epoch 27/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.2027 - accuracy: 0.5330 - val_loss: 1.1639 - val_accuracy: 0.5581\n",
      "Epoch 28/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.2044 - accuracy: 0.5295 - val_loss: 1.1711 - val_accuracy: 0.5618\n",
      "Epoch 29/30\n",
      "5492/5492 [==============================] - 0s 89us/sample - loss: 1.1913 - accuracy: 0.5328 - val_loss: 1.1568 - val_accuracy: 0.5574\n",
      "Epoch 30/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.1939 - accuracy: 0.5350 - val_loss: 1.1621 - val_accuracy: 0.5560\n",
      "Train on 5492 samples, validate on 1376 samples\n",
      "Epoch 1/30\n",
      "5492/5492 [==============================] - 1s 187us/sample - loss: 1.5936 - accuracy: 0.4182 - val_loss: 1.5611 - val_accuracy: 0.4251\n",
      "Epoch 2/30\n",
      "5492/5492 [==============================] - 0s 76us/sample - loss: 1.5752 - accuracy: 0.4223 - val_loss: 1.5763 - val_accuracy: 0.4251\n",
      "Epoch 3/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.5713 - accuracy: 0.4223 - val_loss: 1.5736 - val_accuracy: 0.4251\n",
      "Epoch 4/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5722 - accuracy: 0.4223 - val_loss: 1.5560 - val_accuracy: 0.4251\n",
      "Epoch 5/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.5704 - accuracy: 0.4223 - val_loss: 1.5585 - val_accuracy: 0.4251\n",
      "Epoch 6/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5606 - accuracy: 0.4223 - val_loss: 1.5479 - val_accuracy: 0.4251\n",
      "Epoch 7/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5381 - accuracy: 0.4250 - val_loss: 1.5060 - val_accuracy: 0.4469\n",
      "Epoch 8/30\n",
      "5492/5492 [==============================] - 0s 83us/sample - loss: 1.4966 - accuracy: 0.4448 - val_loss: 1.4863 - val_accuracy: 0.4455\n",
      "Epoch 9/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.4643 - accuracy: 0.4558 - val_loss: 1.4530 - val_accuracy: 0.4658\n",
      "Epoch 10/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.4250 - accuracy: 0.4605 - val_loss: 1.3991 - val_accuracy: 0.4891\n",
      "Epoch 11/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3908 - accuracy: 0.4745 - val_loss: 1.3625 - val_accuracy: 0.4891\n",
      "Epoch 12/30\n",
      "5492/5492 [==============================] - 0s 83us/sample - loss: 1.3752 - accuracy: 0.4743 - val_loss: 1.3337 - val_accuracy: 0.5015\n",
      "Epoch 13/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3532 - accuracy: 0.4782 - val_loss: 1.3063 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "5492/5492 [==============================] - 0s 83us/sample - loss: 1.3255 - accuracy: 0.4843 - val_loss: 1.2833 - val_accuracy: 0.5058\n",
      "Epoch 15/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3223 - accuracy: 0.4916 - val_loss: 1.2659 - val_accuracy: 0.5131\n",
      "Epoch 16/30\n",
      "5492/5492 [==============================] - 0s 83us/sample - loss: 1.2908 - accuracy: 0.5018 - val_loss: 1.2603 - val_accuracy: 0.5153\n",
      "Epoch 17/30\n",
      "5492/5492 [==============================] - 0s 87us/sample - loss: 1.2791 - accuracy: 0.5082 - val_loss: 1.2354 - val_accuracy: 0.5334\n",
      "Epoch 18/30\n",
      "5492/5492 [==============================] - 0s 87us/sample - loss: 1.2806 - accuracy: 0.5049 - val_loss: 1.2293 - val_accuracy: 0.5400\n",
      "Epoch 19/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2629 - accuracy: 0.5089 - val_loss: 1.2200 - val_accuracy: 0.5312\n",
      "Epoch 20/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2493 - accuracy: 0.5180 - val_loss: 1.2168 - val_accuracy: 0.5342\n",
      "Epoch 21/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2448 - accuracy: 0.5133 - val_loss: 1.2111 - val_accuracy: 0.5276\n",
      "Epoch 22/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2452 - accuracy: 0.5162 - val_loss: 1.1885 - val_accuracy: 0.5487\n",
      "Epoch 23/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.2284 - accuracy: 0.5188 - val_loss: 1.2021 - val_accuracy: 0.5334\n",
      "Epoch 24/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2247 - accuracy: 0.5182 - val_loss: 1.1777 - val_accuracy: 0.5552\n",
      "Epoch 25/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.2154 - accuracy: 0.5295 - val_loss: 1.1829 - val_accuracy: 0.5407\n",
      "Epoch 26/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2157 - accuracy: 0.5200 - val_loss: 1.1759 - val_accuracy: 0.5523\n",
      "Epoch 27/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.2150 - accuracy: 0.5248 - val_loss: 1.1780 - val_accuracy: 0.5509\n",
      "Epoch 28/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2026 - accuracy: 0.5255 - val_loss: 1.1721 - val_accuracy: 0.5472\n",
      "Epoch 29/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.1989 - accuracy: 0.5297 - val_loss: 1.1696 - val_accuracy: 0.5567\n",
      "Epoch 30/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.1976 - accuracy: 0.5310 - val_loss: 1.1607 - val_accuracy: 0.5531\n",
      "Train on 5492 samples, validate on 1376 samples\n",
      "Epoch 1/30\n",
      "5492/5492 [==============================] - 1s 213us/sample - loss: 1.5910 - accuracy: 0.4170 - val_loss: 1.5692 - val_accuracy: 0.4251\n",
      "Epoch 2/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5752 - accuracy: 0.4223 - val_loss: 1.5636 - val_accuracy: 0.4251\n",
      "Epoch 3/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5716 - accuracy: 0.4223 - val_loss: 1.5584 - val_accuracy: 0.4251\n",
      "Epoch 4/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5741 - accuracy: 0.4223 - val_loss: 1.5564 - val_accuracy: 0.4251\n",
      "Epoch 5/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5714 - accuracy: 0.4223 - val_loss: 1.5500 - val_accuracy: 0.4251\n",
      "Epoch 6/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5526 - accuracy: 0.4223 - val_loss: 1.5243 - val_accuracy: 0.4251\n",
      "Epoch 7/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.5354 - accuracy: 0.4213 - val_loss: 1.5115 - val_accuracy: 0.4251\n",
      "Epoch 8/30\n",
      "5492/5492 [==============================] - 0s 81us/sample - loss: 1.4830 - accuracy: 0.4470 - val_loss: 1.4661 - val_accuracy: 0.4644\n",
      "Epoch 9/30\n",
      "5492/5492 [==============================] - 0s 83us/sample - loss: 1.4464 - accuracy: 0.4599 - val_loss: 1.4081 - val_accuracy: 0.4746\n",
      "Epoch 10/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.4051 - accuracy: 0.4656 - val_loss: 1.3665 - val_accuracy: 0.4920\n",
      "Epoch 11/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3689 - accuracy: 0.4789 - val_loss: 1.3275 - val_accuracy: 0.4985\n",
      "Epoch 12/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3530 - accuracy: 0.4832 - val_loss: 1.3155 - val_accuracy: 0.5102\n",
      "Epoch 13/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3376 - accuracy: 0.4873 - val_loss: 1.2983 - val_accuracy: 0.4971\n",
      "Epoch 14/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.3100 - accuracy: 0.4987 - val_loss: 1.2802 - val_accuracy: 0.5015\n",
      "Epoch 15/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2953 - accuracy: 0.5035 - val_loss: 1.2564 - val_accuracy: 0.5211\n",
      "Epoch 16/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.2792 - accuracy: 0.5066 - val_loss: 1.2572 - val_accuracy: 0.5138\n",
      "Epoch 17/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2668 - accuracy: 0.5107 - val_loss: 1.2208 - val_accuracy: 0.5407\n",
      "Epoch 18/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.2520 - accuracy: 0.5173 - val_loss: 1.2211 - val_accuracy: 0.5436\n",
      "Epoch 19/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2527 - accuracy: 0.5137 - val_loss: 1.2053 - val_accuracy: 0.5298\n",
      "Epoch 20/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2373 - accuracy: 0.5177 - val_loss: 1.1935 - val_accuracy: 0.5385\n",
      "Epoch 21/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2376 - accuracy: 0.5162 - val_loss: 1.1909 - val_accuracy: 0.5487\n",
      "Epoch 22/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2321 - accuracy: 0.5215 - val_loss: 1.1791 - val_accuracy: 0.5618\n",
      "Epoch 23/30\n",
      "5492/5492 [==============================] - 0s 75us/sample - loss: 1.2236 - accuracy: 0.5259 - val_loss: 1.1845 - val_accuracy: 0.5392\n",
      "Epoch 24/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2155 - accuracy: 0.5231 - val_loss: 1.1760 - val_accuracy: 0.5516\n",
      "Epoch 25/30\n",
      "5492/5492 [==============================] - 0s 82us/sample - loss: 1.2018 - accuracy: 0.5302 - val_loss: 1.1651 - val_accuracy: 0.5560\n",
      "Epoch 26/30\n",
      "5492/5492 [==============================] - 1s 106us/sample - loss: 1.2043 - accuracy: 0.5244 - val_loss: 1.1551 - val_accuracy: 0.5589\n",
      "Epoch 27/30\n",
      "5492/5492 [==============================] - 1s 270us/sample - loss: 1.1863 - accuracy: 0.5308 - val_loss: 1.1512 - val_accuracy: 0.5618\n",
      "Epoch 28/30\n",
      "5492/5492 [==============================] - 2s 276us/sample - loss: 1.1892 - accuracy: 0.5344 - val_loss: 1.1465 - val_accuracy: 0.5618\n",
      "Epoch 29/30\n",
      "5492/5492 [==============================] - 2s 276us/sample - loss: 1.1899 - accuracy: 0.5364 - val_loss: 1.1460 - val_accuracy: 0.5640\n",
      "Epoch 30/30\n",
      "5492/5492 [==============================] - 2s 283us/sample - loss: 1.1820 - accuracy: 0.5317 - val_loss: 1.1427 - val_accuracy: 0.5654\n",
      "\r"
     ]
    }
   ],
   "source": [
    "# from experiment import run_generic_keras_experiment\n",
    "results_list = []\n",
    "for rep_no in range(reps):\n",
    "    train_idx_dict, test_idx_dict = subsample(meta_data, \"race\", \n",
    "                                              list(filter(lambda x: x != \"Other\", subgroups)), rep_no)\n",
    "\n",
    "    for tsize in train_sizes:\n",
    "        train_idx = []\n",
    "        valid_idx = []\n",
    "        test_idx = []\n",
    "\n",
    "        # adding up all subgroup indices\n",
    "        for group in filter(lambda x: x != \"Other\", subgroups):\n",
    "            train_idx += train_idx_dict[group][:int(tsize * (1 - validation_ratio))]\n",
    "            valid_idx += train_idx_dict[group][int(tsize * (1 - validation_ratio)):int(tsize)]\n",
    "            test_idx += test_idx_dict[group][:tsize]\n",
    "            \n",
    "            # test to make sure train (+valid): test is 50:50\n",
    "            assert(\n",
    "                len(train_idx_dict[group][:int(tsize * (1 - validation_ratio))]) +\n",
    "                len(train_idx_dict[group][int(tsize * (1 - validation_ratio)):int(tsize)]) == len(test_idx_dict[group][:tsize]))\n",
    "        \n",
    "        try:\n",
    "            # running the experiment\n",
    "            results = run_generic_keras_experiment(\n",
    "                binary_data = X,\n",
    "                meta_data= meta_data,\n",
    "                y_label='y', \n",
    "                z_label=\"race\",\n",
    "                z_values=list(filter(lambda x: x != \"Other\", subgroups)),\n",
    "                clf=clf,\n",
    "                validation=None,\n",
    "                train_valid_test_idx=(train_idx, valid_idx, test_idx),\n",
    "                clf_name=\"ff_keras\",\n",
    "                fit_args=fit_args,\n",
    "                num_batches=num_batches,\n",
    "                synthetic_bins=10,\n",
    "                diagnose_calibration=False,\n",
    "                balanced=False,\n",
    "                y_range=[0, 1, 2, 3, 4, 5],\n",
    "                random_state=None,\n",
    "                save_best_only=True,\n",
    "                checkpoint=checkpoint_path,\n",
    "                compile_parameters=None)\n",
    "            \n",
    "        except:\n",
    "            results = pd.DataFrame([None])\n",
    "\n",
    "        # adding metadata\n",
    "        results = results.assign(tsize=tsize, rep_no=rep_no)\n",
    "\n",
    "        results_list.append(results)\n",
    "        \n",
    "#     if rep_no % 3 == 0:\n",
    "#         pd.to_pickle(results_list, \"results/subgroup_distro_jan27_temp.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import max_disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "_to_merge = []\n",
    "for results in results_list:\n",
    "    if len(results) == 1:\n",
    "        continue\n",
    "    agg_res = results.groupby([\"subgroup\", \"batch_no\", \"attacker\", \"tsize\"]).agg(\"mean\")\n",
    "    _to_merge.append(agg_res)\n",
    "\n",
    "aggregated_results = pd.concat(_to_merge).groupby([\"subgroup\", \"attacker\", \"tsize\", \"rep_no\"]).agg(\"mean\")\n",
    "# aggregated_results = pd.concat(_to_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd795f5c668>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20,8), sharey=True)\n",
    "sns.pointplot(data=aggregated_results.reset_index().query(\"attacker == 'discriminating'\"), hue_order=[\"Asian\", \"Black\", \"Indian\", \"White\", \"Overall\"],\n",
    "                                                          x=\"tsize\", y=\"vuln\", hue=\"subgroup\", ax=ax[0], legend=None)\n",
    "\n",
    "sns.pointplot(data=aggregated_results.reset_index().query(\"attacker == 'regular'\"), hue_order=[\"Asian\", \"Black\", \"Indian\", \"White\", \"Overall\"],\n",
    "                                                          x=\"tsize\", y=\"vuln\", hue=\"subgroup\", ax=ax[1])\n",
    "\n",
    "ax[0].set_title(\"Discriminating Attacker\")\n",
    "ax[1].set_title(\"Regular Attacker\")\n",
    "ax[0].legend().remove()\n",
    "ax[1].legend(loc='center left', bbox_to_anchor=(1, 0.5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2_p36] *",
   "language": "python",
   "name": "conda-env-tensorflow2_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
