"""
Vulnerability estimation code.
"""

import itertools
import numpy as np
import pandas as pd


class GenericAttacker:
    def __init__(self, attacker_clf, p_label, y_label, z_label, attacker_type):
        self.clf = attacker_clf
        self.p_label = p_label
        self.y_label = y_label
        self.z_label = z_label
        self.encoder = {}

        if attacker_type == "Discriminating" or attacker_type == "Regular":
            self.type = attacker_type
        else:
            raise NotImplementedError(
                "Attacker type can be either `Discriminating` or `Regular`"
            )

    def fit(self, learn_df):
        subgroups = learn_df[self.z_label].unique().tolist()
        self.encoder = dict(zip(subgroups, range(len(subgroups))))
        learn_df = learn_df.copy()
        learn_df[self.z_label] = learn_df[self.z_label].apply(lambda x: self.encoder[x])

        if self.type == "Discriminating":
            self.clf.fit(
                learn_df[[self.z_label, self.y_label, self.p_label]].values,
                learn_df["m"],
            )
        else:
            self.clf.fit(learn_df[[self.y_label, self.p_label]].values, learn_df["m"])

    def predict(self, record):
        record[self.z_label] = self.encoder[record[self.z_label]]

        if self.type == "Discriminating":
            return self.clf.predict(
                record[[self.z_label, self.y_label, self.p_label]].values.reshape(1, -1)
            )[0]
        else:
            return self.clf.predict(
                record[[self.y_label, self.p_label]].values.reshape(1, -1)
            )[0]

    def score(self, eval_df):
        return eval_df.apply(axis=1, func=lambda x: self.predict(x) == x.m).mean()


class ProbabilityEstimator:
    """
    Probability operator builder.

    >>> X = pd.DataFrame({"a": [1, 1, 2], "b": [3, 6, 3]})
    >>> prob_est = ProbabilityEstimator()
    >>> prob_est.of("a", 1).given("b", 4).fit(X)
    0.0
    >>> prob_est.of("a", 1).given("b", 3).fit(X)
    0.5
    >>> prob_est.of("a", 1).given("b", 6).fit(X)
    1.0
    """

    def __init__(self, of=None, given=None):
        self.lhs_exprs = of or {}
        self.rhs_exprs = given or {}

    def clear(self):
        self.lhs_exprs = {}
        self.rhs_exprs = {}

    @staticmethod
    def _build_query(**kwargs):
        queries = [f"`{k}` == {repr(v)}" for (k, v) in kwargs.items()]
        return " and ".join(queries)

    def __repr__(self):
        return f"ProbabilityEstimator(of={self.lhs_exprs}, given={self.rhs_exprs})"

    def of(self, label, value):
        self.lhs_exprs[label] = value
        return self

    def given(self, label, value):
        self.rhs_exprs[label] = value
        return self

    def fit(self, X):
        count_df = X.query(self._build_query(**self.lhs_exprs, **self.rhs_exprs))
        count = len(count_df)
        if self.rhs_exprs:
            norm_df = X.query(self._build_query(**self.rhs_exprs))
            norm = len(norm_df)
        else:
            norm = len(X)
        self.clear()

        if norm == 0.0:
            return 0.
        return count / norm


class Adv:
    """Regular adversary."""

    def __init__(self, obs_space, p_label, y_label):
        self.obs_space = obs_space
        self.p_label = p_label
        self.y_label = y_label

    def fit(self, X):
        self.decisions_ = {}
        for p, y in self.obs_space:
            # max_m Pr[m, p, y] - more numerically stable than the conditional.
            vuln0 = (
                ProbabilityEstimator()
                .of("m", 0)
                .of(self.p_label, p)
                .of(self.y_label, y)
                .fit(X)
            )
            vuln1 = (
                ProbabilityEstimator()
                .of("m", 1)
                .of(self.p_label, p)
                .of(self.y_label, y)
                .fit(X)
            )

            # vuln1 = 1 - vuln0
            self.decisions_[(p, y)] = np.argmax([vuln0, vuln1])

    def predict(self, x):
        """Predict in/out on an observation."""
        mhat = self.decisions_.get((x[self.p_label], x[self.y_label]))
        return mhat


class DiscriminatingAdv:
    """Discriminating adversary."""

    def __init__(self, obs_space, p_label, y_label, z_label):
        self.obs_space = obs_space
        self.p_label = p_label
        self.y_label = y_label
        self.z_label = z_label

    def fit(self, X):
        self.decisions_ = {}
        for p, y, z_prime in self.obs_space:
            # max_m Pr[m | p, y, z]
            vuln0 = (
                ProbabilityEstimator()
                .of("m", 0)
                .given(self.p_label, p)
                .given(self.y_label, y)
                .given(self.z_label, z_prime)
                .fit(X)
            )
            vuln1 = 1 - vuln0
            self.decisions_[(p, y, z_prime)] = np.argmax([vuln0, vuln1])

    def predict(self, x):
        mhat = self.decisions_.get((x[self.p_label], x[self.y_label], x[self.z_label]))
        return mhat


def regular_vuln_individual(
    learn_df,
    eval_df,
    y_label,
    p_label,
    z_label,
    y_range,
    p_range,
    z=None,
    attacker_clf="counts",
):
    if attacker_clf == "counts":
        obs_space = itertools.product(p_range, y_range)
        adv = Adv(obs_space=obs_space, p_label=p_label, y_label=y_label)
        adv.fit(learn_df)
    else:
        adv = attacker_clf

    if z is not None:
        eval_df = eval_df.query(f"`{z_label}` == {repr(z)}")

    return eval_df.apply(lambda x: adv.predict(x) == x.m, axis=1)


def discriminating_vuln_individual(
    learn_df,
    eval_df,
    y_label,
    p_label,
    z_label,
    z_values,
    y_range,
    p_range,
    z=None,
    attacker_clf="counts",
):
    if attacker_clf == "counts":
        obs_space = itertools.product(p_range, y_range, z_values)
        adv = DiscriminatingAdv(
            obs_space=obs_space, p_label=p_label, y_label=y_label, z_label=z_label
        )
        adv.fit(learn_df)
    else:
        adv = attacker_clf

    if z is not None:
        eval_df = eval_df.query(f"`{z_label}` == {repr(z)}")

    return eval_df.apply(lambda x: adv.predict(x) == x.m, axis=1)


def estimate_vulnerability(
    train_learn_df,
    train_eval_df,
    test_learn_df,
    test_eval_df,
    attacker,
    p_label,
    y_label,
    z_label,
    z_values,
    z_value=None,
    y_range=None,
    p_range=None,
    full_set_eval=False,
    attacker_clf="counts",
):
    if y_range is None:
        y_range = [0, 1]
    if p_range is None:
        p_range = [0, 1]

    learn_df = train_learn_df.assign(m=1).append(test_learn_df.assign(m=0))
    eval_df = train_eval_df.assign(m=1).append(test_eval_df.assign(m=0))

    if full_set_eval:
        learn_df = learn_df.append(eval_df)
        eval_df = learn_df.copy()

    if attacker == "regular":
        vuln = regular_vuln_individual(
            learn_df,
            eval_df,
            y_label=y_label,
            p_label=p_label,
            z_label=z_label,
            y_range=y_range,
            p_range=p_range,
            z=z_value,
            attacker_clf=attacker_clf,
        )

    elif attacker == "discriminating":
        vuln = discriminating_vuln_individual(
            learn_df,
            eval_df,
            y_label=y_label,
            p_label=p_label,
            z_label=z_label,
            z_values=z_values,
            y_range=y_range,
            p_range=p_range,
            z=z_value,
            attacker_clf=attacker_clf,
        )
    else:
        raise NotImplementedError

    return vuln
