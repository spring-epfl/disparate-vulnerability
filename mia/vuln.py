import numpy as np
import pandas as pd
import itertools


def smoothed_len(arr, default=1):
    return len(arr) or default


def estimate_group_disc_vuln(
    data,
    y,
    pred,
    z,
    z_val,
    train_indices,
    y_range=None,
    pred_range=None,
    artificial_overfitting=0.0,
    artificial_bias=0.0,
    sampling_bias=True,
):
    """
    Subgroup vulnerability to a discriminating adversary.

    Args:
        data: Dataframe
        y: True-class column
        pred: Predictions column
        z: Subgroup column
        z_val: Subgroup value
        y_range: Discrete range of true-class values
        pred_range: Discrete range of prediction values
    """
    if y_range is None:
        y_range = [0, 1]
    if pred_range is None:
        pred_range = [0, 1]

    if z is not None:
        group_mask = data[z] == z_val
    else:
        group_mask = np.ones(len(data)).astype(bool)

    mem_mask = np.isin(data.index, train_indices)
    group_size = group_mask.sum()
    group_prop = group_mask.mean()

    exp_terms = []
    var_terms = []
    results = pd.DataFrame()
    for y_val, p_val in itertools.product(y_range, pred_range):
        class_mask = data[y] == y_val
        pred_mask = data[pred] == p_val
        pzym = data[pred_mask & group_mask & class_mask & mem_mask]
        zyp = data[group_mask & class_mask & pred_mask]
        zym = data[group_mask & class_mask & mem_mask]
        ym = data[class_mask & mem_mask]

        # Subgroup overfitting: P[p | z, y, m]
        membership_prob = len(pzym) / smoothed_len(zym) + artificial_overfitting
        # Class/membership probability: P[y, m]
        membership_prob *= len(ym) / smoothed_len(data)
        # Normalizer: P[z, y, p]
        membership_prob /= smoothed_len(zyp) / smoothed_len(data)
        # Subgroup-sampling bias
        if sampling_bias:
            membership_prob *= len(zym) / smoothed_len(ym) + artificial_bias
        else:
            zy = data[group_mask & class_mask]
            membership_prob *= len(zy) / class_mask.sum()

        max_prob = max(membership_prob, 1 - membership_prob)
        # Observation conditional: P[p, y | z]
        obs_prob = len(zyp) / group_size

        exp_terms.append(max_prob * obs_prob)
        var_terms.append(max_prob ** 2 * obs_prob)

    acc = np.sum(exp_terms)
    var = np.sum(var_terms) - acc ** 2
    results = results.append(
        {
            "z": z_val,
            "artificial_overfitting": artificial_overfitting,
            "artificial_bias": artificial_bias,
            "acc": acc,
            "std": np.sqrt(var)
        },
        ignore_index=True
    )
    return results


def estimate_group_regular_vuln(
    data,
    y,
    pred,
    z_val,
    z,
    train_indices,
    y_range=None,
    pred_range=None,
    artificial_overfitting=0.0,
    sampling_bias=True,
):
    """
    Subgroup vulnerability to a regular adversary.

    Args:
        data: Dataframe
        y: True-class column
        pred: Predictions column
        z: Subgroup column
        z_val: Subgroup value
        y_range: Discrete range of true-class values
        pred_range: Discrete range of prediction values
    """
    if y_range is None:
        y_range = [0, 1]
    if pred_range is None:
        pred_range = [0, 1]

    if z is not None:
        group_mask = data[z] == z_val
    else:
        group_mask = np.ones(len(data)).astype(bool)

    mem_mask = np.isin(data.index, train_indices)
    group_size = group_mask.sum()
    group_prop = group_mask.mean()

    exp_terms = []
    var_terms = []
    results = pd.DataFrame()
    for y_val, p_val in itertools.product(y_range, pred_range):
        iter_mask = (data[y] == y_val) & (data[pred] == p_val)
        yp = data[iter_mask]
        myp = data[mem_mask & iter_mask]
        zyp = data[group_mask & iter_mask]

        membership_prob = len(myp) / smoothed_len(yp)
        max_prob = max(membership_prob, 1 - membership_prob)
        obs_prob = len(zyp) / group_size

        exp_terms.append(max_prob * obs_prob)
        var_terms.append(max_prob ** 2 * obs_prob)


    acc = np.sum(exp_terms)
    var = np.sum(var_terms) - acc ** 2
    results = results.append(
        {
            "z": z_val,
            "artificial_overfitting": artificial_overfitting,
            "acc": acc,
            "std": np.sqrt(var)
        },
        ignore_index=True
    )

    return results
