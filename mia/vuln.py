"""
Vulnerability estimation code.
"""

import itertools
import numpy as np
import pandas as pd

from sklearn.neural_network import MLPClassifier


class GenericAttacker:
    def __init__(self, attacker_clf, p_label, y_label, z_label, attacker_type):
        self.clf = attacker_clf
        self.p_label = p_label
        self.y_label = y_label
        self.z_label = z_label
        self.encoder = {}

        if attacker_type == "Discriminating" or attacker_type == "Regular":
            self.type = attacker_type
        else:
            raise NotImplementedError(
                "Attacker type can be either `Discriminating` or `Regular`"
            )

    def fit(self, learn_df):
        subgroups = learn_df[self.z_label].unique().tolist()
        self.encoder = dict(zip(subgroups, range(len(subgroups))))
        learn_df = learn_df.copy()
        learn_df[self.z_label] = learn_df[self.z_label].apply(lambda x: self.encoder[x])

        if self.type == "Discriminating":
            self.clf.fit(
                learn_df[[self.z_label, self.y_label, self.p_label]].values,
                learn_df["m"],
            )
        else:
            self.clf.fit(learn_df[[self.y_label, self.p_label]].values, learn_df["m"])

    def predict(self, record):
        record[self.z_label] = self.encoder[record[self.z_label]]

        if self.type == "Discriminating":
            return self.clf.predict(
                record[[self.z_label, self.y_label, self.p_label]].values.reshape(1, -1)
            )[0]
        else:
            return self.clf.predict(
                record[[self.y_label, self.p_label]].values.reshape(1, -1)
            )[0]

    def score(self, eval_df):
        return eval_df.apply(axis=1, func=lambda x: self.predict(x) == x.m).mean()


class ProbabilityEstimator:
    """
    Probability operator builder.

    >>> X = pd.DataFrame({"a": [1, 1, 2], "b": [3, 6, 3]})
    >>> prob_est = ProbabilityEstimator()
    >>> prob_est.of("a", 1).given("b", 4).fit(X)
    0.0
    >>> prob_est.of("a", 1).given("b", 3).fit(X)
    0.5
    >>> prob_est.of("a", 1).given("b", 6).fit(X)
    1.0
    """

    def __init__(self, of=None, given=None):
        self.lhs_exprs = of or {}
        self.rhs_exprs = given or {}

    def clear(self):
        self.lhs_exprs = {}
        self.rhs_exprs = {}

    @staticmethod
    def _build_query(**kwargs):
        queries = [f"`{k}` == {repr(v)}" for (k, v) in kwargs.items()]
        return " and ".join(queries)

    def __repr__(self):
        return f"ProbabilityEstimator(of={self.lhs_exprs}, given={self.rhs_exprs})"

    def of(self, label, value):
        self.lhs_exprs[label] = value
        return self

    def given(self, label, value):
        self.rhs_exprs[label] = value
        return self

    def fit(self, X):
        count_df = X.query(self._build_query(**self.lhs_exprs, **self.rhs_exprs))
        count = len(count_df)
        if self.rhs_exprs:
            norm_df = X.query(self._build_query(**self.rhs_exprs))
            norm = len(norm_df)
        else:
            norm = len(X)
        self.clear()

        if norm == 0.0:
            return 0.0
        return count / norm


class CountAdv:
    """Regular counting adversary."""

    def __init__(self, obs_space, p_label, y_label):
        self.obs_space = obs_space
        self.p_label = p_label
        self.y_label = y_label

    def fit(self, X):
        self.decisions_ = {}
        for p, y in self.obs_space:
            # max_m Pr[m, p, y] - more numerically stable than the conditional.
            vuln0 = (
                ProbabilityEstimator()
                .of("m", 0)
                .of(self.p_label, p)
                .of(self.y_label, y)
                .fit(X)
            )
            vuln1 = (
                ProbabilityEstimator()
                .of("m", 1)
                .of(self.p_label, p)
                .of(self.y_label, y)
                .fit(X)
            )

            # vuln1 = 1 - vuln0
            self.decisions_[(p, y)] = np.argmax([vuln0, vuln1])

    def predict(self, x):
        """Predict in/out on an observation."""
        mhat = self.decisions_.get((x[self.p_label], x[self.y_label]))
        return mhat


class CountDiscriminatingAdv:
    """Discriminating counting adversary."""

    def __init__(self, obs_space, p_label, y_label, z_label):
        self.obs_space = obs_space
        self.p_label = p_label
        self.y_label = y_label
        self.z_label = z_label

    def fit(self, X):
        self.decisions_ = {}
        for p, y, z_prime in self.obs_space:
            # max_m Pr[m | p, y, z]
            vuln0 = (
                ProbabilityEstimator()
                .of("m", 0)
                .given(self.p_label, p)
                .given(self.y_label, y)
                .given(self.z_label, z_prime)
                .fit(X)
            )
            vuln1 = 1 - vuln0
            self.decisions_[(p, y, z_prime)] = np.argmax([vuln0, vuln1])

    def predict(self, x):
        mhat = self.decisions_.get((x[self.p_label], x[self.y_label], x[self.z_label]))
        return mhat


def _find_best_threshold(a, b, balance=True):
    best_threshold = 0
    best_acc = 0
    for c in itertools.chain(a, b):
        acc = 0.5 * (a < c).mean() + 0.5 * (a >= c).mean()
        if acc > best_acc:
            best_threshold = c

    return best_threshold, False


def _log_losses(y_true, y_pred, eps=1e-15):
    y_pred = np.clip(y_pred, eps, 1 - eps)
    one_minus_y_pred = np.clip(1 - y_pred, eps, 1 - eps)
    return -(y_true * np.log(y_pred) + (1 - y_true) * np.log(one_minus_y_pred))


class ThresholdAdv:
    """Regular threshold adversary."""

    def __init__(self, p_label, y_label):
        self.p_label = p_label
        self.y_label = y_label

    def fit(self, X):
        ins = X.query(f"m == 1")
        outs = X.query(f"m == 0")
        preds_train = ins[self.p_label]
        preds_test = outs[self.p_label]
        y_train = ins[self.y_label]
        y_test = outs[self.y_label]
        losses_train = _log_losses(y_train, preds_train)
        losses_test = _log_losses(y_test, preds_test)

        self.threshold_, self.sign_ = _find_best_threshold(losses_train, losses_test)

    def predict(self, x):
        p_value = x[self.p_label]
        y_value = x[self.y_label]
        loss_value = _log_losses(y_value, p_value)
        if not self.sign_:
            return loss_value < self.threshold_
        else:
            return loss_value >= self.threshold_


class ThresholdDiscriminatingAdv:
    """Discriminating threshold adversary."""

    def __init__(self, p_label, y_label, z_label):
        self.p_label = p_label
        self.z_label = z_label
        self.y_label = y_label

    def fit(self, X):
        subgroups = X[self.z_label].unique().tolist()
        self.threshold_by_subgroup_ = {}
        for z_value in subgroups:
            ins = X.query(f"m == 1 and `{self.z_label}` == '{z_value}'")
            outs = X.query(f"m == 0 and `{self.z_label}` == '{z_value}'")
            preds_train = ins[self.p_label]
            preds_test = outs[self.p_label]
            y_train = ins[self.y_label]
            y_test = outs[self.y_label]
            losses_train = _log_losses(y_train, preds_train)
            losses_test = _log_losses(y_test, preds_test)

            threshold, sign = _find_best_threshold(losses_train, losses_test)
            self.threshold_by_subgroup_[z_value] = threshold, sign

    def predict(self, x):
        p_value = x[self.p_label]
        y_value = x[self.y_label]
        z_value = x[self.z_label]
        loss = _log_losses(y_value, p_value)
        threshold, sign = self.threshold_by_subgroup_[z_value]
        if not sign:
            return loss < threshold
        else:
            return loss >= threshold


def regular_vuln_individual(
    learn_df,
    eval_df,
    y_label,
    p_label,
    z_label,
    y_range,
    p_range,
    z=None,
    attacker_clf="counts",
):
    if attacker_clf == "counts":
        obs_space = itertools.product(p_range, y_range)
        adv = CountAdv(obs_space=obs_space, p_label=p_label, y_label=y_label)
        adv.fit(learn_df)
    elif attacker_clf == "loss_threshold":
        adv = ThresholdAdv(p_label=p_label, y_label=y_label)
        adv.fit(learn_df)
    elif attacker_clf == "nn32":
        adv = GenericAttacker(
            attacker_clf=MLPClassifier(hidden_layer_sizes=[32]),
            p_label=p_label,
            y_label=y_label,
            z_label=z_label,
            attacker_type="Regular",
        )
        adv.fit(learn_df)
    else:
        adv = attacker_clf

    if z is not None:
        eval_df = eval_df.query(f"`{z_label}` == {repr(z)}")

    return eval_df.apply(lambda x: adv.predict(x) == x.m, axis=1)


def discriminating_vuln_individual(
    learn_df,
    eval_df,
    y_label,
    p_label,
    z_label,
    z_values,
    y_range,
    p_range,
    z=None,
    attacker_clf="counts",
):
    if attacker_clf == "counts":
        obs_space = itertools.product(p_range, y_range, z_values)
        adv = CountDiscriminatingAdv(
            obs_space=obs_space, p_label=p_label, y_label=y_label, z_label=z_label
        )
        adv.fit(learn_df)
    elif attacker_clf == "loss_threshold":
        adv = ThresholdDiscriminatingAdv(
            p_label=p_label, z_label=z_label, y_label=y_label
        )
        adv.fit(learn_df)
    elif attacker_clf == "nn32":
        adv = GenericAttacker(
            attacker_clf=MLPClassifier(hidden_layer_sizes=[32]),
            p_label=p_label,
            y_label=y_label,
            z_label=z_label,
            attacker_type="Discriminating",
        )
        adv.fit(learn_df)
    else:
        adv = attacker_clf

    if z is not None:
        eval_df = eval_df.query(f"`{z_label}` == {repr(z)}")

    return eval_df.apply(lambda x: adv.predict(x) == x.m, axis=1)


def estimate_vulnerability(
    train_learn_df,
    train_eval_df,
    test_learn_df,
    test_eval_df,
    attacker,
    p_label,
    y_label,
    z_label,
    z_values,
    z_value=None,
    y_range=None,
    p_range=None,
    full_set_eval=False,
    attacker_clf="counts",
):
    if y_range is None:
        y_range = [0, 1]
    if p_range is None:
        p_range = [0, 1]

    learn_df = train_learn_df.assign(m=1).append(test_learn_df.assign(m=0))
    eval_df = train_eval_df.assign(m=1).append(test_eval_df.assign(m=0))

    if full_set_eval:
        learn_df = learn_df.append(eval_df)
        eval_df = learn_df.copy()

    if attacker == "regular":
        vuln = regular_vuln_individual(
            learn_df,
            eval_df,
            y_label=y_label,
            p_label=p_label,
            z_label=z_label,
            y_range=y_range,
            p_range=p_range,
            z=z_value,
            attacker_clf=attacker_clf,
        )

    elif attacker == "discriminating":
        vuln = discriminating_vuln_individual(
            learn_df,
            eval_df,
            y_label=y_label,
            p_label=p_label,
            z_label=z_label,
            z_values=z_values,
            y_range=y_range,
            p_range=p_range,
            z=z_value,
            attacker_clf=attacker_clf,
        )
    else:
        raise NotImplementedError

    return vuln
