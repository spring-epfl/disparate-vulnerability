import pytest
import pandas as pd
import numpy as np
import itertools

from sklearn.model_selection import train_test_split

import utils

from conftest import MockModel


def _ensure_numpy(data):
    if isinstance(data, pd.DataFrame) or isinstance(data, pd.Series):
        return data.values
    else:
        return data


@pytest.mark.parametrize(
    "data",
    [pytest.lazy_fixture("np_data"), pytest.lazy_fixture("pd_data")],
    ids=["numpy", "pandas"],
)
def test_subsample_data_size(data):
    X, y = data
    subsample_size = 5
    sample_X, sample_y, sample_X_rest, sample_y_rest = utils.subsample_data(
        X, y, size=subsample_size, seed=1
    )
    assert len(sample_X) == len(sample_y) == subsample_size
    assert len(sample_X_rest) == len(sample_y_rest) == len(X) - subsample_size


@pytest.mark.parametrize(
    "data",
    [pytest.lazy_fixture("np_data"), pytest.lazy_fixture("pd_data")],
    ids=["numpy", "pandas"],
)
def test_subsample_data_deterministic(data):
    X, y = data
    subsample_size = 20
    data1 = list(utils.subsample_data(X, y, size=subsample_size, seed=1))
    data2 = list(utils.subsample_data(X, y, size=subsample_size, seed=2))
    data3 = list(utils.subsample_data(X, y, size=subsample_size, seed=2))

    for elem1, elem2, elem3 in zip(data1, data2, data3):
        assert np.any(_ensure_numpy(elem1) != _ensure_numpy(elem2))
        assert np.all(_ensure_numpy(elem2) == _ensure_numpy(elem3))


@pytest.mark.parametrize(
    "data",
    [pytest.lazy_fixture("np_data"), pytest.lazy_fixture("pd_data")],
    ids=["numpy", "pandas"],
)
@pytest.mark.parametrize("label", [0, 1])
@pytest.mark.parametrize("num_points", [1, None])
def test_make_attack_part(data, label, num_points):
    X, y = data
    if num_points is not None:
        X = X[: num_points + 1]
        y = y[: num_points + 1]
    num_classes = utils.get_num_classes(y)
    model = MockModel(num_classes)

    attack_X_part, attack_y_part = utils.make_attack_part(model, X, y, label=label)
    y_true, y_pred = attack_X_part

    assert y_true.shape == y_pred.shape
    assert y_pred.shape[0] == attack_y_part.shape[0]
    assert np.all(attack_y_part == label)

    if num_classes == 2:
        assert len(y_true.shape) == 1
        assert len(y_pred.shape) == 1
    else:
        assert y_true.shape[1] == num_classes
        assert y_pred.shape[1] == num_classes


@pytest.mark.parametrize(
    "data",
    [pytest.lazy_fixture("np_data"), pytest.lazy_fixture("pd_data")],
    ids=["numpy", "pandas"],
)
def test_make_attack_dataset(data):
    X, y = data
    num_classes = utils.get_num_classes(y)
    model = MockModel(num_classes)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)

    attacker_X, attacker_y = utils.make_attack_data(
        model, X_train, X_test, y_train, y_test
    )
    y_true, y_pred = attacker_X

    assert len(y_true) == len(y_pred)
    assert len(y_pred) == len(attacker_y)

    assert len(y_true) == len(X_train) + len(X_test)

    assert np.all(attacker_y[: len(X_train)] == 1.)
    assert np.all(attacker_y[len(X_train) :] == 0.)


@pytest.mark.parametrize(
    "data",
    [pytest.lazy_fixture("np_data"), pytest.lazy_fixture("pd_data")],
    ids=["numpy", "pandas"],
)
def test_run_mia(data):
    X, y = data
    num_classes = utils.get_num_classes(y)
    target_model = MockModel(num_classes)
    attacker_model = MockModel(2)

    results = utils.run_mia(target_model, attacker_model, X, y)
    assert list(results.keys()) == [
        "attack_pred",
        "target_y_true",
        "target_y_pred",
        "target_y_proba",
    ]
    assert len(results["attack_pred"]) == len(X)


@pytest.mark.parametrize("mode", ["prob", "avg"])
def test_get_mia_global_loss(mode):
    ins_y_pred = np.array([[0.1, 0.1, 0.8], [0.1, 0.1, 0.8], [0.4, 0.2, 0.4]])

    outs_y_pred = np.array([[0.3, 0.5, 0.2], [0.2, 0.6, 0.2], [0.3, 0.2, 0.5]])

    loss = utils.get_mia_global_loss(ins_y_pred, outs_y_pred, mode=mode, bins=2)

    if mode == "prob":
        # Returns the ratio of max histogram values between in and out.
        assert loss == pytest.approx([np.log(1), 1.09861229, np.log(2)])

    elif mode == "avg":
        assert loss == pytest.approx(
            [
                np.log((0.8 / 3) / (0.6 / 3)),
                np.log((1.3 / 3) / (0.4 / 3)),
                np.log((2. / 3) / (0.9 / 3)),
            ]
        )


@pytest.mark.parametrize("mode", ["avg"])
def test_get_mia_loss_by_class(mode):
    ins_y_pred = np.array([[0.1, 0.1, 0.8], [0.1, 0.1, 0.8], [0.4, 0.2, 0.4]])
    outs_y_pred = np.array([[0.3, 0.5, 0.2], [0.2, 0.6, 0.2], [0.3, 0.2, 0.5]])
    ins_y_true = np.array([[0, 1, 0], [0, 1, 0], [1, 0, 0]])
    outs_y_true = np.array([[0, 0, 1], [0, 1, 0], [0, 1, 0]])

    loss = utils.get_mia_loss_by_class(
        ins_y_true, outs_y_true, ins_y_pred, outs_y_pred, mode=mode, bins=2
    )

    if mode == "avg":
        assert loss[[0, 1, 2], [0, 1, 2]] == pytest.approx(
            [np.log(1), np.log(0.4 / 0.1), np.log(1)]
        )
