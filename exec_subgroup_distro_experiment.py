from experiment import *
# from tqdm.notebook import tqdm

from functools import partial
from tqdm import tqdm as std_tqdm
tqdm = partial(std_tqdm, dynamic_ncols=True)

import pandas as pd
import numpy as np
import tensorflow as tf
from utkface import prepare_utkface


def subsample(meta_data, z_label, subgroups, random_state=None):
    _data = meta_data.loc[meta_data[z_label].isin(subgroups)]
    counts = _data.race.value_counts()
    smallest_subgroup_size = counts.min()
    state = np.random.RandomState(random_state) if random_state is not None else np.random.RandomState()

    train_idx_dict = {}
    test_idx_dict = {}
    for group in subgroups:
        group_idx = state.choice(
            _data.query(f"{z_label} == '{group}'").index, size=int(smallest_subgroup_size)).tolist()

        train_idx_dict[group] = group_idx[:int(smallest_subgroup_size / 2)]
        test_idx_dict[group] = group_idx[int(smallest_subgroup_size / 2):]

    return train_idx_dict, test_idx_dict


def prepare_model():
    clf = tf.keras.Sequential()

    clf.add(
        tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(32, 32, 3)))
    clf.add(tf.keras.layers.MaxPooling2D(pool_size=2))
    clf.add(tf.keras.layers.Dropout(0.3))

    clf.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))
    clf.add(tf.keras.layers.MaxPooling2D(pool_size=2))
    clf.add(tf.keras.layers.Dropout(0.3))

    clf.add(tf.keras.layers.Flatten())
    clf.add(tf.keras.layers.Dense(256, activation='relu'))
    clf.add(tf.keras.layers.Dropout(0.5))
    clf.add(tf.keras.layers.Dense(6, activation='softmax'))

    return clf


def experiment_setting(debug_):
    validation_ratio_ = 0.2
    if not debug_:
        train_sizes_ = [200, 300, 400, 500, 600, 700, 800, 900, 1000, 1200, 1500, 1717]
        reps_ = 35
        num_batches_ = 35
    else:
        train_sizes_ = [200]
        reps_ = 1
        num_batches_ = 1

    return validation_ratio_, train_sizes_, reps_, num_batches_


if __name__ == "__main__":

    # parse input
    experiment_label = sys.argv[1]
    try:
        debug = sys.argv[2] == "True"
    except IndexError:
        debug = False

    print("Debug: ", debug)

    # load data
    X, y, meta_data = prepare_utkface("data/UTKFace/", "data/UTKFace.npz")

    # subsample data
    subgroups = meta_data.race.unique()
    train_idx_dict, test_idx_dict = subsample(meta_data, "race", list(filter(lambda x: x != "Other", subgroups)), 1)

    # prepare keras classifier
    clf = prepare_model()
    checkpoint_path = "models/subgroup_distro.h5"
    fit_args = dict(batch_size=64, epochs=30)

    # set experiment constants
    filtered_subgroups = list(filter(lambda x: x != "Other", subgroups))
    validation_ratio, train_sizes, reps, num_batches = experiment_setting(debug)
    results_list = []

    # Main Loop
    rep_d = tqdm(range(reps))
    for rep_no in rep_d:
        rep_d.set_description(f"Rep {rep_no}")

        train_idx_dict, test_idx_dict = subsample(meta_data, "race",
                                                  list(filter(lambda x: x != "Other", subgroups)), rep_no)

        tsize_d = tqdm(train_sizes)
        for tsize in tsize_d:
            tsize_d.set_description(f"tsize {tsize}")

            train_idx = []
            valid_idx = []
            test_idx = []

            # adding up all subgroup indices
            for group in filter(lambda x: x != "Other", subgroups):
                train_idx += train_idx_dict[group][:int(tsize * (1 - validation_ratio))]
                valid_idx += train_idx_dict[group][int(tsize * (1 - validation_ratio)):int(tsize)]
                test_idx += test_idx_dict[group][:tsize]

                # test to make sure train (+valid): test is 50:50
                assert (
                        len(train_idx_dict[group][:int(tsize * (1 - validation_ratio))]) +
                        len(train_idx_dict[group][int(tsize * (1 - validation_ratio)):int(tsize)]) == len(
                    test_idx_dict[group][:tsize]))

            try:
                # running the experiment
                results = run_generic_keras_experiment(
                    binary_data=X,
                    meta_data=meta_data,
                    y_label='y',
                    z_label="race",
                    z_values=list(filter(lambda x: x != "Other", subgroups)),
                    clf=clf,
                    validation=None,
                    train_valid_test_idx=(train_idx, valid_idx, test_idx),
                    clf_name="ff_keras",
                    fit_args=fit_args,
                    num_batches=num_batches,
                    synthetic_bins=10,
                    diagnose_calibration=False,
                    balanced=False,
                    y_range=[0, 1, 2, 3, 4, 5],
                    random_state=None,
                    save_best_only=True,
                    checkpoint=checkpoint_path,
                    compile_parameters=None,
                    output_extended_subgroup_metrics=True)
            except:
                results = pd.DataFrame([None])

            # adding metadata
            results = results.assign(tsize=tsize, rep_no=rep_no)

            results_list.append(results)

        # save progress each rep
        pd.to_pickle(results_list, f"results/subgroup_distro_{experiment_label}_temp.pkl")

    pd.to_pickle(results_list, f"results/subgroup_distro_{experiment_label}.pkl")
