{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SHUFFLES = 35\n",
    "FIGWIDTH = 8\n",
    "ALPHA = 0.005\n",
    "LOAD_FROM_PICKLE = True\n",
    "PICKLE = \"results/compas_race_100_reps.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from experiment import run_generic_experiment\n",
    "from model_zoo import model_zoo, renaming_dict, fit_args\n",
    "from utils import metrics_dict_to_dataframe\n",
    "from utils import convert_max_disparity_to_wide, get_latex_table\n",
    "from disparity import compute_emm, compute_anovas, max_disparity\n",
    "from plotting import plot_stat_heatmaps, plot_vuln_dists\n",
    "from loaders.compas import prepare_compas\n",
    "\n",
    "import plot_params\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/compas/compas-scores-two-years.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_undummified = prepare_compas(\"data/compas/compas-scores-two-years.csv\", dummified=False, drop_first=True,\n",
    "                                  drop_duplicates=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_undummified.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 is the maximum number of ones in a COMPAS feature vector after one-hot encoding.\n",
    "model_zoo[\"lr_dp_eps1\"].named_steps.clf.data_norm = np.sqrt(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renaming_dict = dict(**renaming_dict,\n",
    "    **{\n",
    "        \"regular\": \"Regular\",\n",
    "        \"discriminating\": \"Discriminating\",\n",
    "        \"Native American\": \"Native\\nAmerican\",\n",
    "        \"African-American\": \"African-\\nAmerican\",\n",
    "    }\n",
    ")\n",
    "\n",
    "model_order = [renaming_dict[model] for model in [\n",
    "    \"lr\", \"lr_eo\", \"nn_6\", \"nn_100\", \"nn_500\"\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgroups = ['African-American', 'Caucasian', 'Hispanic', 'Other', 'Asian', 'Native American']\n",
    "subgroups_short = [\"AA\", \"CA\", \"HI\", \"OT\", \"AS\", \"NA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_FROM_PICKLE:\n",
    "    metrics_race = pd.read_pickle(PICKLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LOAD_FROM_PICKLE:\n",
    "    metrics_race = {}\n",
    "    for model_name, clf in model_zoo.items():\n",
    "        print(model_name)\n",
    "        metrics_race[model_name] = run_generic_experiment(\n",
    "            data=data_undummified,\n",
    "            y_label=\"Ground Truth\",\n",
    "            z_label=\"Race\",\n",
    "            z_values=subgroups,\n",
    "            synthetic_bins=10,\n",
    "            parallelize=True,\n",
    "            fit_args=fit_args.get(model_name, {}),\n",
    "            num_batches=NUM_SHUFFLES,\n",
    "            clf=clf,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LOAD_FROM_PICKLE:\n",
    "    pd.to_pickle(metrics_race, PICKLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in metrics_race.items():\n",
    "    metrics_race[k] = metrics_race[k].query(f\"batch_no < {NUM_SHUFFLES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, len(metrics_race), figsize=(6 * FIGWIDTH, FIGWIDTH), sharey=False, sharex=True,\n",
    "                         gridspec_kw=dict(height_ratios=[5, 1]))\n",
    "for ax_id, (model_name, metrics) in enumerate(metrics_race.items()):\n",
    "    plot_df = metrics.query(\"vuln_method=='counts' and batch_no == 0\").copy()\n",
    "    plot_df.loc[:, \"vuln\"] = plot_df.vuln.astype(np.float32)\n",
    "    g = sns.pointplot(data=plot_df.query(\"subgroup != 'Overall'\"), x=\"vuln\", hue=\"attacker\", y=\"subgroup\",\n",
    "                      ax=axes[0, ax_id], join=False, dodge=True)\n",
    "    h = sns.pointplot(data=plot_df.query(\"subgroup == 'Overall'\"), x=\"vuln\", y=\"attacker\", hue=\"attacker\",\n",
    "                      ax=axes[1, ax_id], join=False, dodge=True)\n",
    "    \n",
    "    axes[0, ax_id].set_xlabel(\"\")\n",
    "    axes[1, ax_id].set_xlabel(\"Vulnerability\")\n",
    "    if ax_id > 0: \n",
    "        g.set_yticks([], [])\n",
    "        h.set_yticks([], [])\n",
    "        \n",
    "#     axes[0, ax_id].set_xscale(\"log\")\n",
    "#     axes[1, ax_id].set_xscale(\"log\")\n",
    "        \n",
    "    g.set_ylabel(\"Subgroups\" if ax_id == 0 else \"\")\n",
    "    h.set_ylabel(\"Overall\" if ax_id == 0 else \"\")\n",
    "    g.set_title(renaming_dict[model_name])\n",
    "    h.get_legend().remove()\n",
    "    if ax_id == len(metrics_race) - 1:\n",
    "        g.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    else:\n",
    "        g.get_legend().remove()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacks to put group sizes on the plot legends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = dict(zip(subgroups, subgroups_short))\n",
    "subgroup_sizes = {}\n",
    "subgroup_renaming_dict = {}\n",
    "for subgroup in subgroups:\n",
    "    subgroup_sizes[subgroup] = int(\n",
    "        metrics_race[\"lr\"].query(f\"subgroup == '{subgroup}'\").support.mean()\n",
    "    )\n",
    "total = sum(subgroup_sizes.values())\n",
    "subgroups = list(sorted(subgroups, key=lambda k: -subgroup_sizes[k]))\n",
    "\n",
    "for subgroup in subgroups + [\"Overall\"]:\n",
    "    if subgroup == \"Overall\":\n",
    "        size = total\n",
    "    else:\n",
    "        size = subgroup_sizes[subgroup]\n",
    "    subgroup_renaming_dict[subgroup] = \"{}: {}\\n({}\\\\%)\".format(\n",
    "        subgroup, size, round(size / total * 100)\n",
    "    )\n",
    "\n",
    "subgroup_annotated_ordered = {s: subgroup_renaming_dict[s] for s in (subgroups)}\n",
    "renaming_dict = dict(renaming_dict, **subgroup_annotated_ordered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paper plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlim = [42, 65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (2*FIGWIDTH, FIGWIDTH)\n",
    "options = dict(pad_inches=1)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=figsize, sharey=False, sharex=True,\n",
    "                         gridspec_kw=dict(height_ratios=[4, 1], hspace=0.))\n",
    "plot_vuln_dists(metrics_race,\n",
    "                models=[\"lr\", \"nn_6\"],\n",
    "                axes=axes,\n",
    "                renaming_dict=renaming_dict,\n",
    "                vuln_method=\"counts\",\n",
    "                ignore_subgroups=[\"Native American\", \"Asian\"],\n",
    "                percentages=True,\n",
    "                legend=False)\n",
    "\n",
    "for ax in itertools.chain(axes[0], axes[1]):\n",
    "    ax.set_xlim(*xlim)\n",
    "    ax.set_facecolor('none')\n",
    "    ax.set_alpha(0)\n",
    "    \n",
    "fig.set_tight_layout(tight=True)\n",
    "fig.patch.set_facecolor(\"white\")\n",
    "fig.patch.set_alpha(0.4)\n",
    "fig.savefig(\"images/compas_race_dist_plots_normal.pdf\", **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (2*FIGWIDTH, FIGWIDTH)\n",
    "options = dict(pad_inches=1)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=figsize, sharey=False, sharex=True,\n",
    "                         gridspec_kw=dict(height_ratios=[4, 1], hspace=0.))\n",
    "plot_vuln_dists(metrics_race,\n",
    "                models=[\"nn_100\", \"nn_500\"],\n",
    "                axes=axes,\n",
    "                renaming_dict=renaming_dict,\n",
    "                vuln_method=\"counts\",\n",
    "                ignore_subgroups=[\"Native American\", \"Asian\"],\n",
    "                percentages=True,\n",
    "                legend=False)\n",
    "\n",
    "for ax in itertools.chain(axes[0], axes[1]):\n",
    "    ax.set_xlim(*xlim)\n",
    "    ax.set_facecolor('none')\n",
    "    ax.set_alpha(0)\n",
    "    \n",
    "fig.set_tight_layout(tight=True)\n",
    "fig.patch.set_facecolor(\"white\")\n",
    "fig.patch.set_alpha(0.4)\n",
    "fig.savefig(\"images/compas_race_dist_plots_overfitting.pdf\", **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (FIGWIDTH * 1.28, FIGWIDTH)\n",
    "options = dict(pad_inches=1)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=figsize, sharey=False, sharex=True,\n",
    "                         gridspec_kw=dict(height_ratios=[4, 1], hspace=0.))\n",
    "plot_vuln_dists(metrics_race,\n",
    "                models=[\"lr_eo\"],\n",
    "                axes=np.expand_dims(axes, 1),\n",
    "                renaming_dict=renaming_dict,\n",
    "                vuln_method=\"counts\",\n",
    "                ignore_subgroups=[\"Native American\", \"Asian\"],\n",
    "                percentages=True,\n",
    "                legend=False)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlim(*xlim)\n",
    "    ax.set_facecolor('none')\n",
    "    ax.set_alpha(0)\n",
    "    \n",
    "fig.set_tight_layout(tight=True)\n",
    "fig.patch.set_facecolor(\"white\")\n",
    "fig.patch.set_alpha(0.4)\n",
    "# fig.savefig(\"images/compas_race_dist_plots_eo.pdf\", **options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_anovas_by_model = compute_anovas(\n",
    "    metrics_race,\n",
    "    attacker=\"regular\",\n",
    ")\n",
    "\n",
    "discriminating_anovas_by_model = compute_anovas(\n",
    "    metrics_race,\n",
    "    attacker=\"discriminating\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there any disparate vulnerability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, (p_value, _) in regular_anovas_by_model.items():\n",
    "    print(f\"{model}: {p_value:.4f} (regular)\")\n",
    "    \n",
    "for model, (p_value, _) in discriminating_anovas_by_model.items():\n",
    "    print(f\"{model}: {p_value:.4f} (discriminating)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow-up pairwise comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_p_matrices_by_model = compute_emm(\n",
    "    regular_anovas_by_model,\n",
    "    subgroups=subgroups,\n",
    ")\n",
    "\n",
    "discriminating_p_matrices_by_model = compute_emm(\n",
    "    discriminating_anovas_by_model,\n",
    "    subgroups=subgroups,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = sns.color_palette([\"#ECF0F1\", \"#E74C3C\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(2*FIGWIDTH, FIGWIDTH), sharex=True, sharey=True)\n",
    "for ax_id, model_name in enumerate([\"lr\", \"nn_6\"]):\n",
    "    ax = axes[ax_id]\n",
    "    ax.set_title(renaming_dict[model_name])\n",
    "    metrics = metrics_race[model_name].replace(group_names)\n",
    "    plot_stat_heatmaps(\n",
    "        metrics,\n",
    "        [t.rename(index=group_names, columns=group_names) for t in regular_p_matrices_by_model[model_name]],\n",
    "        subgroups=subgroups_short,\n",
    "        alpha=ALPHA,\n",
    "        ax=ax,\n",
    "        xticklabels=True,\n",
    "        cmap=cmap\n",
    "    )\n",
    "fig.set_tight_layout(tight=True)\n",
    "plt.show()\n",
    "fig.savefig(\"images/compas_p_plots_normal_regular.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(2*FIGWIDTH, FIGWIDTH), sharex=True, sharey=True)\n",
    "for ax_id, model_name in enumerate([\"lr\", \"nn_6\"]):\n",
    "    ax = axes[ax_id]\n",
    "    ax.set_title(renaming_dict[model_name])\n",
    "    metrics = metrics_race[model_name].replace(dict(zip(subgroups, subgroups_short)))\n",
    "    plot_stat_heatmaps(\n",
    "        metrics,\n",
    "        [t.rename(index=group_names, columns=group_names)\n",
    "         for t in discriminating_p_matrices_by_model[model_name]],\n",
    "        subgroups=subgroups_short,\n",
    "        alpha=ALPHA,\n",
    "        ax=ax,\n",
    "        xticklabels=True,\n",
    "        cmap=cmap\n",
    "    )\n",
    "fig.set_tight_layout(tight=True)\n",
    "plt.show()\n",
    "fig.savefig(\"images/compas_p_plots_normal_discriminating.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(2*FIGWIDTH, FIGWIDTH), sharex=True, sharey=True)\n",
    "for ax_id, model_name in enumerate([\"nn_100\", \"nn_500\"]):\n",
    "    ax = axes[ax_id]\n",
    "    ax.set_title(renaming_dict[model_name])\n",
    "    metrics = metrics_race[model_name].replace(dict(zip(subgroups, subgroups_short)))\n",
    "    plot_stat_heatmaps(\n",
    "        metrics,\n",
    "        [t.rename(index=group_names, columns=group_names) for t in regular_p_matrices_by_model[model_name]],\n",
    "        subgroups=subgroups_short,\n",
    "        alpha=ALPHA,\n",
    "        ax=ax,\n",
    "        xticklabels=True,\n",
    "        cmap=cmap,\n",
    "    )\n",
    "fig.set_tight_layout(tight=True)\n",
    "plt.show()\n",
    "fig.savefig(\"images/compas_p_plots_overfit_regular.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(2*FIGWIDTH, FIGWIDTH), sharex=True, sharey=True)\n",
    "for ax_id, model_name in enumerate([\"nn_100\", \"nn_500\"]):\n",
    "    ax = axes[ax_id]\n",
    "    ax.set_title(renaming_dict[model_name])\n",
    "    metrics = metrics_race[model_name].replace(dict(zip(subgroups, subgroups_short)))\n",
    "    plot_stat_heatmaps(\n",
    "        metrics,\n",
    "        [t.rename(index=group_names, columns=group_names) for t in discriminating_p_matrices_by_model[model_name]],\n",
    "        subgroups=subgroups_short,\n",
    "        alpha=ALPHA,\n",
    "        ax=ax,\n",
    "        xticklabels=True,\n",
    "        cmap=cmap\n",
    "    )\n",
    "fig.set_tight_layout(tight=True)\n",
    "plt.show()\n",
    "fig.savefig(\"images/compas_p_plots_overfit_discriminating.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(FIGWIDTH, FIGWIDTH), sharex=True, sharey=True)\n",
    "model_name = \"lr_eo\"\n",
    "ax.set_title(renaming_dict[model_name])\n",
    "metrics = metrics_race[model_name].replace(dict(zip(subgroups, subgroups_short)))\n",
    "plot_stat_heatmaps(\n",
    "    metrics,\n",
    "    [t.rename(index=group_names, columns=group_names) for t in regular_p_matrices_by_model[model_name]],\n",
    "    subgroups=subgroups_short,\n",
    "    alpha=ALPHA,\n",
    "    ax=ax,\n",
    "    xticklabels=True,\n",
    "    cmap=cmap,\n",
    ")\n",
    "fig.set_tight_layout(tight=True)\n",
    "plt.show()\n",
    "fig.savefig(\"images/compas_p_plots_eo_regular.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(FIGWIDTH, FIGWIDTH), sharex=True, sharey=True)\n",
    "model_name = \"lr_eo\"\n",
    "ax.set_title(renaming_dict[model_name])\n",
    "metrics = metrics_race[model_name].replace(dict(zip(subgroups, subgroups_short)))\n",
    "plot_stat_heatmaps(\n",
    "    metrics,\n",
    "    [t.rename(index=group_names, columns=group_names) for t in discriminating_p_matrices_by_model[model_name]],\n",
    "    subgroups=subgroups_short,\n",
    "    alpha=ALPHA,\n",
    "    ax=ax,\n",
    "    xticklabels=True,\n",
    "    cmap=cmap,\n",
    ")\n",
    "fig.set_tight_layout(tight=True)\n",
    "plt.show()\n",
    "fig.savefig(\"images/compas_p_plots_eo_discriminating.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_disparity_race_wide = pd.DataFrame()\n",
    "\n",
    "for model_name, metrics in metrics_race.items():\n",
    "    # calculate max disparity table\n",
    "    max_disparity_race = max_disparity({model_name: metrics}, renaming_dict=renaming_dict)\n",
    "\n",
    "    # convert to wide format (Regular | Discriminating)\n",
    "    max_disparity_race_wide = max_disparity_race_wide.append(\n",
    "        convert_max_disparity_to_wide(max_disparity_race))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming dictionaries\n",
    "renaming_dict2 = dict(attacker=\"Attacker\", model=\"Model\", target_train_acc=\"Train Acc.\", target_test_acc=\"Test Acc.\", \n",
    "                      overfitting_gap=\"Overfitting\", vuln=\"Vulnerability\", max_vuln_disparity=\"Max Vuln. Disparity\")\n",
    "\n",
    "paper_table = (max_disparity_race_wide\n",
    "               .rename(columns=renaming_dict, level=0)\n",
    "               .rename(columns=renaming_dict2, level=1)\n",
    "               .rename(index=renaming_dict))\n",
    "\n",
    "# Prettification and ordering\n",
    "paper_table = (paper_table * 100).round(2)\n",
    "paper_table = paper_table.reindex(model_order)\n",
    "\n",
    "print(get_latex_table(paper_table))\n",
    "paper_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
