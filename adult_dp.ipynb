{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SHUFFLES = 35\n",
    "FIGWIDTH = 8\n",
    "ALPHA = 0.005\n",
    "LOAD_FROM_PICKLE = True\n",
    "PICKLE = \"results/adult_race_dp_100_reps.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import diffprivlib.models as dp\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from experiment import run_generic_experiment\n",
    "from model_zoo import model_zoo, renaming_dict, lr_setup\n",
    "from utils import metrics_dict_to_dataframe\n",
    "from utils import convert_max_disparity_to_wide, get_latex_table\n",
    "from disparity import compute_emm, compute_anovas, max_disparity\n",
    "from plotting import plot_stat_heatmaps, plot_vuln_dists\n",
    "from loaders.adult import prepare_adult\n",
    "\n",
    "import plot_params\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_undummified = prepare_adult(\"./data/adult/train.csv\", \"./data/adult/test.csv\", binarize=False).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_undummified[\"race\"].value_counts().index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11 is the maximum number of ones in a ADULT feature vector after one-hot encoding.\n",
    "data_norm = np.sqrt(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renaming_dict = {\n",
    "        \"eps1\": r\"$\\varepsilon=1$\",\n",
    "        \"eps2.5\": r\"$\\varepsilon=2.5$\",\n",
    "        \"eps5\": r\"$\\varepsilon=5$\",\n",
    "        \"eps7.5\": r\"$\\varepsilon=7.5$\",\n",
    "        \"eps10\": r\"$\\varepsilon=10$\",\n",
    "        \"regular\": \"Regular\",\n",
    "        \"discriminating\": \"Discriminating\",\n",
    "        \"Native American\": \"Native\\nAmerican\",\n",
    "        \"African-American\": \"African-\\nAmerican\",\n",
    "}\n",
    "\n",
    "model_order = [\n",
    "    \"eps1\", \"eps2.5\", \"eps5\", \"eps7.5\", \"eps10\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_zoo = {\n",
    "    \"eps{}\".format(eps): Pipeline([\n",
    "        (\"scaler\", MinMaxScaler()),\n",
    "        (\"clf\", dp.LogisticRegression(max_iter=lr_setup[\"max_iter\"],\n",
    "                                      epsilon=eps,\n",
    "                                      data_norm=data_norm))\n",
    "    ]) for eps in [1, 2.5, 5, 7.5]\n",
    "}\n",
    "fit_args = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgroups = ['White', 'Black', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo', 'Other']\n",
    "subgroups_short = [\"WH\", \"BL\", \"AI\", \"AE\", \"OT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the experiments on 'race' subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_FROM_PICKLE:\n",
    "    metrics_race = pd.read_pickle(PICKLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LOAD_FROM_PICKLE:\n",
    "    metrics_race = {}\n",
    "    for model_name, clf in model_zoo.items():\n",
    "        print(model_name)\n",
    "        metrics_race[model_name] = run_generic_experiment(\n",
    "            data=data_undummified,\n",
    "            y_label=\"income\",\n",
    "            z_label=\"race\",\n",
    "            z_values=subgroups,\n",
    "            num_batches=NUM_SHUFFLES,\n",
    "            synthetic_bins=10,\n",
    "            parallelize=True,\n",
    "            clf=clf,\n",
    "            fit_args=fit_args.get(model_name, {})\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LOAD_FROM_PICKLE:\n",
    "    pd.to_pickle(metrics_race, PICKLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in metrics_race.items():\n",
    "    metrics_race[k] = metrics_race[k].query(f\"batch_no < {NUM_SHUFFLES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_anovas_by_model = compute_anovas(\n",
    "    metrics_race,\n",
    "    attacker=\"regular\",\n",
    ")\n",
    "\n",
    "discriminating_anovas_by_model = compute_anovas(\n",
    "    metrics_race,\n",
    "    attacker=\"discriminating\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, (p_value, _) in regular_anovas_by_model.items():\n",
    "    print(f\"{model}: {p_value:.4f} (regular)\")\n",
    "    \n",
    "for model, (p_value, _) in discriminating_anovas_by_model.items():\n",
    "    print(f\"{model}: {p_value:.4f} (discriminating)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_p_matrices_by_model = compute_emm(\n",
    "    regular_anovas_by_model,\n",
    "    subgroups=subgroups,\n",
    ")\n",
    "\n",
    "discriminating_p_matrices_by_model = compute_emm(\n",
    "    discriminating_anovas_by_model,\n",
    "    subgroups=subgroups,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = sns.color_palette([\"#ECF0F1\", \"#E74C3C\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(3*FIGWIDTH, FIGWIDTH), sharex=True, sharey=True)\n",
    "for ax_id, model_name in enumerate(metrics_race.keys()):\n",
    "    metrics = metrics_race[model_name]\n",
    "    axes[ax_id].set_title(renaming_dict[model_name])\n",
    "    plot_stat_heatmaps(metrics,\n",
    "                       regular_p_matrices_by_model[model_name],\n",
    "                       subgroups=subgroups,\n",
    "                       alpha=ALPHA, ax=axes[ax_id],\n",
    "                       xticklabels=True, cmap=cmap)\n",
    "    axes[ax_id].set_xticklabels(subgroups_short)\n",
    "    axes[ax_id].set_yticklabels(subgroups_short)\n",
    "\n",
    "fig.set_tight_layout(tight=True)\n",
    "plt.show()\n",
    "fig.savefig(\"images/adult_p_plots_dp_regular.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(3*FIGWIDTH, FIGWIDTH), sharex=True, sharey=True)\n",
    "for ax_id, model_name in enumerate(metrics_race.keys()):\n",
    "    metrics = metrics_race[model_name]\n",
    "    axes[ax_id].set_title(renaming_dict[model_name])\n",
    "    plot_stat_heatmaps(metrics,\n",
    "                       discriminating_p_matrices_by_model[model_name],\n",
    "                       subgroups=subgroups,\n",
    "                       alpha=ALPHA,\n",
    "                       ax=axes[ax_id],\n",
    "                       xticklabels=True,\n",
    "                       cmap=cmap)\n",
    "    axes[ax_id].set_xticklabels(subgroups_short)\n",
    "    axes[ax_id].set_yticklabels(subgroups_short)\n",
    "\n",
    "fig.set_tight_layout(tight=True)\n",
    "plt.show()\n",
    "fig.savefig(\"images/adult_p_plots_dp_discriminating.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_disparity_race_wide = pd.DataFrame()\n",
    "\n",
    "for model_name, metrics in metrics_race.items():\n",
    "    # calculate max disparity table\n",
    "    max_disparity_race = max_disparity({model_name: metrics}, renaming_dict=renaming_dict)\n",
    "\n",
    "    # convert to wide format (Regular | Discriminating)\n",
    "    max_disparity_race_wide = max_disparity_race_wide.append(\n",
    "        convert_max_disparity_to_wide(max_disparity_race))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming dictionaries\n",
    "renaming_dict2 = dict(attacker=\"Attacker\", model=\"Model\", target_train_acc=\"Train Acc.\", target_test_acc=\"Test Acc.\", \n",
    "                      overfitting_gap=\"Overfitting\", vuln=\"Vulnerability\", max_vuln_disparity=\"Max Vuln. Disparity\")\n",
    "\n",
    "paper_table = (max_disparity_race_wide\n",
    "               .rename(columns=renaming_dict, level=0)\n",
    "               .rename(columns=renaming_dict2, level=1)\n",
    "               .rename(index=renaming_dict))\n",
    "\n",
    "# Prettification and ordering\n",
    "paper_table = (paper_table * 100).round(2)\n",
    "\n",
    "print(get_latex_table(paper_table))\n",
    "paper_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
