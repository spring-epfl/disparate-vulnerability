from itertools import product

import joblib
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from tqdm import tqdm_notebook as tqdm
import sys
from functools import reduce
from fbleau.fbleau import calc_vulnerability as fbleau_vuln

from compas import prepare_compas
from helpers import encode_dataframe, prob_operator, joint_prob, balance_dataset
from fixes import model_zoo
from mia.vuln import calc_vulnerability_closed_form


def calculate_discriminating(train_learn_df, train_eval_df, test_learn_df, test_eval_df, z_label, z_value, y_label,
                             y_value, yhat_value):
    prob = lambda *args, **kwargs: prob_operator(y_label, y_value, yhat_value, z_label, z_value, *args, **kwargs)

    learn_df = train_learn_df.assign(m=1).append(test_learn_df.assign(m=0))

    try:
        vuln = np.max([prob(learn_df, "m", condition="yhat y z", m_value=0),
                       prob(learn_df, "m", condition="yhat y z", m_value=1)])
    except ZeroDivisionError:
        vuln = 0.5

    # vulnerability
    eval_df = train_eval_df.append(test_eval_df)
    subgroup_vuln = vuln * prob(eval_df, "yhat y", condition="z")

    # overfitting factor \epsilon
    p_train_learn = prob(train_learn_df, "yhat", condition="y z")
    p_test_learn = prob(test_learn_df, "yhat", condition="y z")
    eps_learn = max(p_train_learn, p_test_learn) - np.mean([p_train_learn, p_test_learn])

    p_train_eval = prob(train_eval_df, "yhat", condition="y z")
    p_test_eval = prob(test_eval_df, "yhat", condition="y z")

    try:
        eps_eval = max(p_train_eval, p_test_eval) - np.mean([p_train_eval, p_test_eval])
    except TypeError:
        eps_eval = None

    # unfairness factor \phi
    learn_df = train_learn_df.append(test_learn_df)

    try:
        phi_learn = prob(learn_df, "yhat", condition="y z") / prob(learn_df, "yhat", condition="y")
    except ZeroDivisionError:
        phi_learn = np.inf

    try:
        phi_eval = prob(eval_df, "yhat", condition="y z") / prob(eval_df, "yhat", condition="y")
    except ZeroDivisionError:
        phi_eval = np.inf

    return subgroup_vuln, eps_learn, eps_eval, phi_learn, phi_eval


def calculate_regular(train_learn_df, train_eval_df, test_learn_df, test_eval_df, z_label, z_value, y_label, y_value,
                      yhat_value):
    learn_df = train_learn_df.assign(m=1).append(test_learn_df.assign(m=0))
    eval_df = train_eval_df.append(test_eval_df)

    prob = lambda *args, **kwargs: prob_operator(y_label, y_value, yhat_value, z_label, z_value, *args, **kwargs)

    try:
        vuln = np.max([prob(learn_df, "m", condition="yhat y", m_value=0),
                       prob(learn_df, "m", condition="yhat y", m_value=1)])
    except ZeroDivisionError:
        vuln = 0.5

    # vulnerability
    subgroup_vuln = vuln * prob(eval_df, "yhat y", condition="z")

    # overfitting factor \epsilon
    p_train_learn = prob(train_learn_df, "yhat", condition="y")
    p_test_learn = prob(test_learn_df, "yhat", condition="y")
    eps_learn = max(p_train_learn, p_test_learn) - np.mean([p_train_learn, p_test_learn])

    p_train_eval = prob(train_eval_df, "yhat", condition="y")
    p_test_eval = prob(test_eval_df, "yhat", condition="y")
    eps_eval = max(p_train_eval, p_test_eval) - np.mean([p_train_eval, p_test_eval])

    # unfairness factor \phi
    learn_df = train_learn_df.append(test_learn_df)
    try:
        phi_learn = prob(learn_df, "yhat", condition="y z") / prob(learn_df, "yhat", condition="y")
    except ZeroDivisionError:
        phi_learn = np.inf

    try:
        phi_eval = prob(eval_df, "yhat", condition="y z") / prob(eval_df, "yhat", condition="y")
    except ZeroDivisionError:
        phi_eval = np.inf

    return subgroup_vuln, eps_learn, eps_eval, phi_learn, phi_eval


def calculate_vulnerability(train_learn_df, train_eval_df, test_learn_df, test_eval_df,
                            attacker, z_label, z_value, y_label):
    subgroup_vuln_list, eps_learn_list, eps_eval_list, phi_learn_list, phi_eval_list = [[] for _ in range(5)]
    for y_value, yhat_value in product([0, 1], [0, 1]):
        if attacker == "regular":
            subgroup_vuln, eps_learn, eps_eval, phi_learn, phi_eval = calculate_regular(train_learn_df, train_eval_df,
                                                                                        test_learn_df, test_eval_df,
                                                                                        z_label, z_value,
                                                                                        y_label, y_value, yhat_value)
        elif attacker == "discriminating":
            subgroup_vuln, eps_learn, eps_eval, phi_learn, phi_eval = calculate_discriminating(train_learn_df,
                                                                                               train_eval_df,
                                                                                               test_learn_df,
                                                                                               test_eval_df,
                                                                                               z_label, z_value,
                                                                                               y_label, y_value,
                                                                                               yhat_value)
        else:
            raise NotImplementedError

        subgroup_vuln_list.append(subgroup_vuln)
        eps_learn_list.append(eps_learn)
        eps_eval_list.append(eps_eval)
        phi_learn_list.append(eps_learn)
        phi_eval_list.append(phi_eval)

    subgroup_vuln = np.sum(subgroup_vuln_list)
    eps_learn = np.mean(eps_learn_list)
    eps_eval = np.mean(eps_eval_list)
    phi_learn = np.mean(phi_learn_list)
    phi_eval = np.mean(phi_eval_list)

    return subgroup_vuln, eps_learn, eps_eval, phi_learn, phi_eval


def run_compas_experiment(data, z_label, z_values, clf, fit_args=None, num_batches=1):
    """
    :: experiment settings

    """

    # setup
    # if classifier is None:
    #     clf = LogisticRegression(solver="lbfgs")
    # else:
    #     clf = classifier

    # adding the joint column for stratification
    data["strat"] = data.apply(lambda x: x[z_label] + '-' + x["Ground Truth"], axis=1)

    y_label = "Ground Truth_Will not reoffend"
    encode = lambda df, cols: encode_dataframe(df, drop_first=False,
                                               output_columns=cols,
                                               initially_drop_columns=None,
                                               add_non_dummified_columns=[z_label],
                                               finally_drop_columns=['Ground Truth_Will reoffend', 'Gender_Female',
                                                                     'Felony or Misdemeanor_Misdemeanor'] if cols == None else None,
                                               return_output_columns=cols == None)

    metrics = []
    for batch_no in tqdm(range(num_batches)):

        # train/test split
        train_df, test_df = train_test_split(data, test_size=0.5, stratify=data["strat"])

        # encode dataframes for learning and prediction
        train_df, cols = encode(train_df, None)
        test_df = encode(test_df, cols)

        # separate features and labels
        X_train, y_train = train_df.drop([y_label, z_label, "strat"], axis=1), train_df[y_label]
        X_test, y_test = test_df.drop([y_label, z_label, "strat"], axis=1), test_df[y_label]

        # print(X_train.columns)

        fit_args_ = dict(sensitive_features=train_df[z_label],
                         **{k: v for k, v in fit_args.items() if k != "sensitive"}) if fit_args.get("sensitive",
                                                                                                    False) else dict()
        clf.fit(X_train, y_train, **fit_args_)

        # save confidences to train/test dataframes
        predict_args_ = lambda df: dict(sensitive_features=df[z_label]) if fit_args.get("sensitive", False) else dict()

        train_df.loc[:, "p"] = clf.predict_proba(X_train, **predict_args_(train_df))[:, 1]
        test_df.loc[:, "p"] = clf.predict_proba(X_test, **predict_args_(test_df))[:, 1]

        # save predicted labels to train/test dataframes
        train_df.loc[:, "yhat"] = clf.predict(X_train, **predict_args_(train_df))
        test_df.loc[:, "yhat"] = clf.predict(X_test, **predict_args_(test_df))

        # measure target model accuracy
        target_train_acc = accuracy_score(train_df[y_label], train_df["yhat"])
        target_test_acc = accuracy_score(test_df[y_label], test_df["yhat"])

        # split train into learn/eval
        train_learn_df, train_eval_df = train_test_split(train_df, test_size=0.3, stratify=train_df["strat"])

        # split test into learn/eval
        test_learn_df, test_eval_df = train_test_split(test_df, test_size=0.3, stratify=test_df["strat"])

        for z_val in z_values + [None]:
            # Counts.
            disc_vuln = calc_vulnerability_closed_form(train_learn_df, train_eval_df, test_learn_df,
                    test_eval_df, p_label="yhat", z_label=z_label, z_values=z_values, z_value=z_val,
                    y_label=y_label, attacker="discriminating")
            reg_vuln = calc_vulnerability_closed_form(train_learn_df, train_eval_df, test_learn_df,
                    test_eval_df, p_label="yhat", z_label=z_label, z_values=z_values, z_value=z_val,
                    y_label=y_label, attacker="regular")
            metrics.append((z_val or "Overall", "cf", batch_no, 'discriminating', target_train_acc, target_test_acc,
                    disc_vuln))
            metrics.append((z_val or "Overall", "cf", batch_no, 'regular', target_train_acc, target_test_acc,
                    reg_vuln))

            # fbleau.
            vuln = calc_vulnerability(train_learn_df, train_eval_df, test_learn_df,
                    test_eval_df, p_label="yhat", z_label=z_label, z_values=z_values, z_value=z_val,
                    y_label=y_label, attacker="discriminating")
            reg_vuln = calc_vulnerability(train_learn_df, train_eval_df, test_learn_df,
                    test_eval_df, p_label="yhat", z_label=z_label, z_values=z_values, z_value=z_val,
                    y_label=y_label, attacker="regular")
            metrics.append((z_val or "Overall", "fbleau", batch_no, 'discriminating', target_train_acc, target_test_acc,
                    disc_vuln))
            metrics.append((z_val or "Overall", "fbleau", batch_no, 'regular', target_train_acc, target_test_acc,
                    reg_vuln))

    return pd.DataFrame(
            metrics, columns=["subgroup", "type", "batch_no", "attacker", "target_train_acc", "target_test_acc", "vuln"])



def run_adult_experiment(data, z_label, z_values, clf, clf_name=None, fit_args=None, n_processes=4, num_batches=1,
                         diagnostic=0, balanced=False):
    """
    :: experiment settings

    """

    # adding the joint column for stratification
    data["strat"] = data.apply(lambda x: x[z_label] + '-' + str(x["income"]), axis=1)

    y_label = "income"
    encode = lambda df, cols: encode_dataframe(df, drop_first=False,
                                               output_columns=cols,
                                               initially_drop_columns=None,
                                               add_non_dummified_columns=[z_label],
                                               finally_drop_columns=[] if cols == None else None,
                                               return_output_columns=cols == None)

    def one_iter(batch_no):

        if balanced:
            _data = balance_dataset(data, z_label, y_label, random_state=batch_no)
        else:
            _data = data

        metrics = []
        # train/test split
        train_df, test_df = train_test_split(_data, test_size=0.5, stratify=_data["strat"], random_state=batch_no)

        # encode dataframes for learning and prediction
        train_df, cols = encode(train_df, None)
        test_df = encode(test_df, cols)

        # separate features and labels
        X_train, y_train = train_df.drop([y_label, z_label, "strat"], axis=1), train_df[y_label]
        X_test, y_test = test_df.drop([y_label, z_label, "strat"], axis=1), test_df[y_label]

        fit_args_ = dict(sensitive_features=train_df[z_label],
                         **{k: v for k, v in fit_args.items() if k != "sensitive"}) if fit_args.get("sensitive",
                                                                                                    False) else dict()
        clf.fit(X_train, y_train, **fit_args_)

        # save confidences to train/test dataframes
        predict_args_ = lambda df: dict(sensitive_features=df[z_label]) if fit_args.get("sensitive", False) else dict()

        train_df.loc[:, "p"] = clf.predict_proba(X_train, **predict_args_(train_df))[:, 1]
        test_df.loc[:, "p"] = clf.predict_proba(X_test, **predict_args_(test_df))[:, 1]

        # save predicted labels to train/test dataframes
        train_df.loc[:, "yhat"] = clf.predict(X_train, **predict_args_(train_df))
        test_df.loc[:, "yhat"] = clf.predict(X_test, **predict_args_(test_df))

        # measure target model accuracy
        target_train_acc = accuracy_score(train_df[y_label], train_df["yhat"])
        target_test_acc = accuracy_score(test_df[y_label], test_df["yhat"])

        # split train into learn/eval
        train_learn_df, train_eval_df = train_test_split(train_df, test_size=0.3, stratify=train_df["strat"],
                                                         random_state=batch_no)

        # split test into learn/eval
        test_learn_df, test_eval_df = train_test_split(test_df, test_size=0.3, stratify=test_df["strat"],
                                                       random_state=batch_no)

        if diagnostic == 1:
            return train_learn_df, train_eval_df, test_learn_df, test_eval_df
        elif diagnostic == 3:
            learn_df = train_learn_df.assign(m=0).append(test_learn_df.assign(m=1))
            return [
                (joint_prob(learn_df, m=1, yhat=1, **{y_label: 1, z_label: z_values[0]}) /
                 joint_prob(learn_df, yhat=1, **{y_label: 1, z_label: z_values[0]})
                 ),
                joint_prob(learn_df, m=1, yhat=1, **{y_label: 1}) / joint_prob(learn_df, yhat=1, **{y_label: 1})]

        for z_val in z_values:
            # calculate fbleau vulnerability
            fbleau_vuln_discriminating = fbleau_vuln(train_learn_df, train_eval_df, test_learn_df, test_eval_df,
                                                     "discriminating",
                                                     z_values=z_values,
                                                     z_label=z_label,
                                                     y_label=y_label,
                                                     p_label="yhat",
                                                     # estimate_method='--knn=1',
                                                     z_value=z_val)

            fbleau_vuln_regular = fbleau_vuln(train_learn_df, train_eval_df, test_learn_df, test_eval_df,
                                              "regular",
                                              z_values=z_values,
                                              z_label=z_label,
                                              y_label=y_label,
                                              p_label="yhat",
                                              # estimate_method='--knn=1',
                                              z_value=z_val)

            bogdan_vuln_discriminating = calc_vulnerability_closed_form(train_learn_df, train_eval_df, test_learn_df,
                                                                        test_eval_df,
                                                                        "discriminating",
                                                                        z_label=z_label,
                                                                        z_value=z_val,
                                                                        y_label=y_label,
                                                                        p_label="yhat",
                                                                        yhat_label="yhat",
                                                                        z_values=z_values)

            bogdan_vuln_regular = calc_vulnerability_closed_form(train_learn_df, train_eval_df, test_learn_df,
                                                                 test_eval_df,
                                                                 "regular",
                                                                 z_label=z_label,
                                                                 z_value=z_val,
                                                                 y_label=y_label,
                                                                 p_label="yhat",
                                                                 yhat_label="yhat",
                                                                 z_values=z_values)

            # mohammad_vuln_regular, _, _, _, _ = calculate_vulnerability(train_learn_df, train_eval_df, test_learn_df,
            #                                                             test_eval_df,
            #                                                             "regular",
            #                                                             z_label, z_val, y_label)
            #
            # mohammad_vuln_discriminating, _, _, _, _ = calculate_vulnerability(train_learn_df, train_eval_df,
            #                                                                    test_learn_df,
            #                                                                    test_eval_df,
            #                                                                    "discriminating",
            #                                                                    z_label, z_val, y_label)

            eval_df = train_eval_df.append(test_eval_df)
            support = len(eval_df.loc[eval_df[z_label] == z_val])

            # metrics
            metrics += [
                (z_val, batch_no, 'discriminating', target_train_acc, target_test_acc, fbleau_vuln_discriminating,
                bogdan_vuln_discriminating, support),
                (z_val, batch_no, 'regular', target_train_acc, target_test_acc, fbleau_vuln_regular,
                bogdan_vuln_regular, support)
            ]

        # Overall
        eval_df = train_eval_df.append(test_eval_df)
        overall_support = len(eval_df)

        overall_fbleau_vuln_discriminating = fbleau_vuln(train_learn_df, train_eval_df, test_learn_df, test_eval_df,
                                                         "discriminating",
                                                         z_values=z_values,
                                                         z_label=z_label,
                                                         y_label=y_label,
                                                         p_label="yhat",
                                                         # estimate_method='--knn=1',
                                                         z_value=None)

        overall_fbleau_vuln_regular = fbleau_vuln(train_learn_df, train_eval_df, test_learn_df, test_eval_df,
                                                  "regular",
                                                  z_values=z_values,
                                                  z_label=z_label,
                                                  y_label=y_label,
                                                  p_label="yhat",
                                                  # estimate_method='--knn=1',
                                                  z_value=None)

        overall_vuln_discriminating = calc_vulnerability_closed_form(train_learn_df, train_eval_df, test_learn_df,
                                                                    test_eval_df,
                                                                    "discriminating",
                                                                    z_label=z_label,
                                                                    z_value=None,
                                                                    y_label=y_label,
                                                                    p_label="yhat",
                                                                    yhat_label="yhat",
                                                                    z_values=z_values)

        overall_vuln_regular = calc_vulnerability_closed_form(train_learn_df, train_eval_df, test_learn_df,
                                                             test_eval_df,
                                                             "regular",
                                                             z_label=z_label,
                                                             z_value=None,
                                                             y_label=y_label,
                                                             p_label="yhat",
                                                             yhat_label="yhat",
                                                             z_values=z_values)


        metrics += [
            ("overall", batch_no, 'discriminating', target_train_acc, target_test_acc, overall_fbleau_vuln_discriminating,
             overall_vuln_discriminating, overall_support),
            ("overall", batch_no, 'regular', target_train_acc, target_test_acc, overall_fbleau_vuln_regular,
             overall_vuln_regular, overall_support)
        ]


        # print(metrics[0])
        return metrics

    if diagnostic == 1:
        return one_iter(num_batches)
    elif diagnostic == 2:
        results = one_iter(num_batches)
    elif diagnostic == 3:
        return
    else:
        if clf_name is not None:
            if "nn" in clf_name:
                n_jobs = int(n_processes / 4)
            else:
                n_jobs = n_processes
        else:
            n_jobs = n_processes

        with joblib.parallel_backend("loky", inner_max_num_threads=4):
            results = joblib.Parallel(n_jobs=n_jobs, verbose=51, prefer="threads")(
                joblib.delayed(one_iter)(i) for i in range(num_batches))
            results = reduce(lambda list1, list2: [*list1, *list2], results)

    # flatten list of lists
    print(results)

    return pd.DataFrame(results,
                        columns=["subgroup", "batch_no", "attacker",
                                 "target_train_acc", "target_test_acc",
                                 "fbleau_vuln", "b_vuln", "support"])

    return results

if __name__ == "__main__":
    data_undummified = prepare_compas("data/compas/compas-scores-two-years.csv", dummified=False, drop_first=True,
                                      drop_duplicates=False)

    fit_args = {"fair_lr": dict(sensitive_col_idx=[10], correlation_tolerance=0.2)}

    metrics_gender = {
        model_name: run_compas_experiment(data_undummified, z_label="Gender", z_values=["Male", "Female"],
                                          num_batches=1,
                                          clf=clf, fit_args=fit_args.get(model_name, {})) for model_name, clf in
        model_zoo.items()}
