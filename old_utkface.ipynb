{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SHUFFLES = 35\n",
    "FIGWIDTH = 8\n",
    "ALPHA = 0.005\n",
    "LOAD_FROM_PICKLE = True\n",
    "PICKLE = \"results/utkface_paper.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from plotting import plot_stat_heatmaps, plot_vuln_dists, plot_vuln_dists_legends_combined\n",
    "from utils import metrics_dict_to_dataframe\n",
    "from utils import convert_max_disparity_to_wide, get_latex_table\n",
    "from disparity import compute_emm, compute_anovas, max_disparity\n",
    "from experiment import run_generic_keras_experiment\n",
    "from model_zoo import model_zoo, renaming_dict\n",
    "from loaders.utkface import prepare_utkface\n",
    "\n",
    "import plot_params\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, meta_data = prepare_utkface(\"data/UTKFace/\", \"data/UTKFace.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIA Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renaming_dict = {\n",
    "    \"normal\": \"DNN (Non-Overfitting)\",\n",
    "    \"overfitting\": \"DNN (Overfitting)\",\n",
    "    \"discriminating\": \"Discriminating\",\n",
    "    \"regular\": \"Regular\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgroups = meta_data.race.unique().tolist()\n",
    "subgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_overfitting = tf.keras.Sequential(name=\"Overfitting\")\n",
    "\n",
    "model_overfitting.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(32,32,3))) \n",
    "model_overfitting.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "\n",
    "model_overfitting.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model_overfitting.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "\n",
    "model_overfitting.add(tf.keras.layers.Flatten())\n",
    "model_overfitting.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model_overfitting.add(tf.keras.layers.Dense(6, activation='softmax'))\n",
    "model_overfitting.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(name=\"Normal\")\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(32,32,3))) \n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(6, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LOAD_FROM_PICKLE:\n",
    "    metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LOAD_FROM_PICKLE:\n",
    "    metrics[\"normal\"] = run_generic_keras_experiment(\n",
    "            binary_data=X,\n",
    "            meta_data=meta_data,\n",
    "            y_label='y', \n",
    "            z_label=\"race\",\n",
    "            z_values=subgroups,\n",
    "            clf=model,\n",
    "            clf_name=\"normal\",\n",
    "            num_batches=NUM_SHUFFLES,\n",
    "            balanced=False,\n",
    "            synthetic_bins=10,\n",
    "            y_range=[0, 1, 2, 3, 4, 5],\n",
    "            save_best_only=True,\n",
    "            validation=2500,\n",
    "            checkpoint=\"models/normal_model_{}.h5\",\n",
    "            fit_args=dict(batch_size=64, epochs=100)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LOAD_FROM_PICKLE:\n",
    "    metrics[\"overfitting\"] = run_generic_keras_experiment(\n",
    "            binary_data=X,\n",
    "            meta_data=meta_data,\n",
    "            validation=None,\n",
    "            y_label='y', \n",
    "            z_label=\"race\",\n",
    "            z_values=subgroups,\n",
    "            clf=model_overfitting,\n",
    "            num_batches=10, \n",
    "            balanced=False,\n",
    "            synthetic_bins=10,\n",
    "            y_range=[0, 1, 2, 3, 4, 5],\n",
    "            save_best_only=False,\n",
    "            clf_name=\"overfitting\",\n",
    "            checkpoint=\"models/overfitting_model_{}.h5\",\n",
    "            fit_args=dict(batch_size=64, epochs=100)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LOAD_FROM_PICKLE:\n",
    "    pd.to_pickle(metrics, PICKLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_FROM_PICKLE:\n",
    "    metrics = pd.read_pickle(PICKLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in metrics.items():\n",
    "    metrics[k] = metrics[k].query(f\"batch_no < {NUM_SHUFFLES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics[\"overfitting\"].vuln.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics[\"normal\"].vuln.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacks to put group sizes on the plot legends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgroup_sizes = {}\n",
    "subgroup_renaming_dict = {}\n",
    "for subgroup in subgroups:\n",
    "    subgroup_sizes[subgroup] = int(\n",
    "        metrics[\"normal\"].query(f\"subgroup == '{subgroup}'\").support.mean()\n",
    "    )\n",
    "total = sum(subgroup_sizes.values())\n",
    "subgroups = list(sorted(subgroups, key=lambda k: -subgroup_sizes[k]))\n",
    "\n",
    "for subgroup in subgroups + [\"Overall\"]:\n",
    "    if subgroup == \"Overall\":\n",
    "        size = total\n",
    "    else:\n",
    "        size = subgroup_sizes[subgroup]\n",
    "    subgroup_renaming_dict[subgroup] = \"{}: {}\\n({}\\\\%)\".format(\n",
    "        subgroup, size, round(size / total * 100)\n",
    "    )\n",
    "\n",
    "subgroup_annotated_ordered = {s: subgroup_renaming_dict[s] for s in (subgroups)}\n",
    "renaming_dict = dict(renaming_dict, **subgroup_annotated_ordered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paper Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (FIGWIDTH, FIGWIDTH)\n",
    "xlim = [45, 65]\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=figsize, sharey=False, sharex=True,\n",
    "                         gridspec_kw=dict(height_ratios=[4, 1], hspace=0.))\n",
    "plot_vuln_dists(metrics,\n",
    "                models=[\"normal\"],\n",
    "                axes=np.expand_dims(axes, 1),\n",
    "                renaming_dict=renaming_dict,\n",
    "                vuln_method=\"counts\",\n",
    "                percentages=False,\n",
    "                legend=False,\n",
    "                order=subgroup_annotated_ordered.values(),\n",
    ")\n",
    "\n",
    "fig.set_tight_layout(tight=True)\n",
    "fig.savefig(\"images/utkface_dist_plots_normal.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (FIGWIDTH, FIGWIDTH)\n",
    "xlim = [45, 65]\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=figsize, sharey=False, sharex=True,\n",
    "                         gridspec_kw=dict(height_ratios=[4, 1], hspace=0.))\n",
    "plot_vuln_dists(metrics,\n",
    "                models=[\"overfitting\"],\n",
    "                axes=np.expand_dims(axes, 1),\n",
    "                renaming_dict=renaming_dict,\n",
    "                vuln_method=\"counts\",\n",
    "                percentages=False,\n",
    "                legend=False,\n",
    "                order=subgroup_annotated_ordered.values(),\n",
    ")\n",
    "\n",
    "fig.set_tight_layout(tight=True)\n",
    "fig.savefig(\"images/utkface_dist_plots_overfit.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_anovas_by_model = compute_anovas(\n",
    "    metrics,\n",
    "    attacker=\"regular\",\n",
    ")\n",
    "\n",
    "discriminating_anovas_by_model = compute_anovas(\n",
    "    metrics,\n",
    "    attacker=\"discriminating\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there any disparate vulnerability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, (p_value, _) in regular_anovas_by_model.items():\n",
    "    print(f\"{model}: {p_value:.4f} (regular)\")\n",
    "    \n",
    "for model, (p_value, _) in discriminating_anovas_by_model.items():\n",
    "    print(f\"{model}: {p_value:.4f} (discriminating)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow-up pairwise comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_p_matrices_by_model = compute_emm(\n",
    "    regular_anovas_by_model,\n",
    "    subgroups=subgroups,\n",
    ")\n",
    "\n",
    "discriminating_p_matrices_by_model = compute_emm(\n",
    "    discriminating_anovas_by_model,\n",
    "    subgroups=subgroups,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-test plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = sns.color_palette([\"#ECF0F1\", \"#E74C3C\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(FIGWIDTH, FIGWIDTH))\n",
    "ax.set_title(renaming_dict[\"normal\"])\n",
    "plot_stat_heatmaps([metrics[\"normal\"]], regular_p_matrices_by_model[\"normal\"], subgroups, alpha=ALPHA, ax=ax, cmap=cmap)\n",
    "fig.savefig(\"images/utkface_p_plots_normal_regular.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(FIGWIDTH, FIGWIDTH))\n",
    "ax.set_title(renaming_dict[\"normal\"])\n",
    "plot_stat_heatmaps(\n",
    "    [metrics[\"normal\"]],\n",
    "    discriminating_p_matrices_by_model[\"normal\"],\n",
    "    subgroups,\n",
    "    alpha=0.05,\n",
    "    ax=ax,\n",
    "    cmap=cmap\n",
    ")\n",
    "fig.savefig(\"images/utkface_p_plots_normal_discriminating.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(FIGWIDTH, FIGWIDTH))\n",
    "ax.set_title(renaming_dict[\"overfitting\"])\n",
    "plot_stat_heatmaps(\n",
    "    [metrics[\"overfitting\"]],\n",
    "    discriminating_p_matrices_by_model[\"overfitting\"],\n",
    "    subgroups,\n",
    "    alpha=ALPHA,\n",
    "    ax=ax,\n",
    "    cmap=cmap)\n",
    "fig.savefig(\"images/utkface_p_plots_overfit_regular.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(FIGWIDTH, FIGWIDTH))\n",
    "ax.set_title(renaming_dict[\"overfitting\"])\n",
    "plot_stat_heatmaps(\n",
    "    [metrics[\"overfitting\"]],\n",
    "    discriminating_p_matrices_by_model[\"overfitting\"],\n",
    "    subgroups,\n",
    "    alpha=ALPHA,\n",
    "    ax=ax,\n",
    "    cmap=cmap\n",
    ")\n",
    "fig.savefig(\"images/utkface_p_plots_overfit_discriminating.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_disparity_race_wide = pd.DataFrame()\n",
    "\n",
    "for model_name, m_ in metrics.items():\n",
    "    # calculate max disparity table\n",
    "    max_disparity_race = max_disparity({model_name: m_}, renaming_dict=renaming_dict)\n",
    "\n",
    "    # convert to wide format (Regular | Discriminating)\n",
    "    max_disparity_race_wide = max_disparity_race_wide.append(\n",
    "        convert_max_disparity_to_wide(max_disparity_race))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming dictionaries\n",
    "renaming_dict2 = dict(attacker=\"Attacker\", model=\"Model\", target_train_acc=\"Train Acc.\", target_test_acc=\"Test Acc.\", \n",
    "                      overfitting_gap=\"Overfitting\", vuln=\"Vulnerability\", max_vuln_disparity=\"Max Vuln. Disparity\")\n",
    "\n",
    "paper_table = (max_disparity_race_wide\n",
    "               .rename(columns=renaming_dict, level=0)\n",
    "               .rename(columns=renaming_dict2, level=1)\n",
    "               .rename(index=renaming_dict))\n",
    "\n",
    "# Prettification and ordering\n",
    "paper_table = (paper_table * 100).round(2)\n",
    "# paper_table = paper_table.reindex(model_order)\n",
    "\n",
    "print(get_latex_table(paper_table))\n",
    "paper_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2_p36] *",
   "language": "python",
   "name": "conda-env-tensorflow2_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
