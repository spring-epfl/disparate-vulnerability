{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_REPS = 20\n",
    "NUM_SHUFFLES = 35\n",
    "NUM_EPOCHS = 60\n",
    "LOAD_FROM_PICKLE = True\n",
    "\n",
    "SIZE_EXPERIMENT_LABEL = \"sample_size_feb3\"\n",
    "SIZE_PICKLE_PATH = \"results/learnability_sample_size/\"\n",
    "DISTRO_EXPERIMENT_LABEL = \"subgroup_distro_feb3\"\n",
    "DISTRO_PICKLE_PATH = \"results/learnability_subgroup_distro/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from plotting import plot_stat_heatmaps, plot_vuln_dists\n",
    "from experiment import *\n",
    "from model_zoo import model_zoo, renaming_dict\n",
    "from disparity import compute_p_matrices, max_disparity\n",
    "from utils import metrics_dict_to_dataframe\n",
    "from loaders.utkface import prepare_utkface\n",
    "\n",
    "import plot_params\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "rc('text', usetex=False) \n",
    "\n",
    "# Plotting Fonts\n",
    "SMALL_SIZE = 40\n",
    "MEDIUM_SIZE = SMALL_SIZE + 1\n",
    "BIGGER_SIZE = MEDIUM_SIZE + 1\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=43)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "plt.rcParams['axes.labelweight'] = 'normal'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Size Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample(meta_data, z_label, subgroups, random_state=None):\n",
    "    _data = meta_data.loc[meta_data[z_label].isin(subgroups)]\n",
    "    counts = _data.race.value_counts()\n",
    "    smallest_subgroup_size = counts.min()\n",
    "    state = np.random.RandomState(random_state) if random_state is not None else np.random.RandomState()\n",
    "\n",
    "    train_idx_dict = {}\n",
    "    test_idx_dict = {}\n",
    "    for group in subgroups:\n",
    "        group_idx = state.choice(\n",
    "            _data.query(f\"{z_label} == '{group}'\").index, size=int(smallest_subgroup_size)).tolist()\n",
    "\n",
    "        train_idx_dict[group] = group_idx[:int(smallest_subgroup_size / 2)]\n",
    "        test_idx_dict[group] = group_idx[int(smallest_subgroup_size / 2):]\n",
    "\n",
    "    return train_idx_dict, test_idx_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model():\n",
    "    clf = tf.keras.Sequential()\n",
    "\n",
    "    clf.add(\n",
    "        tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
    "    clf.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "    clf.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "    clf.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "    clf.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "    clf.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "    clf.add(tf.keras.layers.Flatten())\n",
    "    clf.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    clf.add(tf.keras.layers.Dropout(0.5))\n",
    "    clf.add(tf.keras.layers.Dense(6, activation='softmax'))\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_setting(debug_):\n",
    "    validation_ratio_ = 0.2\n",
    "    if not debug_:\n",
    "        #     train_sizes = [200, 300, 400, 500, 600, 700, 800, 900, 1000, 1200, 1500, 1717]\n",
    "        train_sizes_ = [250, 500, 750, 1000]\n",
    "        reps_ = 5\n",
    "        num_batches_ = NUM_SHUFFLES\n",
    "    else:\n",
    "        train_sizes_ = [250]\n",
    "        reps_ = 1\n",
    "        num_batches_ = 2\n",
    "\n",
    "    return validation_ratio_, train_sizes_, reps_, num_batches_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LOAD_FROM_PICKLE:\n",
    "    # Setup\n",
    "    debug = False\n",
    "    start_rep = 0\n",
    "    end_rep = NUM_REPS\n",
    "\n",
    "    # load data\n",
    "    X, y, meta_data = prepare_utkface(\"data/UTKFace/\", \"data/UTKFace.npz\")\n",
    "\n",
    "    # subsample data\n",
    "    subgroups = meta_data.race.unique()\n",
    "    train_idx_dict, test_idx_dict = subsample(meta_data, \"race\", list(filter(lambda x: x != \"Other\", subgroups)), 1)\n",
    "\n",
    "    # prepare keras classifier\n",
    "    clf = prepare_model()\n",
    "    checkpoint_path = \"models/downsampling_model_2.h5\"\n",
    "    fit_args = dict(batch_size=64, epochs=NUM_EPOCHS)\n",
    "\n",
    "    # set experiment constants\n",
    "    filtered_subgroups = list(filter(lambda x: x != \"Other\", subgroups))\n",
    "    validation_ratio, train_sizes, reps, num_batches = experiment_setting(debug)\n",
    "\n",
    "    # Main Loop\n",
    "\n",
    "    if end_rep is None:\n",
    "        rep_d = tqdm(range(start_rep, reps))\n",
    "    else:\n",
    "        rep_d = tqdm(range(start_rep, end_rep + 1))\n",
    "\n",
    "    for rep_no in rep_d:\n",
    "        rep_d.set_description(f\"Rep {rep_no}\")\n",
    "\n",
    "        train_idx_dict, test_idx_dict = subsample(meta_data, \"race\",\n",
    "                                                  filtered_subgroups, rep_no)\n",
    "\n",
    "        tsize_d = tqdm(train_sizes)\n",
    "        for tsize in tsize_d:\n",
    "            tsize_d.set_description(f\"{tsize}\")\n",
    "\n",
    "            group_d = tqdm(filtered_subgroups)\n",
    "            for group in group_d:\n",
    "                group_d.set_description(f\"{group}\")\n",
    "\n",
    "                train_idx = []\n",
    "                valid_idx = []\n",
    "                test_idx = []\n",
    "\n",
    "                # adding selected subgroup up to tsize samples\n",
    "                train_idx += train_idx_dict[group][:int(tsize * (1 - validation_ratio))]\n",
    "                valid_idx += train_idx_dict[group][int(tsize * (1 - validation_ratio)):int(tsize)]\n",
    "\n",
    "                # take the |train| + |valid| (= tsize) number of samples from test set\n",
    "                test_idx += test_idx_dict[group][:tsize]\n",
    "\n",
    "                for not_group in filtered_subgroups:\n",
    "                    if not_group != group:\n",
    "                        # adding other subgroups \"completely\"\n",
    "                        validation_size = int(len(train_idx_dict[not_group]) * validation_ratio)\n",
    "                        valid_idx += train_idx_dict[not_group][:validation_size]\n",
    "                        train_idx += train_idx_dict[not_group][validation_size:]\n",
    "                        test_idx += test_idx_dict[not_group]\n",
    "\n",
    "                try:\n",
    "                    # running the experiment\n",
    "                    results = run_generic_keras_experiment(\n",
    "                        binary_data=X,\n",
    "                        meta_data=meta_data,\n",
    "                        y_label='y',\n",
    "                        z_label=\"race\",\n",
    "                        z_values=filtered_subgroups,\n",
    "                        clf=clf,\n",
    "                        validation=None,\n",
    "                        train_valid_test_idx=(train_idx, valid_idx, test_idx),\n",
    "                        clf_name=\"ff_keras\",\n",
    "                        fit_args=fit_args,\n",
    "                        num_batches=num_batches,\n",
    "                        synthetic_bins=10,\n",
    "                        diagnose_calibration=False,\n",
    "                        balanced=False,\n",
    "                        y_range=[0, 1, 2, 3, 4, 5],\n",
    "                        random_state=None,\n",
    "                        save_best_only=True,\n",
    "                        checkpoint=checkpoint_path,\n",
    "                        compile_parameters=None,\n",
    "                        output_extended_subgroup_metrics=False)\n",
    "                except:\n",
    "                    results = pd.DataFrame([None])\n",
    "\n",
    "                # adding metadata\n",
    "                results = results.assign(tsize=tsize, rep_no=rep_no)\n",
    "\n",
    "                # metrics[(group, tsize)].append(results)\n",
    "                pd.to_pickle(results, os.path.join(SIZE_PICKLE_PATH, f\"{SIZE_EXPERIMENT_LABEL}_{group}_{tsize}_{rep_no}.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_metrics_pkls(path, experiment_label):\n",
    "    valid_files = [file for file in os.listdir(path) if experiment_label in file]\n",
    "    metrics = collections.defaultdict(list)\n",
    "    \n",
    "    for filename in valid_files:\n",
    "        tgroup, tsize = filename.replace(experiment_label, \"\").split(\"_\")[1:3]\n",
    "        df = pd.read_pickle(os.path.join(path, filename))\n",
    "        metrics[(tgroup, int(tsize))].append(df)\n",
    "        \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_sample_size_result(path, experiment_label):\n",
    "    valid_files = [file for file in os.listdir(path) if experiment_label in file]\n",
    "    metrics = collections.defaultdict(list)\n",
    "\n",
    "    for filename in valid_files:\n",
    "        tgroup, tsize = filename.replace(experiment_label, \"\").split(\"_\")[1:3]\n",
    "        df = pd.read_pickle(os.path.join(path, filename))\n",
    "        yield tgroup, tsize, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_FROM_PICKLE:\n",
    "    metrics = produce_sample_size_result(SIZE_PICKLE_PATH, SIZE_EXPERIMENT_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_to_merge = []\n",
    "for tgroup, tsize, df in metrics:\n",
    "    _df = df.groupby([\"subgroup\", \"attacker\", \"batch_no\"]).agg(\"mean\").assign(tgroup=tgroup)\n",
    "    _to_merge.append(_df)\n",
    "        \n",
    "aggregated_results = pd.concat(_to_merge)\n",
    "del _to_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 3 (right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lims = [51, 58]\n",
    "pointplot_settings = dict(hue_order=[\"Asian\", \"Black\", \"Indian\", \"White\"], palette=\"tab10\", dodge=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = (aggregated_results.query(\"subgroup == 'Asian' & attacker=='discriminating'\")\n",
    "                              .reset_index()\n",
    "                              .groupby([\"tgroup\", \"subgroup\", \"attacker\", \"tsize\", \"rep_no\"]).agg(\"mean\")).reset_index()\n",
    "plot_df[\"vuln\"] = plot_df[\"vuln\"] * 100\n",
    "\n",
    "rename_dict = {'vuln': 'Vulnerability',\n",
    " 'overfitting': 'Overfitting Gap',\n",
    " 'tsize': \" Treatment Group Train Size\"}\n",
    "\n",
    "plot_df = plot_df.rename(columns=rename_dict)\n",
    "\n",
    "g = sns.FacetGrid(plot_df, col=\"subgroup\",\n",
    "                  col_wrap=2, height=6, aspect=1.5, legend_out=False)\n",
    "\n",
    "print(plot_df.columns)\n",
    "g = (g.map(sns.pointplot, rename_dict[\"tsize\"], rename_dict[\"vuln\"], \"tgroup\", order=[250, 500, 750, 1000], **pointplot_settings)\n",
    "     .set_titles(\"'{col_name}' Vulnerability\"))\n",
    "\n",
    "g.axes[0].set_ylim(y_lims)\n",
    "g.savefig(\"images/utkface_sample_size_subgroup_asian_discriminating.pdf\", format=\"pdf\", layout=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df.to_pickle(\"sample_size.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ylim = [50, 59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = (aggregated_results.query(\"subgroup != 'Overall' & attacker=='discriminating'\")\n",
    "                              .reset_index()\n",
    "                              .groupby([\"tgroup\", \"subgroup\", \"attacker\", \"tsize\", \"rep_no\"]).agg(\"mean\")).reset_index()\n",
    "plot_df[\"vuln\"] = plot_df[\"vuln\"] * 100\n",
    "\n",
    "_dict = dict(vuln=\"Vulnerability\", tsize=\"Target Training Size\")\n",
    "plot_df = plot_df.rename(columns=_dict)\n",
    "\n",
    "g = sns.FacetGrid(plot_df, col=\"subgroup\", \n",
    "                  col_wrap=2, height=6, aspect=1.5, legend_out=True, ylim=plot_ylim)\n",
    "\n",
    "g = (g.map(sns.pointplot, \"Target Training Size\", \"Vulnerability\", \"tgroup\", order=[250, 500, 750, 1000], **pointplot_settings)\n",
    "     .set_titles(\"'{col_name}' Vulnerability\"))\n",
    "\n",
    "g.add_legend(title=\"Target Group\")\n",
    "g.savefig(\"images/utkface_sample_size_discriminating.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = (aggregated_results.query(\"subgroup != 'Overall' & attacker=='regular'\")\n",
    "                              .reset_index()\n",
    "                              .groupby([\"tgroup\", \"subgroup\", \"attacker\", \"tsize\", \"rep_no\"]).agg(\"mean\")).reset_index()\n",
    "plot_df[\"vuln\"] = plot_df[\"vuln\"] * 100\n",
    "\n",
    "_dict = dict(vuln=\"Vulnerability\", tsize=\"Target Training Size\")\n",
    "plot_df = plot_df.rename(columns=_dict)\n",
    "\n",
    "g = sns.FacetGrid(plot_df, col=\"subgroup\", \n",
    "                  col_wrap=2, height=6, aspect=1.5, legend_out=True, ylim=plot_ylim)\n",
    "\n",
    "g = (g.map(sns.pointplot, \"Target Training Size\", \"Vulnerability\", \"tgroup\", order=[250, 500, 750, 1000], **pointplot_settings)\n",
    "     .set_titles(\"'{col_name}' Vulnerability\"))\n",
    "g.savefig(\"images/utkface_sample_size_regular.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Distribution Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del metrics\n",
    "del aggregated_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_setting(debug_):\n",
    "    validation_ratio_ = 0.2\n",
    "    if not debug_:\n",
    "        train_sizes_ = [200, 300, 400, 500, 600, 700, 800, 900, 1000, 1200, 1500, 1717]\n",
    "        reps_ = 35\n",
    "        num_batches_ = 35\n",
    "    else:\n",
    "        train_sizes_ = [200]\n",
    "        reps_ = 2\n",
    "        num_batches_ = 1\n",
    "\n",
    "    return validation_ratio_, train_sizes_, reps_, num_batches_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LOAD_FROM_PICKLE:\n",
    "    # Setup\n",
    "    debug=False\n",
    "    start_rep = 0\n",
    "    end_rep = 19\n",
    "\n",
    "    # load data\n",
    "    X, y, meta_data = prepare_utkface(\"data/UTKFace/\", \"data/UTKFace.npz\")\n",
    "\n",
    "    # subsample data\n",
    "    subgroups = meta_data.race.unique()\n",
    "    train_idx_dict, test_idx_dict = subsample(meta_data, \"race\", list(filter(lambda x: x != \"Other\", subgroups)), 1)\n",
    "\n",
    "    # prepare keras classifier\n",
    "    clf = prepare_model()\n",
    "    checkpoint_path = \"models/subgroup_distro.h5\"\n",
    "    fit_args = dict(batch_size=64, epochs=30)\n",
    "\n",
    "    # set experiment constants\n",
    "    filtered_subgroups = list(filter(lambda x: x != \"Other\", subgroups))\n",
    "    validation_ratio, train_sizes, reps, num_batches = experiment_setting(debug)\n",
    "    results_list = []\n",
    "\n",
    "    # Main Loop\n",
    "    if start_rep == 0:\n",
    "        rep_d = tqdm(range(reps))\n",
    "    else:\n",
    "        rep_d = tqdm(range(start_rep, reps + 1))\n",
    "    if end_rep is not None:\n",
    "        rep_d = tqdm(range(start_rep, end_rep))\n",
    "\n",
    "    for rep_no in rep_d:\n",
    "        rep_d.set_description(f\"Rep {rep_no}\")\n",
    "\n",
    "        train_idx_dict, test_idx_dict = subsample(meta_data, \"race\",\n",
    "                                                  list(filter(lambda x: x != \"Other\", subgroups)), rep_no)\n",
    "\n",
    "        tsize_d = tqdm(train_sizes)\n",
    "        for tsize in tsize_d:\n",
    "            tsize_d.set_description(f\"tsize {tsize}\")\n",
    "\n",
    "            train_idx = []\n",
    "            valid_idx = []\n",
    "            test_idx = []\n",
    "\n",
    "            # adding up all subgroup indices\n",
    "            for group in filter(lambda x: x != \"Other\", subgroups):\n",
    "                train_idx += train_idx_dict[group][:int(tsize * (1 - validation_ratio))]\n",
    "                valid_idx += train_idx_dict[group][int(tsize * (1 - validation_ratio)):int(tsize)]\n",
    "                test_idx += test_idx_dict[group][:tsize]\n",
    "\n",
    "                # test to make sure train (+valid): test is 50:50\n",
    "                assert (\n",
    "                        len(train_idx_dict[group][:int(tsize * (1 - validation_ratio))]) +\n",
    "                        len(train_idx_dict[group][int(tsize * (1 - validation_ratio)):int(tsize)]) == len(\n",
    "                    test_idx_dict[group][:tsize]))\n",
    "\n",
    "            try:\n",
    "                # running the experiment\n",
    "                results = run_generic_keras_experiment(\n",
    "                    binary_data=X,\n",
    "                    meta_data=meta_data,\n",
    "                    y_label='y',\n",
    "                    z_label=\"race\",\n",
    "                    z_values=list(filter(lambda x: x != \"Other\", subgroups)),\n",
    "                    clf=clf,\n",
    "                    validation=None,\n",
    "                    train_valid_test_idx=(train_idx, valid_idx, test_idx),\n",
    "                    clf_name=\"ff_keras\",\n",
    "                    fit_args=fit_args,\n",
    "                    num_batches=num_batches,\n",
    "                    synthetic_bins=10,\n",
    "                    diagnose_calibration=False,\n",
    "                    balanced=False,\n",
    "                    y_range=[0, 1, 2, 3, 4, 5],\n",
    "                    random_state=None,\n",
    "                    save_best_only=True,\n",
    "                    checkpoint=checkpoint_path,\n",
    "                    compile_parameters=None,\n",
    "                    output_extended_subgroup_metrics=False)\n",
    "            except:\n",
    "                results = pd.DataFrame([None])\n",
    "\n",
    "            # adding metadata\n",
    "            results = results.assign(tsize=tsize, rep_no=rep_no)\n",
    "\n",
    "            results_list.append(results)\n",
    "\n",
    "        # save progress each rep\n",
    "        pd.to_pickle(results_list, os.path.join(DISTRO_PICKLE_PATH, f\"{DISTRO_EXPERIMENT_LABEL}_{rep_no}.pkl\"))\n",
    "        results_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_results_pkls(path, experiment_label):\n",
    "    valid_files = [file for file in os.listdir(path) if experiment_label in file]\n",
    "    results_list = []\n",
    "    \n",
    "    for filename in valid_files:\n",
    "        results_list += pd.read_pickle(os.path.join(path, filename))\n",
    "        \n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_distro_result(path, experiment_label):\n",
    "    valid_files = iter([file for file in os.listdir(path) if experiment_label in file])\n",
    "    for filename in valid_files:\n",
    "        rep_results = pd.read_pickle(os.path.join(path, filename))\n",
    "        for indv_results in rep_results:\n",
    "            yield indv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_FROM_PICKLE:\n",
    "    results_list = produce_distro_result(DISTRO_PICKLE_PATH, DISTRO_EXPERIMENT_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_to_merge = []\n",
    "count = 0\n",
    "for results in results_list:\n",
    "    if len(results) == 1:\n",
    "        print(\"Problematic:\\n\", results)\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        _res = results.drop([\"support\", \"vuln_method\"], axis=1)\n",
    "        _res = _res.groupby([\"subgroup\", \"attacker\", \"tsize\", \"rep_no\", \"batch_no\"]).agg(\"mean\")\n",
    "        _to_merge.append(_res)\n",
    "    except KeyError as e:\n",
    "        print(e)\n",
    "        print(results.head())\n",
    "        \n",
    "    except pkl.UnpicklingError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    finally:\n",
    "        count += 1\n",
    "        \n",
    "aggregated_results = pd.concat(_to_merge).groupby([\"subgroup\", \"attacker\", \"tsize\", \"rep_no\"]).agg(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_results[\"overfitting\"] = aggregated_results[\"target_train_acc\"] - aggregated_results[\"target_test_acc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointplot_settings = dict(dodge=0.4, scale=2)\n",
    "paper_ylim = [51, 58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = dict(\n",
    "    vuln=\"Vulnerability\",\n",
    "    overfitting=\"Overfitting Gap\",\n",
    "    tsize=\"Subgroup Train Size\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = aggregated_results.copy()\n",
    "plot_df[[\"overfitting\", \"vuln\"]] = plot_df[[\"overfitting\", \"vuln\"]] * 100\n",
    "plot_df = plot_df.reset_index().rename(columns=rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df_sample_size = pd.read_pickle(\"sample_size.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dict = {'Subgroup Train Size': 'Subgroup Training Size'}\n",
    "plot_df = plot_df.rename(columns=_dict)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(25,10), sharex=False, sharey=True, gridspec_kw=dict(width_ratios=[2, 1]))\n",
    "sns.pointplot(data=plot_df.query(\"attacker == 'discriminating'\"), hue_order=[\"Asian\", \"Black\", \"Indian\", \"White\", \"Overall\"],\n",
    "              x=_dict[rename_dict[\"tsize\"]], y=rename_dict[\"vuln\"], hue=\"subgroup\", ax=axes[0], palette=\"tab10\", **pointplot_settings)\n",
    "\n",
    "_dict = {\" Treatment Group Train Size\": \"Target Training Size\"}\n",
    "plot_df_sample_size = plot_df_sample_size.rename(columns=_dict)\n",
    "sns.pointplot(\"Target Training Size\", \"Vulnerability\",  \"tgroup\", palette=\"tab10\", hue_order=[\"Asian\", \"Black\", \"Indian\", \"White\"],\n",
    "              order=[250, 500, 750, 1000], data=plot_df_sample_size, ax=axes[1], linestyles=[\"--\", \"-\", \"-\", \"-\"],\n",
    "              **pointplot_settings)\n",
    "\n",
    "axes[0].set_ylim(paper_ylim)\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=45)\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=45)\n",
    "axes[1].get_yaxis().set_visible(False)\n",
    "axes[1].legend().remove()\n",
    "\n",
    "leg = axes[0].legend(loc=\"upper right\", bbox_to_anchor=(1.0, 1),\n",
    "          fancybox=True, shadow=False, ncol=3)\n",
    "\n",
    "leg.get_frame().set_alpha(0.5)\n",
    "\n",
    "fig.subplots_adjust(hspace=0.01, wspace=0.01)\n",
    "fig.savefig(\"images/utkface_subgroup_distro_all.pdf\", format=\"pdf\",  bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = dict(\n",
    "    vuln=\"Vulnerability\",\n",
    "    overfitting=\"Overfitting Gap\",\n",
    "    tsize=\"Subgroup Training Size\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = aggregated_results.copy()\n",
    "plot_df[[\"overfitting\", \"vuln\"]] = plot_df[[\"overfitting\", \"vuln\"]] * 100\n",
    "plot_df = plot_df.reset_index().rename(columns=rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_ylim = [51, 58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(25,8), sharex=True, sharey=True)\n",
    "\n",
    "sns.pointplot(data=plot_df.query(\"attacker == 'regular'\"), hue_order=[\"Asian\", \"Black\", \"Indian\", \"White\", \"Overall\"],\n",
    "              x=rename_dict[\"tsize\"], y=rename_dict[\"vuln\"], hue=\"subgroup\", ax=axes[0], palette=\"tab10\", **pointplot_settings)\n",
    "\n",
    "sns.pointplot(data=plot_df.query(\"attacker == 'discriminating'\"), hue_order=[\"Asian\", \"Black\", \"Indian\", \"White\", \"Overall\"],\n",
    "              x=rename_dict[\"tsize\"], y=rename_dict[\"vuln\"], hue=\"subgroup\", ax=axes[1], palette=\"tab10\", **pointplot_settings)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_ylim(paper_ylim)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "    ax.legend().remove()\n",
    "    \n",
    "axes[1].set_ylabel(\"\")\n",
    "\n",
    "leg = axes[1].legend(loc=\"upper right\", bbox_to_anchor=(1, 1),\n",
    "          fancybox=True, shadow=False, ncol=3)\n",
    "\n",
    "leg.get_frame().set_alpha(0.5)\n",
    "\n",
    "fig.subplots_adjust(wspace=0.01)\n",
    "fig.savefig(\"images/utkface_subgroup_distro.pdf\", format=\"pdf\", bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2_p36] *",
   "language": "python",
   "name": "conda-env-tensorflow2_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
